<!DOCTYPE html>













<html class="theme-next gemini" lang="zh-CN">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2"/>
<meta name="theme-color" content="#222">

<meta name="google-site-verification" content="jgw73iXouBAJcOuff0yi9vdSNDecBSOUXacsHJszpmo" />
<meta name="baidu-site-verification" content="xyf9WD2vvl" />











<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=6.3.0" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=6.3.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=6.3.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=6.3.0">


  <link rel="mask-icon" href="/images/apple-icon-57x57.png?v=6.3.0" color="#222">









<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '6.3.0',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":true,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":false,"async":false,"transition":{"post_body":"slideDownIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="商汤面经作者：Hunto链接：https://www.nowcoder.com/discuss/209857来源：牛客网 很幸运地遇到了和我做的方向非常match的组，boss也很有魅力，极速面试，菜鸡能够过面试很幸运很幸运，不出意外就上岸了吧，给大家分享一下我的面经，可能有些不全，回想起多少写多少 【商汤1面】  CornerNet介绍，CornerPooling是怎么做的，怎么解决corner">
<meta property="og:type" content="article">
<meta property="og:title" content="面试-面经汇总">
<meta property="og:url" content="https://hellozhaozheng.github.io/z_post/面试-面经汇总/index.html">
<meta property="og:site_name" content="从零开始的BLOG">
<meta property="og:description" content="商汤面经作者：Hunto链接：https://www.nowcoder.com/discuss/209857来源：牛客网 很幸运地遇到了和我做的方向非常match的组，boss也很有魅力，极速面试，菜鸡能够过面试很幸运很幸运，不出意外就上岸了吧，给大家分享一下我的面经，可能有些不全，回想起多少写多少 【商汤1面】  CornerNet介绍，CornerPooling是怎么做的，怎么解决corner">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="https://hellozhaozheng.github.io/z_post/面试-面经汇总/Batch-Normalization深入解析">
<meta property="og:updated_time" content="2019-07-30T02:22:37.115Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="面试-面经汇总">
<meta name="twitter:description" content="商汤面经作者：Hunto链接：https://www.nowcoder.com/discuss/209857来源：牛客网 很幸运地遇到了和我做的方向非常match的组，boss也很有魅力，极速面试，菜鸡能够过面试很幸运很幸运，不出意外就上岸了吧，给大家分享一下我的面经，可能有些不全，回想起多少写多少 【商汤1面】  CornerNet介绍，CornerPooling是怎么做的，怎么解决corner">
<meta name="twitter:image" content="https://hellozhaozheng.github.io/z_post/面试-面经汇总/Batch-Normalization深入解析">






  <link rel="canonical" href="https://hellozhaozheng.github.io/z_post/面试-面经汇总/"/>



<script type="text/javascript" id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>面试-面经汇总 | 从零开始的BLOG</title>
  






  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?21a4899cc63d3c11a3d90ac58074a19c";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




  <noscript>
  <style type="text/css">
    .use-motion .motion-element,
    .use-motion .brand,
    .use-motion .menu-item,
    .sidebar-inner,
    .use-motion .post-block,
    .use-motion .pagination,
    .use-motion .comments,
    .use-motion .post-header,
    .use-motion .post-body,
    .use-motion .collection-title { opacity: initial; }

    .use-motion .logo,
    .use-motion .site-title,
    .use-motion .site-subtitle {
      opacity: initial;
      top: initial;
    }

    .use-motion {
      .logo-line-before i { left: initial; }
      .logo-line-after i { right: initial; }
    }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">从零开始的BLOG</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
      
        <p class="site-subtitle">与其感慨路难行，不如马上出发</p>
      
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">
    <a href="/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-home"></i> <br />首页</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">
    <a href="/archives/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />归档<span class="badge">268</span></a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-计算机视觉">
    <a href="/categories/计算机视觉/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-tripadvisor"></i> <br />计算机视觉</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-深度学习">
    <a href="/categories/深度学习/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-drupal"></i> <br />深度学习</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-caffe2">
    <a href="/categories/Caffe2/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-coffee"></i> <br />Caffe2</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-pytorch">
    <a href="/categories/PyTorch/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-free-code-camp"></i> <br />PyTorch</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-c++">
    <a href="/categories/Cpp/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-codiepie"></i> <br />C++</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-python">
    <a href="/categories/Python/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-product-hunt"></i> <br />Python</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-项目">
    <a href="/categories/项目/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-connectdevelop"></i> <br />项目</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-cuda">
    <a href="/categories/CUDA/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-braille"></i> <br />CUDA</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-其他">
    <a href="/categories/其他/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-th"></i> <br />其他</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">
    <a href="/tags/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />标签<span class="badge">41</span></a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-about">
    <a href="/about/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-user"></i> <br />关于我</a>
  </li>

      
      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />站内搜索(首次加载需3~5秒)</a>
        </li>
      
    </ul>
  

  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="站内搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



  



</div>
    </header>

    
  
  
  
    
      
    
    <a href="https://github.com/hellozhaozheng" class="github-corner" target="_blank" title="Follow me on GitHub" aria-label="Follow me on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#222; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg>
    
      </a>
    



    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
            

          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://hellozhaozheng.github.io/z_post/面试-面经汇总/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ZeroZone">
      <meta itemprop="description" content="吾乃闪耀的芝士蛋挞!">
      <meta itemprop="image" content="/images/avatar_zz.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="从零开始的BLOG">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">面试-面经汇总
              
            
          </h1>
        

        <div class="post-meta">
	
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2018-10-18 12:49:47" itemprop="dateCreated datePublished" datetime="2018-10-18T12:49:47+08:00">2018-10-18</time>
            

            
          </span>

	  
  	    <span class="post-updated">
    		&nbsp; | &nbsp; 更新于
    		<time itemprop="dateUpdated" datetime="2019-07-30T10:22:37+08:00" content="2019-07-30">
      		  2019-07-30
    		</time>
  	  </span>
	  

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/面试/" itemprop="url" rel="index"><span itemprop="name">面试</span></a></span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/z_post/面试-面经汇总/#comments" itemprop="discussionUrl">
                  <span class="post-meta-item-text">评论数：</span> <span class="post-comments-count valine-comment-count" data-xid="/z_post/面试-面经汇总/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="post-meta-item-icon"
            >
            <i class="fa fa-eye"></i>
             阅读次数： 
            <span class="busuanzi-value" id="busuanzi_value_page_pv" ></span>
            </span>
          

          
            <div class="post-symbolscount">
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">本文字数：</span>
                
                <span title="本文字数">21k</span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">19 分钟</span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="商汤面经"><a href="#商汤面经" class="headerlink" title="商汤面经"></a>商汤面经</h1><p>作者：Hunto<br>链接：<a href="https://www.nowcoder.com/discuss/209857" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/209857</a><br>来源：牛客网</p>
<p>很幸运地遇到了和我做的方向非常match的组，boss也很有魅力，极速面试，菜鸡能够过面试很幸运很幸运，不出意外就上岸了吧，给大家分享一下我的面经，可能有些不全，回想起多少写多少</p>
<p>【商汤1面】</p>
<ol>
<li>CornerNet介绍，CornerPooling是怎么做的，怎么解决cornernet检测物体合并为一个框的问题</li>
<li>介绍Mimic知识蒸馏是怎么做的</li>
<li>MobileNet 介绍</li>
<li>普通卷积、DW+PW卷积计算量推导</li>
<li>MobileNet V2中的Residual结构最先是哪个网络提出来的</li>
</ol>
<p>编程：</p>
<ol>
<li>之子形打印二叉树</li>
<li>MxN的方格中有多少个正方形、多少个矩形、有多少种不同面积矩形</li>
</ol>
<p>【商汤2面】</p>
<ol>
<li>在人脸关键点和检测中的mimic是怎么做的？为什么不在logits输出上做？用l2 loss吗？</li>
<li>人脸关键点使用pose做multitask为什么landmark会有提升？</li>
<li>目标检测在工程中应用有没有遇到一些问题？检测类别冲突怎么办？</li>
<li>对机器学习了解多吗？</li>
<li>现有两个特征向量，怎么分析他们的相似度？</li>
<li>有没有什么数学方法能够去除特征矩阵中的噪声？</li>
</ol>
<p>编程：</p>
<ol>
<li>判断二叉树是否包含另一二叉树</li>
<li>有序数组合并</li>
</ol>
<p>【商汤3面-leader面】<br>主要与大boss聊自己的未来规划、对某个大方向做一些自己的分析</p>
<ol>
<li>介绍你在xx项目中的工作</li>
<li>项目中你用做过SDK和安卓开发，是在这个项目中学的吗？</li>
<li>你认为目前video和知识蒸馏这两个方向的挑战和可以改进的地方在哪</li>
<li>RNN为什么long-term dependency做不好</li>
<li>你用了Memory Network，有提升吗</li>
<li>你觉得网络模型和硬件平台是什么关系</li>
<li>未来有什么打算，我带的两个组你想去哪个</li>
<li>更想做出一个实用的产品还是做研究</li>
</ol>
<p>【HR面】<br>主要介绍了公司的一些情况、福利，询问手中的offer情况，聊天，我可能是第一个拿到商汤研究员20校招offer的哈哈</p>
<p>等offer中，希望没有意外</p>
<h1 id="商汤"><a href="#商汤" class="headerlink" title="商汤"></a>商汤</h1><p>作者：明月千里寄相思2<br>链接：<a href="https://www.nowcoder.com/discuss/113046" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/113046</a><br>来源：牛客网</p>
<p>前言<br>楼主因为之前实习拿到商汤的offer，加了面试官微信。前几日面试官问我是否需要内推，就把我简历要了过去，然后商汤就给我打电话了，然后然后….就有了昨日被血虐的过程。</p>
<p>一面<br>针对项目提问，简历上所有的项目都问了个遍。其中我有用到ssd-mobilenetv1-coco的预训练模型，我自己finetune之后的map是0.956@IOU0.5，面试官问我map的误报率是多少…我一脸懵逼= =哎，菜是原罪。<br>问曰：熟悉目标检测吗？<br>答曰：看过经典论文，但实际的项目做得不多。<br>继续问：知道nms吧？把nms的代码写一下，并且分析一下时间复杂度。<br>答曰：好的。<br>于是我吭哧吭哧的写了一段，给面试官看，面试官提出了一些优化的点：不用每一次都排序，可以用 一个bool的vector记录哪个bbox会被留下来，我恍然大悟，于是又吭哧吭哧写了一段，如下：</p>
<p>1<br>2<br>3<br>4<br>5<br>6<br>7<br>8<br>9<br>10<br>11<br>12<br>13<br>14<br>15<br>16<br>17<br>18<br>19<br>20<br>21<br>22<br>23<br>24<br>25<br>26<br>27<br>28<br>29<br>30<br>31<br>32<br>33<br>34<br>35<br>36<br>37<br>class Boundingbox<br>{<br> int x;<br> int y;<br> int w;<br> int h;<br> float score;<br>};<br>bool cmp(const Boudingbox &amp;a, const Boundingbox &amp;b)<br>{<br> return a.score &gt; b.score;<br>}<br>float calIOU(Boundingbox a, Boudingbox b);//假设已经定义好这个<br>void NMS(vector<boundingbox> &amp;bboxes, const int num, const int threshold)<br>{<br> if(bboxes.size() &lt;= 0)<br>     return;<br> sort(bboxes.begin(), bboxes.end());<br> int i = 0, count = 0;<br> vector<bool> flags(bboxes.size(), false);<br> while(i &lt; bboxes.size() &amp;&amp; count !=num)<br> {<br>     maxbbox = bboxes[i];<br>     for(int j = i 1;j<bboxes.size();j )="" {="" if(caliou(bboxes[j],="" maxbbox)=""> threshold)<br>            continue;<br>         flags[j] = true;<br>     }<br> }<br> vector<boundingbox>::iterator it = bboxes.begin();<br> for(int i = 0; i&lt;flags.size(); i  )<br> {<br>     if(!flags[i])<br>         it = bboxes.erase(it)<br> }<br>}<br>分析上述代码的时间复杂度为o(N2),N为待选bboxes的个数。（ps：上述代码估计运行还是不行的，只是比伪代码稍微强一点，表明思路）</boundingbox></bboxes.size();j></bool></boundingbox></p>
<p>好了，到这里我觉得我表现的还不错嘛，最起码这个nms的之前我只看过大概流程，但是也“差不<br>多”写出来了，但是下面….</p>
<p>面试官：做个题吧，数组的最大子区间和。<br>我心想：这个也太简单了吧，我得写慢点，于是我控制在五分钟之后才说我写好了。谁料该来的还是<br>要来…<br>面试官：如果数组是二维的咋办？就是一个矩阵，求里面最大的一个子矩阵的和。<br>我： 思考了一下，写了个上面的二维版，面试官说不对。于是又问：那咱们换个问题吧，如果数组首尾相连咋办？<br>我: 思考了很长时间….说可以把数组复制成两段来做，面试官说这样虽然可以，但是可能最大和区间会超过数组本来的长度…好吧确实是这样，面试官此间还多番提醒，仍未果。<br>这题的答案，网上应该有，都是数组的最大子数组和的变种，我这般菜鸡，不会举一反三，不会触类旁通，真是丢脸呀。<br>二面<br>二面面试官竟然是实习时面我的，他认出我来了，我一开始并没有认出来，后面想起来脱口而出：诶呀你变帅了我都木有认出来！感觉这句话把面试官给雷到了，但这确实是心里话，他确实变帅了。</p>
<p>为什么没来实习？我blablabla<br>再讲一下你的毕设吧，我好像忘了。因为我的毕设是做视觉显著性检测，他问我和深度学习中常见的attention有什么关系，其实我觉得就是那个，但是我还是很怂的说不了解attention，怕给自己挖坑…<br>问了一点c STL里面的知识；vector删除(erase()函数)，i 和 i更有效率？（我知道是 i但我不知道为啥啊！！！？？？）<br>下面的重点来了：定义一颗多叉树，并从{ 0 1;0 2;0 3; 0 4; 3 4; 3 5; 3 6}build这棵树<br>好吧，我真的不会，装模做样的在草稿纸上瞎写了一波，面试官亲切的问怎么了哪里不会？我好想说哪里都不会….<br>看我一副便秘般憋不出代码的表情，面试官问我是不是计算机专业的，我说不是，他说好吧那确实为难你了，那我们换个题吧？<br>给我讲下你简历里面你写的熟悉的这些东西吧？讲讲PCA？<br>好吧，PCA我已经不太熟了，我大概说了下：是给数据降维的方法，计算数据矩阵的特征值，并保留特征值累加起来超过全部特征值和的90%以上的特征值对应的特征向量(这是我凭印象瞎说的，正确答案请自行百度= =)，然后面试官问我矩阵的特征值和特征向量是什么意义？好吧我真的说不出个所以然，放弃了。<br>看我很受挫，面试官让我手推下svm，我按照自己的理解推了一遍，重拾了一波信心。<br>三面<br>可能是实习时肯定过我吧，不好打脸，还是给了三面。三面应该是个大佬，在香港，于是微信语音面了一波。</p>
<p>问我什么时候毕业，毕业要求达到没？<br>问我对计算机视觉任务中比较熟悉哪一类，是检测，分割，分类还是什么？<br>我突然我发现我好菜，我竟然一个都不敢说熟悉，检测知道些理论但实际项目没咋做过，分类倒是做过实际项目，但是感觉论文没有看太多，分割就是论文和项目都没咋做过。于是我硬着头皮说了分类。<br>分类网络有哪些？我从LeNet到resNet和mobilenet都说了一遍，然后着重问了我两个问题：<br>(1)resnet为什么好？（我用csdn博客上看到的一个理解解释了一波，被反驳了，后面我问应该怎么理解，面试官说是因为shortlink接口可以减轻梯度消失，这个我不知道咋理解啊？我说这个我知道，面试官又问我梯度消失的原因是什么，我说了一波激活函数导数那个解释，但是面试官说后面都用relu函数了，导数是1或0，为什么还会有梯度消失？不知道不知道真的不知道吗，求各位大佬解答= =）<br>(2)mobilenet为什么快？(分析了一波深度可分离卷积)怎么证明mobilenet的快是因为用了深度可分离卷积？（不知道咋回答…）mobilenet有多少层？（不记得）mobilenet有多少参数(不记得)<br>总之三面就是各种不知道，不清楚，全程很尴尬= =</p>
<p>总结<br>凉经。</p>
<h1 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h1><p>概率题：在圆上任意三个点，形成的三角形为锐角三角形的概率是多少</p>
<h1 id="优秀面经"><a href="#优秀面经" class="headerlink" title="优秀面经"></a>优秀面经</h1><p><a href="https://www.nowcoder.com/discuss/192224" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/192224</a></p>
<p><a href="https://www.cnblogs.com/huanyi0723/p/8470866.html" target="_blank" rel="noopener">https://www.cnblogs.com/huanyi0723/p/8470866.html</a></p>
<p><a href="https://www.nowcoder.com/discuss/78195" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/78195</a></p>
<p><a href="http://www.zheyibu.com/article/5626.html" target="_blank" rel="noopener">http://www.zheyibu.com/article/5626.html</a></p>
<p><a href="https://www.jianshu.com/p/6671232cec79" target="_blank" rel="noopener">https://www.jianshu.com/p/6671232cec79</a></p>
<p><a href="https://www.zhihu.com/question/62482926" target="_blank" rel="noopener">https://www.zhihu.com/question/62482926</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/42705310" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/42705310</a></p>
<h2 id="在多线程和大量并发环境下，如果有一个平均运行一百万次出现一次的bug，-你如何调试这个bug。"><a href="#在多线程和大量并发环境下，如果有一个平均运行一百万次出现一次的bug，-你如何调试这个bug。" class="headerlink" title="在多线程和大量并发环境下，如果有一个平均运行一百万次出现一次的bug， 你如何调试这个bug。"></a>在多线程和大量并发环境下，如果有一个平均运行一百万次出现一次的bug， 你如何调试这个bug。</h2><p>解决Bug，第一步就是重现，第二步定位以及Reduce，第三步再来解。所以，不管百万次还是十万次，首先要重现出来，然后找出重现出来的计算机状态。计算机不会欺骗人，每一个问题出来肯定是有原因的，唯一要做的就是如何把这个计算机状态信息还原出来，你可以使用log跟踪等，怎么纪录还原都是工程师的选择。而若能把相关的状态信息拿到，剩下的就是定位是哪里的问题，而这时候最好的就是模拟和Reduce，把问题缩小，排除其它信息干扰。模拟与Reduce成功以后，再想办法解决，然后再来估计解决问题的难度与成本问题等，有些BUG我们是知道，但是解决太麻烦了，影响也不大，就放着。</p>
<p>作者：蓝色<br>链接：<a href="https://www.zhihu.com/question/43416744/answer/95944740" target="_blank" rel="noopener">https://www.zhihu.com/question/43416744/answer/95944740</a><br>来源：知乎<br>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>
<p>另一方面，从管理上应该要考虑 bug 的严重性与成本／时间的问题。如果最终能找出问题，需要研究怎样防范相似的 bug。</p>
<h2 id="这个bug很难重现，这个时候你要怎么处理或者重现呢。"><a href="#这个bug很难重现，这个时候你要怎么处理或者重现呢。" class="headerlink" title="这个bug很难重现，这个时候你要怎么处理或者重现呢。"></a>这个bug很难重现，这个时候你要怎么处理或者重现呢。</h2><h1 id="有一个类指针，指向类实例化的对象，在这个对象程序的运行过程中，程序崩溃了，后来发现是这个类指针的虚函数表被破坏了，现在如何定位这个问题。"><a href="#有一个类指针，指向类实例化的对象，在这个对象程序的运行过程中，程序崩溃了，后来发现是这个类指针的虚函数表被破坏了，现在如何定位这个问题。" class="headerlink" title="有一个类指针，指向类实例化的对象，在这个对象程序的运行过程中，程序崩溃了，后来发现是这个类指针的虚函数表被破坏了，现在如何定位这个问题。"></a>有一个类指针，指向类实例化的对象，在这个对象程序的运行过程中，程序崩溃了，后来发现是这个类指针的虚函数表被破坏了，现在如何定位这个问题。</h1><p>需要先限定编译器和环节，比如，virtual table 在 Linux 下 GCC 4.9 的实现就是放在read only 段 .rodata，怎么可能被修改？好，就算可以被修改，我第一反应就是上GDB与Valgrind，被破坏的原因很多，你不让我调，我怎么跟你继续说下去，不如直接给我代码，我调给你看？ 那你首先准备一个这样的代码？</p>
<p>作者：蓝色<br>链接：<a href="https://www.zhihu.com/question/43416744/answer/95944740" target="_blank" rel="noopener">https://www.zhihu.com/question/43416744/answer/95944740</a><br>来源：知乎<br>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>
<h1 id="模型压缩"><a href="#模型压缩" class="headerlink" title="模型压缩"></a>模型压缩</h1><h1 id="cuda"><a href="#cuda" class="headerlink" title="cuda"></a>cuda</h1><p>作者：oncecoder<br>链接：<a href="https://www.nowcoder.com/discuss/23418" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/23418</a><br>来源：牛客网</p>
<p>   面试官：看你简历上写熟悉CUDA，你能具体讲讲吗。<br>   我：写过图片的resize,padding,卷积，提取hog特征等的gpu代码（kernel函数），效果还不错。<br>   面试官问：具体说说怎么做到提升速度的。<br>   我：把处理安排到gpu的每个thread上。<br>   面试官：那看来你就相当于简单的利用了gpu的多核的特性？<br>   我一听感觉面试官不是很满意，于是扯了扯：还用了share_memory,const_memory等来提升速度，用了原子操作等来保证安全性。<br>   面试官：你能讲讲使用shared memory为什么快吗？<br>   我：在某些应用场景下会快，一来和使用场景有关，讲了下哪些场景用这个会好一些，二来可能是硬件方面的原因吧，硬件原理方面的我也不清楚。<br>    然后面试官从内存的金字塔结构，以及gpu的一些特性给我展开讲了很多，这个面试官感觉是gpu方面的行家，人非常好，感觉给我做了个讲座。。。<br>    然后面试官问：你知道warp这个概念吗？<br>    我说知道，就是gpu底层同时执行的指令数量，现在一般是32.所以在写内核函数的时候，thread的数目最好是32的倍数。其他的不太清楚。<br>    面试官好像点了点头，又给我balabala做了一次讲座。。。。<br>    面试官问：假如要申请一大片空间，一次性申请这么大的，和分多次申请很多小的，但总数一样，哪个快，为什么。<br>    我：在做项目的时候遇到过这种情况，前者会快很多，然后说了原因（答得不太标准，就不误导大家了）<br>    面试官：其实cpu和gpu在这方面是一样的，  都会维护一个表什么的，记不太清楚了。<br>    面试官：怎么看gpu使用情况。我：nvidia-smi(我用的是nvidia的卡)</p>
<h1 id="face-面经"><a href="#face-面经" class="headerlink" title="face++ 面经"></a>face++ 面经</h1><p>作者：一一后<br>链接：<a href="https://www.nowcoder.com/discuss/119900" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/119900</a><br>来源：牛客网</p>
<p>一面（30分钟+</p>
<pre><code>撸项目（很细节，第一个项目每一步都要问为什么不用某个其他的方法）
讲讲adaboost和random frost的相同之处和不同，各自应用范围，实际应用选择
对SVM的理解，简单推导SVM，为什么要用对偶问题（二次规划+核化）具体讲一下为什么要核化，核化的过程
讲一下DL中目标检测的大类和特点（one stage、two stage）为什么two stage比one stage慢，为什么one stage比two stage精度高？one stage在哪些具体方面检测精度不高（ROI+default box的深层理解）
讲讲梯度消失问题及其应对方案（BN、Relu、初始化）
讲讲BN的细节（过程，公式，作用）为什么BN可以加快优化算法的速度
有什么问题
</code></pre><p>总结：问得很深入，基本都要非常理解才行，提到某个细节之后可能会深入问这个细节更细节的东西，千万别在回答的时候给自己挖坑。</p>
<p>二面：（40分钟+</p>
<pre><code>自我介绍；链表的倒数第k个结点（双指针）
应用场景题
抛一个不均匀的硬币，设计策略能得到1/2的概率（抛两次）如果要求得到1/3和2/3呢？设计策略（抛四次，我想着抛6次，小哥哥提醒了）
给出一个0到n的随机数生成器，设计策略，让不得到x的条件下，得到其他数的均匀分布（只能生成一次）（hash映射，但是我找不到合适的映射函数，小哥哥提醒了）扩展：不得到两个数呢？m个数呢？（一样）
房子500万，每年涨10%，程序员工资100万，不涨，问多少年能全款买房（几秒钟估算了一下，永远买不起…）（总觉得小哥哥在暗示我什么）
堆介绍，插入元素时调整的时间复杂度（变成二叉树，递归定义）堆排序、其他排序方法介绍和特点（按时间复杂度分了三种去介绍），最常用哪种
有什么问题（小哥哥建议多看些ML的实际场景（我其实想问智商怎么提升…）
</code></pre><p>总结：二面考基本功，数学算法和ML的熟练运用能力。</p>
<p>三面（院长大佬面）（挂）</p>
<pre><code>自我介绍
用到深度学习的项目（大部分时间聊项目）
深度学习的前沿知识（最新的网络结构、精度最高的目标检测模型等）
有什么问题（大佬很委婉地劝我说他们主要收深度学习方向的…）


作者：jucic
链接：https://www.nowcoder.com/discuss/108078
来源：牛客网

CV岗：
一面：
用C++将一个类改造成线程安全的类
凸优化了解吗
SLAM里面闭环检测是什么怎么做
用深度学习做SLAM了解吗
兼职offer上一原题
交叉熵是什么

二面:
链表反转
快排

三面（院长面）
一直在聊项目
算法细节部分被怼的很厉害
</code></pre><p>某个函数只能随机产生0或1，利用这个实现一个函数能等概率的返回1-n之间的数，手撕实现代码</p>
<p>一个文件有一亿条整数数据，算一下占用多大磁盘，里面有几十个重复的数据，怎么找出来，内存占用不要超过本身的文件大小</p>
<p>a) 概率是抽样的题目居多，计算正确，错误或者抽中没抽中的概率，与腾讯考察的要求差不多，但稍难<br>其中一题，第一题，问试卷中的10道题，每到5个选项，如果瞎猜，每道题的数学期望是多少，如果每道题猜错的概率是92%，那么每道题的数学期望是多少？<br>b) 计算甲乙两地距离的问题，甲乙分别从AB两地相向而行，甲乙速度比是常数，第一次相遇在距离甲地80KM处，分别到达对方起点后，再返回来相向而行，第二次相遇在距离甲地40KM处，计算甲乙两地相距多远的问题<br>c) 研究基础，问到了RANSAC抽样的问题，将它与概率结合，抽取两个样本，抽取10次，问抽样概率<br>d) ICCV会议2013与2015年分别是在哪里开的<br>e) 选做题：写HOG的伪代码；关于图像模糊问题；问常见的跟踪方法有哪些，简述他们的优缺点，举一个近五年CVPR中流行的跟踪方法，写出它的思想</p>
<p>作者：牛客网<br>链接：<a href="https://zhuanlan.zhihu.com/p/29695077" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/29695077</a><br>来源：知乎<br>著作权归作者所有。商业转载请联系作者获得授权，非商业转载请注明出处。</p>
<p>中国平安 - 实习生(上海/北京)  1.卷积正向和反向传播  2.Caffe源码  3.斐波那契 memcpy  4.pooling反向  5.项目介绍  6.override overload 纯虚函数等  阿里巴巴 - 2017.3.23 - 实习生 - idst - 非内推  1.linux 修改环境变量  2.sql语句  3.gbdt xgboost区别  4.kaggle项目 30min  5.融合方法，改进  阿里巴巴 - 2017.3.28 - 实习生 - 淘宝搜索 - 内推一面  1.项目介绍(30分钟)—项目过程，融合方法，训练方法，augmentation等  2.batch normalization  3.有没有了解其他机器学习算法  4.介绍一个熟悉的算法(决策树)  5.在线写线性回归  6.对深度学习框架有没有了解，还是只是停留在使用的层面  7.有没有什么想问的  阿里巴巴 - 2017.3.31 - 实习生 - 淘宝搜索 - 内推二面  1.项目介绍  2.kd-tree  3.开放问题  100w商品 50个推荐窗口，怎么安排推荐  腾讯 - 2017.4.10 - 实习生非内推 - 优图实验室 - 一面  1.项目介绍  2.计算卷积核参数数量  3.如何处理深度学习overfitting  4.如何在测试中，加速1000倍(不改变网络结构)  5.pooling层的作用，以及为什么会选择maxpooling  6.有没有从头开始训练一个模型 vgg16 resnet googlenet收敛问题  今日头条 - 2017.4.11 - 日常实习生非内推 - 一面  1.项目介绍  2.如何训练深度学习网络  3.如何处理样本分布不均衡的问题  4.手写代码-反转链表  5.手写代码-前序遍历  今日头条 - 2017.4.11 - 日常实习生非内推 - 二面  1.项目介绍（为什么不尝试xgboost以外的模型）  2.xgboost gbdt区别  3.深度学习训练方法  4.改进方法  5.caffe框架结构  6.手写代码-旋转数组找出最大数字  今日头条 - 2017.4.13 - 日常实习生非内推 - 三面  1.前两面反应较好，聊天  2.对前两个面试官有什么看法  3.有什么问题  #腾讯挺坑的，一面过了，二面面试官打电话确认了面试时间，收到了确认邮件，然后鸽了  腾讯游戏 - 校招内推 - 一面  1.实习介绍  2.介绍svm，为什么要求对偶  3.介绍一个熟悉的算法  4.全局变量 局部变量存储位置不同，静态变量初始化，生存周期  5.python多线程的实现，死锁  6.优化算法 sgd 牛顿法。为什么牛顿法快？及其缺点？  网易 - 内推校招 - 人工智能事业部 - 一面  1.实习介绍  2.kaggle 深度学习项目介绍  3.几个框架对比  4.模型融合策略和方法  网易 - 内推校招 - 人工智能事业部 - 二面  1.项目介绍，讲你最好的项目  2.实习介绍  3.svm手推  4.kaggle融合的策略和方法  #前3面反映较好，加面  网易 - 内推校招 - 人工智能事业部 - special 加面  1.最好的项目介绍  2.batch normalization算法  3.实习经历  4.cnn现在发展以及不足  5.说对游戏ai感兴趣 - alphago的技术点，强化学习等  华为 - 内推校招 - 1,2,3面  #略  #Nvidia Deeplearning software 面试官很客气，提前定好这次面试时长40分钟  Nvidia - 内推校招 - 一面  1.项目介绍 30min  2.编程题2道  3.过拟合欠拟合 以及其背后本质，偏差方差角度如何理解  #Sensetime 商汤科技 每面30min  #号称最难进公司之一？  Sensetime - 2017.9.11 - 校招内推 - 计算机视觉&amp;深度学习 - 一面  1.kaggle比赛 问的比较详细  包括 data augmentation， KNN的trick， 模型融合等  2.实习经历  3.有什么问题  Sensetime - 2017.9.11 - 校招内推 - 计算机视觉&amp;深度学习 - 二面  1.kaggle比赛  2.头条实习  3.python set-list转化  4.caffe框架结构，learning rate设置  5.第K大的数  6.sgd adam区别  7.resnet vgg区别  8.python 变量拷贝规则  9.有什么要问的  Sensetime - 2017.9.11 - 内推校招 计算机视觉&amp;深度学习 - 三面  1.头条实习 比较详细以及为什么头条推荐这么厉害 #面试官是在做dl+推荐，所以比较关心头条所做的东西  2.熟悉什么框架  3.喜欢什么方向，cv还是推荐等，以及个人认为他们的前景  4.学术型硕士还是工程型硕士？  5.有什么问题  阿里巴巴 - 2017.9.13 - 校招 - 初面  1.头条实习 ——- 特征维度，为什么时延很低，在头条做了哪些，头条的算法  2.深度学习和传统机器学习  3.深度学习最近的发展和技术突破点  4.GBDT是什么 — 加法模型  5.为什么现在推荐可以使用GBDT的内部结点当做LR的特征 — 特征选择和子集评价，还是stack模型融合？  6.RF GBDT区别 — 方差偏差理论，bagging&amp;boost区别  7.GBDT xgboost区别 —泰勒二阶，并行化，正则项  8.手写MergeSort  9.熟悉什么语言  10.用什么框架  11.深度学习正则化  12.GBDT分布式如何实现 #没有了解过，然后简单说了自己的想法，面试官给我讲了许多这方面  阿里巴巴 - 2017.9.15 - 校招 - 终面  1.头条实习 ——- 模型介绍  2.GBDT xgboost区别  3.kaggle比赛  4.一个整数数组中，寻找3个数乘积最大  5.GBDT与bagging等方法区别  6.linux常用指令 sort grep等  阿里巴巴 - 2017.9.15 - 校招 - 加面  #压力面？  1.头条实习ffm替换skip gram模型，为什么？效果如何？为什么会有提速效果？线上如何部署等  2.头条所做？训练两个大模型，效果如何？  3.kaggle比赛  4.vgg16 resnet googlenet区别  5.手写代码-旋转数组找出最小数字  #其余记不清了  大疆 - 2017.9.17 - 校招 - 初面  1.头条实习  2.kaggle项目</p>
<h1 id="待看"><a href="#待看" class="headerlink" title="待看"></a>待看</h1><p><a href="http://www.cnblogs.com/mrxsc/articles/6266584.html" target="_blank" rel="noopener">http://www.cnblogs.com/mrxsc/articles/6266584.html</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/29633019" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/29633019</a></p>
<p>【链接】依图面试经历（三轮面试，已得offer）<br><a href="https://zhuanlan.zhihu.com/p/27842581" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/27842581</a></p>
<p><a href="https://www.nowcoder.com/discuss/73739" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/73739</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/38067051" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/38067051</a></p>
<p>【链接】依图科技暑期实习生面试经验<br><a href="https://blog.csdn.net/wslf123/article/details/79924413" target="_blank" rel="noopener">https://blog.csdn.net/wslf123/article/details/79924413</a></p>
<h1 id="字节跳动提前批"><a href="#字节跳动提前批" class="headerlink" title="字节跳动提前批"></a>字节跳动提前批</h1><p>作者：DASEason<br>链接：<a href="https://www.nowcoder.com/discuss/206226?type=2" target="_blank" rel="noopener">https://www.nowcoder.com/discuss/206226?type=2</a><br>来源：牛客网</p>
<p>一面二面是现场面，三面和交叉面是视频面<br>一面和二面连在一起，三面大约5天之后，交叉面大约三面的两天后，offer call在交叉面的一天后</p>
<h2 id="本人研究方向是NLP，面的是AILab语音部门（前期负责语音组的NLP任务，后期慢慢接手语音相关任务）"><a href="#本人研究方向是NLP，面的是AILab语音部门（前期负责语音组的NLP任务，后期慢慢接手语音相关任务）" class="headerlink" title="本人研究方向是NLP，面的是AILab语音部门（前期负责语音组的NLP任务，后期慢慢接手语音相关任务）"></a>本人研究方向是NLP，面的是AILab语音部门（前期负责语音组的NLP任务，后期慢慢接手语音相关任务）</h2><p>一面（两道编程题）：<br>面试官应该是未来同事，上来在白板上先描述了第一道题。<br>A题题意：给定n个结点，m条有向边（n&lt;=100）。每个结点代表一个抖音用户，每条边A-&gt;B代表A关注了B。关注具有传递性，即若A关注了B且B关注了C，那么等同于A关注了C。 然后定义“抖音红人”的概念：若一个用户被其它n-1个用户关注，那么他是抖音红人。现给定这样一个关注网络，返回所有的“抖音红人”列表。<br>A题题解：DP+dfs（记忆化搜索）。对于某个用户A，若要求关注A的的用户个数，则需要累加所有指向A的用户的被关注数。然后递归地（dfs）求所有指向A的用户Bi，也要累加所有指向Bi的用户的被关注数。。 有两个关键点：1.需要用记忆化搜索保存中间过程，对于已求过的结点，不能重复递归计算；2.累加不是单纯的加和，而是要对每个结点维护一个集合set，累加的操作其实是求并集操作，防止同一用户被累加多次。<br>本人解题情况：一开始写的猛如虎，然后忘记考虑集合求并集的操作了，后来面试官比较好提醒了我一下，后来把代码改对了。</p>
<p>然后面试官接着描述了B题，题意比较简单：描述KMeans算法，并用Tensorflow写代码实现。<br>题解：这题没啥好说了，把能说的关于Kmeans的细节都和面试官说了，代码也写的还OK（不用写feed_dict那些繁琐的过程，只要写建图的部分就好）。 注意代码需要高度并行化，例如计算相似度这些操作需要用张量运算，保证高度并行化。</p>
<p>两题写完之后，面试官问我有啥想问的，然后就让我等一会儿。过5分钟二面开始。</p>
<hr>
<p>二面（个人经历、项目、竞赛、论文）<br>二面面试官应该是我将来的mentor，很和蔼。一开始就让我介绍我的经历，然后我就从本科到研究生的经历都说了一遍，沟通过程也很愉快。 中间主要花时间和面试官讲解了曾经的ACM经历（挫折，成就，意义）、介绍 Github 1.5k star 的项目（项目做了啥，为什么受到这么多关注，创新点）、介绍一年多的实习项目（开发过程，技术细节，沟通协作）、讲解自己的一篇AAAI paper（模型架构，contribution，实验）。<br>最后二面面试官挺满意的，面试愉快地结束了。</p>
<hr>
<p>三面（个人经历、项目、竞赛、论文）<br>三面面试官是AILab王雨轩总监。王老师人在美国，所以是早上7点的视频面。。<br>三面是我个人感觉最难一面，由于不能保证我回答的准确性，这里只写王老师问了啥。</p>
<ol>
<li>讲讲你的个人经历</li>
<li>你介绍一下你的Paper</li>
<li>我看你还做过CV的项目和安卓游戏的项目，也简单介绍一下吧<br>4.（开始虐了）先写道题吧。用Tensorflow写一个KNN算法</li>
<li>KNN算法是否可微</li>
<li>我看你用了tf.argmax()，argmax的导数是啥（其实是不可导，因为我之前回答了KNN是可微的，所以他想看看我会回答什么）<br>7.（王老师看我被虐的有点惨，笑着说换道题吧）用C++写个简单的矩阵乘法吧</li>
<li>矩阵乘法怎么优化？（当时我回答的是将复杂度优化到O(n^log7)的Strassen算法，而且算法名字不会读。。  有可能王老师还希望听到我回答关于多线程的优化方法）</li>
<li>两个上三角矩阵相乘如何优化？（完全懵逼，答不出来）<br>王老师还问了一些其它细节问题，暂时想不起来了。 当时三面面完感觉自己要凉了。。</li>
</ol>
<hr>
<p>交叉面（个人经历、项目、NLP算法细节、职业规划）<br>当接到HR交叉面的通知时，我是不敢相信的（而且HR居然说前三面的面试官对我的评分都很不错，难以置信。。）<br>当我知道面试官是李航老师的时候，我更是不敢相信的（当时心里太激动，心想能和李航老师交流，挂了也值了-。-）<br>抱着久久不能平复的心情，坐在显示器前等待了一个多小时，终于等到李航老师上线了。 能和偶像当面对话，难掩心中的激动，但是担心给李航老师留下不好的印象，于是还是克制住了自己激动的情绪。。<br>我这里也主要只写李航老师问了啥吧，我的回答就不写了。</p>
<ol>
<li>介绍一下你做过的项目</li>
<li>介绍一下你的paper</li>
<li>Word2vec，fasttext，ELMo，GPT，BERT的区别</li>
<li>介绍一下BERT的模型架构，多少层，怎么预训练，怎么feature based/fine-tune</li>
<li>什么是self-attention，什么情况下要用，K、Q、V分别是啥</li>
<li>你为什么选择我们公司</li>
<li>你将来的职业发展规划<br>李航老师人也特别的好，基本没有怎么为难我（而且没考我《统计学习方法》）。<br>最后李航老师问你有什么想问我的。于是我面试结束前才屁颠屁颠地表达了我压抑已久的对李航老师的仰慕，然后臭不要脸地加了李航老师的微信（这波不亏！）</li>
</ol>
<hr>
<p>最终本人于一天后收到offer call。简单总结一下个人认为面试成功的几个关键因素：</p>
<ol>
<li>刷题还是很必须的。要做到快速出题，实在不会的题也得写个次优解，千万不要挂机。</li>
<li>多掌握面试的主导权。引导面试官听你擅长的东西。</li>
<li>面试气氛也很重要。 至少你要保持笑容，尽量不要愁眉苦脸，让面试官觉得以后和你合作会很愉快。</li>
<li>知识的积累。这个平时就要做到，就不多说了。</li>
<li>面试前的复习重点是自己的简历。 因为面试官重点会考察你对自己做过的项目的理解程度，看你是不是划水的。</li>
<li>放松心态。 不要因为一个题出不来就方了，其实很多题大家都做不出来。保持心态回答后续的问题，不要中途就认为自己凉了。很多面试其实是所谓的“压力面”，面试官并不指望你能回答所有问题，有的时候更想看看你在面对这种难题时是如何思考和应对的。</li>
</ol>
<p>暂时先写这么多吧，祝大家都拿到自己心仪的offer！</p>
<h1 id="未整理的问题"><a href="#未整理的问题" class="headerlink" title="未整理的问题"></a>未整理的问题</h1><p>Why Anchor? <a href="https://mp.weixin.qq.com/s/R0mqIUzyj-8m5JqJ-kMC5Q" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/R0mqIUzyj-8m5JqJ-kMC5Q</a><br>盘点: 性能最强的目标检测算法 <a href="https://mp.weixin.qq.com/s/N7QdQVzm6UuPvPN9niHI6w" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/N7QdQVzm6UuPvPN9niHI6w</a></p>
<p>此外，变体ShuffleNet v2<em>具有最好的精度，仍然比其他方法更快。这引发了一个实际的问题:<em>*如何增加接受域的大小?这对于高分辨率图像[39]中的目标检测至关重要。</em></em> 我们以后会研究这个话题。</p>
<p>ResNet 之后还有什么模型?</p>
<p>Batch 的 size 怎么选, 显存中一般会存储写什么: 显存占用 <a href="https://blog.csdn.net/lien0906/article/details/7886311" target="_blank" rel="noopener">https://blog.csdn.net/lien0906/article/details/7886311</a></p>
<p>【链接】网络inference阶段conv层和BN层的融合<br><a href="https://zhuanlan.zhihu.com/p/48005099" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/48005099</a></p>
<p>模型压缩方法: SVD(由于近似计算, 会降低精度), Network Pruning, Crompression.</p>
<p>手写 iou, nms, soft-nms</p>
<p>二值交叉熵, softmax 公式</p>
<p>手写计算两向量的欧式距离</p>
<p>BN</p>
<p>链表排序</p>
<p>卷积参数量的计算</p>
<p>过拟合遇到过吗？怎么处理的</p>
<p>训练时出现 Nan 可能的原因是什么?  怎么办?<br><a href="https://blog.csdn.net/Michael__Corleone/article/details/78531795" target="_blank" rel="noopener">https://blog.csdn.net/Michael__Corleone/article/details/78531795</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/25110930" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/25110930</a></p>
<p><a href="https://www.zhihu.com/question/49346370" target="_blank" rel="noopener">https://www.zhihu.com/question/49346370</a></p>
<p>PCA了解不，其优化目标是什么, Pca白化是什么？</p>
<p>手写BN的实现。注意BN的mean和std是在哪个维度求梯度的，mean和std是滑动平均的值。基于numpy实现</p>
<p>说下牛顿法</p>
<p>反卷积具体怎么实现的</p>
<p>为什么dropout能减少过拟合</p>
<p>NMS的原理，假设两个人靠的非常近，则会识别成一个bbx，会有什么问题，怎么解决</p>
<p>Pytorch当中permute和view的功能</p>
<h1 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h1><p>Logistic(Sigmoid) 函数: $g(z) = \frac{1}{1+e^{-z}}$<br>Logistic 表达式: $h_\theta (x) = g(\theta^T x) = \frac{1}{1 + e^{-\theta^Tx}}$<br>线性回归模型: $\theta^T x = \sum^n_{i=1}\theta_i x_i$<br>SGD</p>
<p>Logistic 的梯度更新表达式和最小二乘法(LMS)的公式相同, 虽然看上去完全相同, 但实际上 SGD 和 LMS 是两个完全不同的算法, 因为 SGD 中的 $h_\theta (x)$ 表示的是关于 $\theta^T x$ 的一个非线性函数.</p>
<p>机器学习500问 第二章<br>百面机器学习 第三章</p>
<h1 id="线性回归和逻辑回归的原理和区别"><a href="#线性回归和逻辑回归的原理和区别" class="headerlink" title="线性回归和逻辑回归的原理和区别"></a>线性回归和逻辑回归的原理和区别</h1><h1 id="在Faster-RCNN中-如果两个物体重合度很高-会怎么样"><a href="#在Faster-RCNN中-如果两个物体重合度很高-会怎么样" class="headerlink" title="在Faster RCNN中, 如果两个物体重合度很高, 会怎么样"></a>在Faster RCNN中, 如果两个物体重合度很高, 会怎么样</h1><p>由于 Faster RCNN 在提取感兴趣区域的时候, 它的类别默认是只有二类, 即是否包含物体, 所以如果两个物体重合度很高的话, 最终可能就只能检测出一个物体.(right?)</p>
<h1 id="卷积神经网络复杂度分析"><a href="#卷积神经网络复杂度分析" class="headerlink" title="卷积神经网络复杂度分析"></a>卷积神经网络复杂度分析</h1><p><a href="../深度学习-卷积神经网络复杂度分析">卷积神经网络复杂度分析</a></p>
<h1 id="卷积计算-卷积层特参数个数及征图谱尺寸计算"><a href="#卷积计算-卷积层特参数个数及征图谱尺寸计算" class="headerlink" title="卷积计算,卷积层特参数个数及征图谱尺寸计算"></a>卷积计算,卷积层特参数个数及征图谱尺寸计算</h1><p>卷积层输入图谱大小为 $D_in \times D_{in} \times depth_{in}$ , 卷积核尺寸为 $F \times F \times depth_{in}$, 步长为 $stride$ ,结合padding,输出的图谱size是多少</p>
<script type="math/tex; mode=display">D_{out} = \frac{D_{in} - F + 2*Padding}{stride} + 1</script><p>输出的特征图谱的深度为卷积核的个数: $depth_{out} = Num_{filters}$</p>
<p>本层的偏置参数数量: $Num_{bias} = Num_{filters}$, 注意只与卷积核的个数有关, 与输入的特征图谱的深度无关</p>
<p>该层的参数个数 = 卷积核参数个数 + 偏置项参数个数:</p>
<script type="math/tex; mode=display">Num_{params} = F \times F \times depth_{in} \times depth_{out} + Num_{bias}</script><h1 id="L2正则化和L2规范化-归一化-的不同"><a href="#L2正则化和L2规范化-归一化-的不同" class="headerlink" title="L2正则化和L2规范化(归一化)的不同"></a>L2正则化和L2规范化(归一化)的不同</h1><p>正则化是指正则项, 计算完以后是一个矢量. 归一化是将向量中每个元素进行归一化, 计算完以后还是同size的向量, L2归一化实际上就是对每一个元素除以L2正则项.</p>
<h1 id="从-rcnn-到-faster"><a href="#从-rcnn-到-faster" class="headerlink" title="从 rcnn 到 faster"></a>从 rcnn 到 faster</h1><p><a href="https://blog.csdn.net/xiaoye5606/article/details/71191429" target="_blank" rel="noopener">https://blog.csdn.net/xiaoye5606/article/details/71191429</a></p>
<h1 id="为什么fast-rcnn的roi-pooling比spp的-spatial-pooling效果好"><a href="#为什么fast-rcnn的roi-pooling比spp的-spatial-pooling效果好" class="headerlink" title="为什么fast rcnn的roi pooling比spp的 spatial pooling效果好???"></a>为什么fast rcnn的roi pooling比spp的 spatial pooling效果好???</h1><h1 id="神经网络参数初始化"><a href="#神经网络参数初始化" class="headerlink" title="神经网络参数初始化"></a>神经网络参数初始化</h1><h1 id="分类问题为什么用交叉熵"><a href="#分类问题为什么用交叉熵" class="headerlink" title="分类问题为什么用交叉熵"></a>分类问题为什么用交叉熵</h1><p><strong>典型错误答案1:</strong> 如果用交叉熵，能保证神经网络训练时是一个凸优化问题</p>
<p>错误原因: 凸函数的复合并不一定是凸函数</p>
<p><strong>典型错误答案2:</strong> 如果当前值与目标值相差很远，则梯度下降法迭代时收敛的更快一些</p>
<p>错误原因: 欧式距离(平方损失)也能起到这个作用, 为什么不用?</p>
<p><strong>正确答案:</strong></p>
<p>Cross-Entropy vs. Squared Error Training: a Theoretical and Experimental Comparison.</p>
<h1 id="Relu和Dropout都具有正则化作用-它们在正则化方面的区别是什么"><a href="#Relu和Dropout都具有正则化作用-它们在正则化方面的区别是什么" class="headerlink" title="Relu和Dropout都具有正则化作用, 它们在正则化方面的区别是什么?"></a>Relu和Dropout都具有正则化作用, 它们在正则化方面的区别是什么?</h1><p>Relu是强制正则化(所有神经元的输出值, 只要小于0, 就置为0)</p>
<p>Dropout是随机正则化(随机让一些神经元的不起作用)</p>
<h1 id="介绍一下-hard-negative-mining-难样例挖掘"><a href="#介绍一下-hard-negative-mining-难样例挖掘" class="headerlink" title="介绍一下 hard negative mining(难样例挖掘)"></a>介绍一下 hard negative mining(难样例挖掘)</h1><h1 id="dropout内部是怎么实现的"><a href="#dropout内部是怎么实现的" class="headerlink" title="dropout内部是怎么实现的"></a>dropout内部是怎么实现的</h1><p>在 <strong>训练阶段</strong> 给每个神经元的参数都会乘以 $\frac{1}{\alpha_{dropout}}$, 这样一来, 在训练阶段可以随时更改dropout的参数值, 而对于测试阶段来说, 无需对神经元进行任何额外处理, 所有的神经元都相当于适配了训练过程中dropout对参数带来的影响.</p>
<h1 id="简述一下BN"><a href="#简述一下BN" class="headerlink" title="简述一下BN"></a>简述一下BN</h1><p>首先标准化就是将数据归一到一个希望的区间内, 一般都是归一化到激活函数敏感区域内, 而BN和传统标准标准化的区别主要有两点:</p>
<ul>
<li>BN是在每一个batch上做标准化的, 并且不仅仅只对输入层数据做标准化, 对网络内部的隐藏层输入也会进行标准话</li>
<li>第二就是BN并不是在标准的减均值初标准差之后, 还会进行一个线性变换,<strong>其本质就是改变数据分布的方差和均值</strong>. 对应的两个参数是通过学习学出来的. 其主要思想是考虑到数据可能本身就具有一定的不对称性, 并且激活函数也不一定就在面对标准数据时才有最好的表现, 因此</li>
</ul>
<p>关于BN的详细解析可以看:</p>
<p><div style="width: 550px; margin: auto"><img src="Batch-Normalization深入解析" alt=""></div></p>
<h1 id="各种初始化方式，及公式各个参数对训练的影响"><a href="#各种初始化方式，及公式各个参数对训练的影响" class="headerlink" title="各种初始化方式，及公式各个参数对训练的影响"></a>各种初始化方式，及公式各个参数对训练的影响</h1><h1 id="目标检测，数据不平衡问题怎么解决"><a href="#目标检测，数据不平衡问题怎么解决" class="headerlink" title="目标检测，数据不平衡问题怎么解决"></a>目标检测，数据不平衡问题怎么解决</h1><p>对于目标物的不平衡问题, 通过采样方法来缓解.</p>
<p>对于前后景样本数的不平衡问题, 尝试使用FocalLoss来解决</p>
<script type="math/tex; mode=display">L = -(1-p_t)^\gamma log(p_t)</script><h1 id="你的zerotensor和TF比性能上有优势吗"><a href="#你的zerotensor和TF比性能上有优势吗" class="headerlink" title="你的zerotensor和TF比性能上有优势吗"></a>你的zerotensor和TF比性能上有优势吗</h1><h1 id="常用的数据增强技术"><a href="#常用的数据增强技术" class="headerlink" title="常用的数据增强技术"></a>常用的数据增强技术</h1><p>水平或垂直翻转图像、裁剪、色彩变换、扩展和旋转</p>
<h1 id="有哪些可以避免过拟合的办法"><a href="#有哪些可以避免过拟合的办法" class="headerlink" title="有哪些可以避免过拟合的办法"></a>有哪些可以避免过拟合的办法</h1><p>数据增强, 正则化, 模型融合(其中dropout是模型融合方法中最高效和常用的技巧)</p>
<p>为了防止过拟合，增加训练样本是一个好的解决方案。此外，还可使用数据增强、L1 正则化、L2 正则化、Dropout、DropConnect 和早停（Early stopping）法等</p>
<h1 id="正则化L1和L2的区别"><a href="#正则化L1和L2的区别" class="headerlink" title="正则化L1和L2的区别"></a>正则化L1和L2的区别</h1><h2 id="rcnn。。"><a href="#rcnn。。" class="headerlink" title="rcnn。。"></a>rcnn。。</h2><h1 id="推导svm"><a href="#推导svm" class="headerlink" title="推导svm"></a>推导svm</h1><h1 id="卷积层的参数个数计算公式是："><a href="#卷积层的参数个数计算公式是：" class="headerlink" title="卷积层的参数个数计算公式是："></a>卷积层的参数个数计算公式是：</h1><p>输入的filers×kernerl size ×输出的filters。如：</p>
<p>（3×3×256）×512   括号前面是每一个卷积核的大小，后面的是总共有512个卷积核</p>
<h1 id="梯度消失和梯度爆炸的概念，引用这两个现象的原因及其解决办法"><a href="#梯度消失和梯度爆炸的概念，引用这两个现象的原因及其解决办法" class="headerlink" title="梯度消失和梯度爆炸的概念，引用这两个现象的原因及其解决办法"></a>梯度消失和梯度爆炸的概念，引用这两个现象的原因及其解决办法</h1><p>详见<a href="">梯度消失和梯度爆炸问题深入解析</a></p>
<p><span id="activation"> </span></p>
<h1 id="关于各种激活函数的解析与讨论"><a href="#关于各种激活函数的解析与讨论" class="headerlink" title="关于各种激活函数的解析与讨论"></a>关于各种激活函数的解析与讨论</h1><h1 id="简述ResNet"><a href="#简述ResNet" class="headerlink" title="简述ResNet"></a>简述ResNet</h1><h1 id="嵌入式开发很底层-一般还是倾向于做一些上层的东西"><a href="#嵌入式开发很底层-一般还是倾向于做一些上层的东西" class="headerlink" title="嵌入式开发很底层   一般还是倾向于做一些上层的东西"></a>嵌入式开发很底层   一般还是倾向于做一些上层的东西</h1><h1 id="推导SVM"><a href="#推导SVM" class="headerlink" title="推导SVM"></a>推导SVM</h1><h1 id="比较Boosting和Bagging的异同"><a href="#比较Boosting和Bagging的异同" class="headerlink" title="比较Boosting和Bagging的异同"></a>比较Boosting和Bagging的异同</h1><p>二者都是集成学习方法, 都是将多个弱学习器组合成强学习器的方法, 它们的区别在于:</p>
<p>Boosting: 每一轮根据上一轮的分类结果动态调整每个样本在分类器中的权重, 训练得到k个弱分类器, 他们都有各自的权重, 通过加权组合的方式得到最终的分类结果</p>
<p>Bagging: 从原始数据集中每一轮又放回地抽取训练集(抽取的训练集小于原始数据集), 训练得到k个弱学习器, 然后将这k个软学习器的分类结果结合, 得到最终的分类结果.</p>
<h1 id="无监督学习中存在过拟合吗"><a href="#无监督学习中存在过拟合吗" class="headerlink" title="无监督学习中存在过拟合吗?"></a>无监督学习中存在过拟合吗?</h1><p>存在.<br>//TODO 补充  什么情况下会产生无监督的过拟合</p>
<h1 id="什么是K折交叉验证"><a href="#什么是K折交叉验证" class="headerlink" title="什么是K折交叉验证?"></a>什么是K折交叉验证?</h1><p>将原始数据集划分为k个子集, 将其中一个子集作为验证集, 其余k-1个子集作为训练集, 如此训练和验证一轮成为一次交叉验证. 交叉验证重复k此, 每个子集都会做一次验证, 最终得到k个模型, 然后可以对这k个模型的结果加权平均, 以作为评估整体模型的依据</p>
<h1 id="关于k折交叉验证-需要注意什么"><a href="#关于k折交叉验证-需要注意什么" class="headerlink" title="关于k折交叉验证, 需要注意什么?"></a>关于k折交叉验证, 需要注意什么?</h1><p>k越大, 不一定效果越好, 而且越大的k会加大训练时间;</p>
<p>在选择k时, 需要考虑最小化数据集之间的方差, 比如对于2分类任务, 如果采用2折交叉验证, 即对原始数据集二分,若此时训练集中都是A类别, 验证集中都是B类别, 则交叉验证效果会非常差</p>
<h1 id="对于一个二分类问题-我们定义超过阈值t的判定为正例-否则判定为负例-现在若将t增大-则准确率和召回率会如何变化"><a href="#对于一个二分类问题-我们定义超过阈值t的判定为正例-否则判定为负例-现在若将t增大-则准确率和召回率会如何变化" class="headerlink" title="对于一个二分类问题, 我们定义超过阈值t的判定为正例, 否则判定为负例. 现在若将t增大, 则准确率和召回率会如何变化?"></a>对于一个二分类问题, 我们定义超过阈值t的判定为正例, 否则判定为负例. 现在若将t增大, 则准确率和召回率会如何变化?</h1><p>准确率 = TP / (TP + FP), 召回率 = TP / (TP, FN)</p>
<p>若增大阈值t, 则更多不确定的样本将会被分为负例, 剩余确定样本的所占比例会增大, 那么准确率就会提升(或不变); 同时, 由于那些不确定的样本中还可能包含有正例, 引起, 阈值调大后, 这些正例就会被认为是负例, 所以召回率减小(或不变)</p>
<h1 id="增加网络层数-是否总能减小训练集错误率"><a href="#增加网络层数-是否总能减小训练集错误率" class="headerlink" title="增加网络层数, 是否总能减小训练集错误率?"></a>增加网络层数, 是否总能减小训练集错误率?</h1><p>不能, 有时候网络层数过深, 还会因为梯度消失导致模型退化, 使得模型性能降低</p>
<h1 id="在目标检测问题上-如何做数据增广"><a href="#在目标检测问题上-如何做数据增广" class="headerlink" title="在目标检测问题上, 如何做数据增广?"></a>在目标检测问题上, 如何做数据增广?</h1><h1 id="softmax怎么跟交叉熵损失函数结合"><a href="#softmax怎么跟交叉熵损失函数结合" class="headerlink" title="softmax怎么跟交叉熵损失函数结合?"></a>softmax怎么跟交叉熵损失函数结合?</h1><h1 id="用梯度下降训练神经网络的参数-为什么参数有时候会被训练为nan值"><a href="#用梯度下降训练神经网络的参数-为什么参数有时候会被训练为nan值" class="headerlink" title="用梯度下降训练神经网络的参数, 为什么参数有时候会被训练为nan值?"></a>用梯度下降训练神经网络的参数, 为什么参数有时候会被训练为nan值?</h1><p>输入数据本身存在nan值, 或者考虑是否梯度爆炸了(可以试着降低学习率, 或者利用截断法先知梯度的值)</p>
<h1 id="有没有自己试过更改模型的框架"><a href="#有没有自己试过更改模型的框架" class="headerlink" title="有没有自己试过更改模型的框架."></a>有没有自己试过更改模型的框架.</h1><p>有时候读paper会遇到一些好的点子或者方法, 自己会去加到现有的网络中去验证一下是不是能够提升模型的性能, 一般情况下, 比较经典且认可度较高的一些算法, 由于在网上都能找到相应的源码, 加上去的时候性能往往会有一点提升, 但是有时候有的方法比较偏, 我加完了以后有时候是没作用, 有时候是性能降低了, 我不知道到底是我实现的和paper有出入, 还是这个东西不适合当前框架</p>
<h1 id="说一下你所有的提高精度的方法-并且说明它们带来了多少的精度提升"><a href="#说一下你所有的提高精度的方法-并且说明它们带来了多少的精度提升" class="headerlink" title="说一下你所有的提高精度的方法, 并且说明它们带来了多少的精度提升!"></a>说一下你所有的提高精度的方法, 并且说明它们带来了多少的精度提升!</h1><p>OHEM ~3%</p>
<h1 id="SSD已经使用了难样例挖掘的技巧-Focal-Loss-相比之下为什么能够提高"><a href="#SSD已经使用了难样例挖掘的技巧-Focal-Loss-相比之下为什么能够提高" class="headerlink" title="SSD已经使用了难样例挖掘的技巧, Focal Loss 相比之下为什么能够提高"></a>SSD已经使用了难样例挖掘的技巧, Focal Loss 相比之下为什么能够提高</h1><h1 id="池化的优点-优化的缺点"><a href="#池化的优点-优化的缺点" class="headerlink" title="池化的优点, 优化的缺点"></a>池化的优点, 优化的缺点</h1><p>优点:</p>
<ul>
<li>显著减少参数数量, 降低过拟合</li>
<li>池化单元具有平移不变性</li>
</ul>
<p>缺点:<br>pooling能够增大感受野, 让后续的卷积看到更多的信息, 但是它在降维的过程中丢失了一些信息, 这对segmentation要求的精确location有一定的影响, 所以pooling层跟segmentation有一定的冲突, 但是感受野的增大有可以特征检测实例的准确率, 还可以降低计算量, 增强泛化能力. 所以这个是实例分割问题需要解决的一个关键点之一.</p>
<h1 id="待定"><a href="#待定" class="headerlink" title="待定"></a>待定</h1><p><a href="https://blog.csdn.net/comway_Li/article/details/82532573" target="_blank" rel="noopener">https://blog.csdn.net/comway_Li/article/details/82532573</a></p>
<h1 id="完善bisai待看"><a href="#完善bisai待看" class="headerlink" title="完善bisai待看"></a>完善bisai待看</h1><p><a href="https://www.kaggle.com/c/google-ai-open-images-object-detection-track/discussion/64986" target="_blank" rel="noopener">https://www.kaggle.com/c/google-ai-open-images-object-detection-track/discussion/64986</a></p>
<p><a href="https://arxiv.org/abs/1809.00778" target="_blank" rel="noopener">https://arxiv.org/abs/1809.00778</a></p>
<p><a href="https://www.kaggle.com/c/google-ai-open-images-object-detection-track/discussion" target="_blank" rel="noopener">https://www.kaggle.com/c/google-ai-open-images-object-detection-track/discussion</a></p>
<h1 id="谈谈你参加的比赛"><a href="#谈谈你参加的比赛" class="headerlink" title="谈谈你参加的比赛"></a>谈谈你参加的比赛</h1><p>对于一个比赛任务, 我会首先进行预处理,  之后, 会根据数据集的数据分布来对参数进行调整, 比如, 先只训练顶层, 然后逐步放开, 最后再训练所有层的参数.  在训练的时候,我一般都会采用bagging的思想, 将训练集随机28分, 分成3份, 然后训练, 最后进行模型融合,  融合的时候我一般都是对训练结果进行融合.</p>
<p>如果是目标检测累任务, 那么就:…</p>
<p>如果是实力分割类任务, 那么就:</p>
<h1 id="对于一个新任务-你一般都会使用那些数据预处理方法"><a href="#对于一个新任务-你一般都会使用那些数据预处理方法" class="headerlink" title="(对于一个新任务,) 你一般都会使用那些数据预处理方法"></a>(对于一个新任务,) 你一般都会使用那些数据预处理方法</h1><ol>
<li>训练数据可视化</li>
</ol>
<p>首先, 不论是什么样的数据集, 我都会先随机挑选 20 到 100张 的训练数据, 然后根据标签, 将图片数据可视化出来, 比如说如果是目标检测的任务, 我就会用opencv 的<code>cv2.rectangle()</code> 函数和 <code>cv2.putText()</code> 函数将标签里面的bbox标签和类别标签画到图片上去, 并且建立一个字典结构, 将不同的class-id对应到不同的颜色,  如果是实力分割任务, 我就会将mask标签反应到图片上去, 一般就是先将单通道的mask扩展成多通道的, 同时根据不同的class-id赋予不同的颜色, 最后利用numpy的where方法和原始图片进行叠加.  一般对于这种几十张的smaple图片, 我都是直接保存, 这样以后想再看的时候也不用重新跑脚本了.</p>
<p>之后, 我就会先简单浏览一下这些数据, 对整个数据集有一个初步的把握, 大概知道哪些物体被标注了, 有时候也能发现很多标注存在问题, 不过这也没有办法,  毕竟标注是一个很费时费力的工作, 错误在所难免.</p>
<ol>
<li>计算数据分布信息</li>
</ol>
<p>然后我就会写个脚本对整个数据集和标签进行遍历, 统计一些信息, 通常我会检测这么几个信息:</p>
<p>图像的平均尺寸, 整个数据集的像素平均值, 每张图片平均包含的目标个数, 每个类别的目标个数以及目标的平均大小,</p>
<p>同时, 因为平均值有时候往往反应不出来太多信息, 所以我还会用matplotlib把每种信息的直方图画出来, 然后看一下数据的整体分布是什么样子的, 比如图片size的分布, 目标大小的分布等等, 我主要就是根据这些分布信息来决定我最开始的参数设置.  主要调的参数就是imagesize,anchors相关的参数, 其他的还有就非极大抑制和置信度的阈值, 有时候还会试一下BN的作用(默认是关闭的)</p>
<p>然后一般情况下我都会对数据集做增广</p>
<p>常用的就是裁剪, 反转, 虚化, 颜色变换等等, 增广我不会做太多, 一般就用一些常用的增广方法</p>
<h1 id="比赛中用到的模型融合方法"><a href="#比赛中用到的模型融合方法" class="headerlink" title="比赛中用到的模型融合方法:"></a>比赛中用到的模型融合方法:</h1><p>对于目标检测任务:</p>
<p>我用的融合策略就是先以一个结果文件为基准, 然后用另一个结果文件里面的某张图片的框去跟前一个结果文件对应图片的所有框作比较, 因为之间会对框的面积做排序, 所以只与面积相似的框作比较, 看看框的位置是不是也相似, 如果相似, 就认为检测的是同一个物体, 然后就看他们的类别是否相同, 这里我一般会使用三个结果文件(来自于三个不同模型)进行投票选择.</p>
<p>对于有的框不在另一个文件的,  我就会根据框的置信度来设置一个阈值, 大于阈值的我就直接把框加进去, 如果有票数相同的, 就按置信度来区分.</p>
<h1 id="你的方法与其他人方法的区别是什么-为什么比别人的方法差"><a href="#你的方法与其他人方法的区别是什么-为什么比别人的方法差" class="headerlink" title="你的方法与其他人方法的区别是什么? 为什么比别人的方法差?"></a>你的方法与其他人方法的区别是什么? 为什么比别人的方法差?</h1><h1 id="对于faster-rcnn-你都调了哪些参数"><a href="#对于faster-rcnn-你都调了哪些参数" class="headerlink" title="对于faster rcnn 你都调了哪些参数?"></a>对于faster rcnn 你都调了哪些参数?</h1><p>首先调的是anchor相关参数, 比如anchor size 和 anchor ratio</p>
<p>然后是学习率, 前景后景的样本比例, 非极大抑制的阈值, 候选区域块的生成个数, 图片的缩放尺度等等</p>
<h1 id="BN具体是什么实现的"><a href="#BN具体是什么实现的" class="headerlink" title="BN具体是什么实现的"></a>BN具体是什么实现的</h1><h1 id="对于平均移动了解吗"><a href="#对于平均移动了解吗" class="headerlink" title="对于平均移动了解吗"></a>对于平均移动了解吗</h1><h1 id="积分图-快速求矩阵的核"><a href="#积分图-快速求矩阵的核" class="headerlink" title="积分图, 快速求矩阵的核"></a>积分图, 快速求矩阵的核</h1><h1 id="样本不均衡问题怎么解决"><a href="#样本不均衡问题怎么解决" class="headerlink" title="样本不均衡问题怎么解决"></a>样本不均衡问题怎么解决</h1><h1 id="详细说一下Focal-Loss"><a href="#详细说一下Focal-Loss" class="headerlink" title="详细说一下Focal Loss"></a>详细说一下Focal Loss</h1><h1 id="说一下为什么Faster-比YOLO和SSD更准确"><a href="#说一下为什么Faster-比YOLO和SSD更准确" class="headerlink" title="说一下为什么Faster 比YOLO和SSD更准确"></a>说一下为什么Faster 比YOLO和SSD更准确</h1><h1 id="样本采样的理论化值是"><a href="#样本采样的理论化值是" class="headerlink" title="样本采样的理论化值是"></a>样本采样的理论化值是</h1><h1 id="anchor的参数设值怎么选的？-为什么这么设置"><a href="#anchor的参数设值怎么选的？-为什么这么设置" class="headerlink" title="anchor的参数设值怎么选的？  为什么这么设置"></a>anchor的参数设值怎么选的？  为什么这么设置</h1><h1 id="在调试RPN网络时有没有遇到什么问题？"><a href="#在调试RPN网络时有没有遇到什么问题？" class="headerlink" title="在调试RPN网络时有没有遇到什么问题？"></a>在调试RPN网络时有没有遇到什么问题？</h1><h1 id="简述一下faster-rcnn模型"><a href="#简述一下faster-rcnn模型" class="headerlink" title="简述一下faster rcnn模型"></a>简述一下faster rcnn模型</h1><h1 id="简述一下ResNet模型及它解决的问题"><a href="#简述一下ResNet模型及它解决的问题" class="headerlink" title="简述一下ResNet模型及它解决的问题"></a>简述一下ResNet模型及它解决的问题</h1><h1 id="如何优化CNN-Backbone"><a href="#如何优化CNN-Backbone" class="headerlink" title="如何优化CNN Backbone"></a>如何优化CNN Backbone</h1><p>我们在DataParallel的语境下面讨论这个问题。也就是说，每张显卡都保存一份参数全集，一份数据+数据形成FeatureMap的子集。</p>
<p>我们知道，就像组装深度学习服务器一样，你的预算一定的条件下，如何搭配一台服务器才能让CPU对数据预处理够用、内存加载数据够用、硬盘I/O够用，以及最重要的是，选择一块好的GPU卡。资源不是无限的。这其实是一个线性规划问题。在这里不赘述。</p>
<p>进行CNN Backbone优化同样有这个问题：</p>
<h1 id="你的显存利用率和GPU算力利用率如何达到最高？"><a href="#你的显存利用率和GPU算力利用率如何达到最高？" class="headerlink" title="你的显存利用率和GPU算力利用率如何达到最高？"></a>你的显存利用率和GPU算力利用率如何达到最高？</h1><p>降低Batch-size会减小Feature Map占用缓存，但收敛情况怎么样，可能饮鸩止渴。<br>加宽直接影响参数数量。<br>加深不仅影响参数数量还影响Feature Map大小。<br>分组极大节省参数，甚至还能提高效果。<br>结构复用、压缩节省参数，增加计算量。<br>特征拼接、高阶操作降低并行效率，尤其不是inplace的那种。在动态图框架尤为如此。<br>Bilinear大量使用额外参数。<br>非对称带来额外的代码工作。<br>任何新颖结构的引入带来非连续超参，让模型BP，让超参优化无B可P。<br>如何提高CNN Backbone设计品位？<br>美就是简单<br>美就是复用<br>美就是对称<br>美就是分形<br>Inception-ResNet.v2干不过ResNeXt，我一点都不意外。<br>Mask-RCNN标配ResNeXt101 Backbone，我一点都不意外。</p>
<h1 id="为什么要压缩模型，而不是直接训练一个小模型"><a href="#为什么要压缩模型，而不是直接训练一个小模型" class="headerlink" title="为什么要压缩模型，而不是直接训练一个小模型"></a>为什么要压缩模型，而不是直接训练一个小模型</h1><p><a href="https://www.zhihu.com/question/303922732/answer/541660954" target="_blank" rel="noopener">https://www.zhihu.com/question/303922732/answer/541660954</a></p>
<h1 id="分类问题为什么使用交叉熵损失函数-而不是平方误差"><a href="#分类问题为什么使用交叉熵损失函数-而不是平方误差" class="headerlink" title="分类问题为什么使用交叉熵损失函数, 而不是平方误差"></a>分类问题为什么使用交叉熵损失函数, 而不是平方误差</h1><p>神经网络中如果预测值与实际值的误差越大，那么在反向传播训练的过程中，各种参数调整的幅度就要更大，从而使训练更快收敛；如果预测值与实际值的误差小，各种参数调整的幅度就要小，从而减少震荡。</p>
<p>使用平方误差损失函数，误差增大参数的梯度会增大，但是当误差很大时，参数的梯度就会又减小了。</p>
<p>使用交叉熵损失函数，误差越大参数的梯度也越大，能够快速收敛。</p>
<h1 id="你知道-mixed-precision-training-吗"><a href="#你知道-mixed-precision-training-吗" class="headerlink" title="你知道 mixed precision training 吗?"></a>你知道 mixed precision training 吗?</h1><h1 id="手写-K-Means-伪代码"><a href="#手写-K-Means-伪代码" class="headerlink" title="手写 K-Means 伪代码"></a>手写 K-Means 伪代码</h1><h1 id="Adam-优化器的迭代公式"><a href="#Adam-优化器的迭代公式" class="headerlink" title="Adam 优化器的迭代公式"></a>Adam 优化器的迭代公式</h1><h1 id="找完全二叉树的最后一个节点"><a href="#找完全二叉树的最后一个节点" class="headerlink" title="找完全二叉树的最后一个节点"></a>找完全二叉树的最后一个节点</h1><h1 id="手推两层神经网络的反向传播"><a href="#手推两层神经网络的反向传播" class="headerlink" title="手推两层神经网络的反向传播"></a>手推两层神经网络的反向传播</h1><h1 id="其他的例如softmax与cross-entropy的推导，过拟合与正则化，BiLSTM，Gradient-Explosion，Top-N，特征选择都是常规问题就不仔细说了。"><a href="#其他的例如softmax与cross-entropy的推导，过拟合与正则化，BiLSTM，Gradient-Explosion，Top-N，特征选择都是常规问题就不仔细说了。" class="headerlink" title="其他的例如softmax与cross entropy的推导，过拟合与正则化，BiLSTM，Gradient Explosion，Top N，特征选择都是常规问题就不仔细说了。"></a>其他的例如softmax与cross entropy的推导，过拟合与正则化，BiLSTM，Gradient Explosion，Top N，特征选择都是常规问题就不仔细说了。</h1><h1 id="2020-秋招时间表"><a href="#2020-秋招时间表" class="headerlink" title="2020 秋招时间表"></a>2020 秋招时间表</h1><ul>
<li>依图<ul>
<li>内推: 7.16~8~16</li>
</ul>
</li>
<li>图森:<ul>
<li>内推: ~7.31</li>
<li>秋招: 8月起</li>
</ul>
</li>
<li>360:<ul>
<li>内推: ~8.12</li>
</ul>
</li>
</ul>

      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/z_post/面试-数学题/" rel="prev" title="数学题">
                <i class="fa fa-chevron-left"></i> 数学题
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/z_post/计算机视觉-SSD-ECCV2016/" rel="next" title="SSD-Single Shot MultiBox Detector">
                SSD-Single Shot MultiBox Detector <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          

  
    <div class="comments" id="comments">
    </div>
  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/avatar_zz.png"
                alt="ZeroZone" />
            
              <p class="site-author-name" itemprop="name">ZeroZone</p>
              <p class="site-description motion-element" itemprop="description">吾乃闪耀的芝士蛋挞!</p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">268</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  <a href="/categories/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">13</span>
                    <span class="site-state-item-name">分类</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  <a href="/tags/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">41</span>
                    <span class="site-state-item-name">标签</span>
                  </a>
                </div>
              
            </nav>
          

          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  <a href="https://github.com/hellozhaozheng" target="_blank" title="GitHub"><i class="fa fa-fw fa-github"></i>GitHub</a>
                  
                </span>
              
                <span class="links-of-author-item">
                  <a href="mailto:hellozhaozheng@foxmail.com" target="_blank" title="E-Mail"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  
                </span>
              
            </div>
          

          
          

          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-block">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-link"></i>
                友情链接
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="https://blog.csdn.net/ksws0292756" title="零域CSDN博客" target="_blank">零域CSDN博客</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://xinghanzzy.github.io/" title="BoXiao的博客" target="_blank">BoXiao的博客</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://oldpan.me/" title="Oldpan的博客" target="_blank">Oldpan的博客</a>
                  </li>
                
              </ul>
            </div>
          

          
            
          
          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#商汤面经"><span class="nav-text">商汤面经</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#商汤"><span class="nav-text">商汤</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#其他"><span class="nav-text">其他</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#优秀面经"><span class="nav-text">优秀面经</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#在多线程和大量并发环境下，如果有一个平均运行一百万次出现一次的bug，-你如何调试这个bug。"><span class="nav-text">在多线程和大量并发环境下，如果有一个平均运行一百万次出现一次的bug， 你如何调试这个bug。</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#这个bug很难重现，这个时候你要怎么处理或者重现呢。"><span class="nav-text">这个bug很难重现，这个时候你要怎么处理或者重现呢。</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#有一个类指针，指向类实例化的对象，在这个对象程序的运行过程中，程序崩溃了，后来发现是这个类指针的虚函数表被破坏了，现在如何定位这个问题。"><span class="nav-text">有一个类指针，指向类实例化的对象，在这个对象程序的运行过程中，程序崩溃了，后来发现是这个类指针的虚函数表被破坏了，现在如何定位这个问题。</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#模型压缩"><span class="nav-text">模型压缩</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#cuda"><span class="nav-text">cuda</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#face-面经"><span class="nav-text">face++ 面经</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#待看"><span class="nav-text">待看</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#字节跳动提前批"><span class="nav-text">字节跳动提前批</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#本人研究方向是NLP，面的是AILab语音部门（前期负责语音组的NLP任务，后期慢慢接手语音相关任务）"><span class="nav-text">本人研究方向是NLP，面的是AILab语音部门（前期负责语音组的NLP任务，后期慢慢接手语音相关任务）</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#未整理的问题"><span class="nav-text">未整理的问题</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#逻辑回归"><span class="nav-text">逻辑回归</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#线性回归和逻辑回归的原理和区别"><span class="nav-text">线性回归和逻辑回归的原理和区别</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#在Faster-RCNN中-如果两个物体重合度很高-会怎么样"><span class="nav-text">在Faster RCNN中, 如果两个物体重合度很高, 会怎么样</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#卷积神经网络复杂度分析"><span class="nav-text">卷积神经网络复杂度分析</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#卷积计算-卷积层特参数个数及征图谱尺寸计算"><span class="nav-text">卷积计算,卷积层特参数个数及征图谱尺寸计算</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#L2正则化和L2规范化-归一化-的不同"><span class="nav-text">L2正则化和L2规范化(归一化)的不同</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#从-rcnn-到-faster"><span class="nav-text">从 rcnn 到 faster</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#为什么fast-rcnn的roi-pooling比spp的-spatial-pooling效果好"><span class="nav-text">为什么fast rcnn的roi pooling比spp的 spatial pooling效果好???</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#神经网络参数初始化"><span class="nav-text">神经网络参数初始化</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#分类问题为什么用交叉熵"><span class="nav-text">分类问题为什么用交叉熵</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Relu和Dropout都具有正则化作用-它们在正则化方面的区别是什么"><span class="nav-text">Relu和Dropout都具有正则化作用, 它们在正则化方面的区别是什么?</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#介绍一下-hard-negative-mining-难样例挖掘"><span class="nav-text">介绍一下 hard negative mining(难样例挖掘)</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#dropout内部是怎么实现的"><span class="nav-text">dropout内部是怎么实现的</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#简述一下BN"><span class="nav-text">简述一下BN</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#各种初始化方式，及公式各个参数对训练的影响"><span class="nav-text">各种初始化方式，及公式各个参数对训练的影响</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#目标检测，数据不平衡问题怎么解决"><span class="nav-text">目标检测，数据不平衡问题怎么解决</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#你的zerotensor和TF比性能上有优势吗"><span class="nav-text">你的zerotensor和TF比性能上有优势吗</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#常用的数据增强技术"><span class="nav-text">常用的数据增强技术</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#有哪些可以避免过拟合的办法"><span class="nav-text">有哪些可以避免过拟合的办法</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#正则化L1和L2的区别"><span class="nav-text">正则化L1和L2的区别</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#rcnn。。"><span class="nav-text">rcnn。。</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#推导svm"><span class="nav-text">推导svm</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#卷积层的参数个数计算公式是："><span class="nav-text">卷积层的参数个数计算公式是：</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#梯度消失和梯度爆炸的概念，引用这两个现象的原因及其解决办法"><span class="nav-text">梯度消失和梯度爆炸的概念，引用这两个现象的原因及其解决办法</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#关于各种激活函数的解析与讨论"><span class="nav-text">关于各种激活函数的解析与讨论</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#简述ResNet"><span class="nav-text">简述ResNet</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#嵌入式开发很底层-一般还是倾向于做一些上层的东西"><span class="nav-text">嵌入式开发很底层   一般还是倾向于做一些上层的东西</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#推导SVM"><span class="nav-text">推导SVM</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#比较Boosting和Bagging的异同"><span class="nav-text">比较Boosting和Bagging的异同</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#无监督学习中存在过拟合吗"><span class="nav-text">无监督学习中存在过拟合吗?</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#什么是K折交叉验证"><span class="nav-text">什么是K折交叉验证?</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#关于k折交叉验证-需要注意什么"><span class="nav-text">关于k折交叉验证, 需要注意什么?</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#对于一个二分类问题-我们定义超过阈值t的判定为正例-否则判定为负例-现在若将t增大-则准确率和召回率会如何变化"><span class="nav-text">对于一个二分类问题, 我们定义超过阈值t的判定为正例, 否则判定为负例. 现在若将t增大, 则准确率和召回率会如何变化?</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#增加网络层数-是否总能减小训练集错误率"><span class="nav-text">增加网络层数, 是否总能减小训练集错误率?</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#在目标检测问题上-如何做数据增广"><span class="nav-text">在目标检测问题上, 如何做数据增广?</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#softmax怎么跟交叉熵损失函数结合"><span class="nav-text">softmax怎么跟交叉熵损失函数结合?</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#用梯度下降训练神经网络的参数-为什么参数有时候会被训练为nan值"><span class="nav-text">用梯度下降训练神经网络的参数, 为什么参数有时候会被训练为nan值?</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#有没有自己试过更改模型的框架"><span class="nav-text">有没有自己试过更改模型的框架.</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#说一下你所有的提高精度的方法-并且说明它们带来了多少的精度提升"><span class="nav-text">说一下你所有的提高精度的方法, 并且说明它们带来了多少的精度提升!</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#SSD已经使用了难样例挖掘的技巧-Focal-Loss-相比之下为什么能够提高"><span class="nav-text">SSD已经使用了难样例挖掘的技巧, Focal Loss 相比之下为什么能够提高</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#池化的优点-优化的缺点"><span class="nav-text">池化的优点, 优化的缺点</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#待定"><span class="nav-text">待定</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#完善bisai待看"><span class="nav-text">完善bisai待看</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#谈谈你参加的比赛"><span class="nav-text">谈谈你参加的比赛</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#对于一个新任务-你一般都会使用那些数据预处理方法"><span class="nav-text">(对于一个新任务,) 你一般都会使用那些数据预处理方法</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#比赛中用到的模型融合方法"><span class="nav-text">比赛中用到的模型融合方法:</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#你的方法与其他人方法的区别是什么-为什么比别人的方法差"><span class="nav-text">你的方法与其他人方法的区别是什么? 为什么比别人的方法差?</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#对于faster-rcnn-你都调了哪些参数"><span class="nav-text">对于faster rcnn 你都调了哪些参数?</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#BN具体是什么实现的"><span class="nav-text">BN具体是什么实现的</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#对于平均移动了解吗"><span class="nav-text">对于平均移动了解吗</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#积分图-快速求矩阵的核"><span class="nav-text">积分图, 快速求矩阵的核</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#样本不均衡问题怎么解决"><span class="nav-text">样本不均衡问题怎么解决</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#详细说一下Focal-Loss"><span class="nav-text">详细说一下Focal Loss</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#说一下为什么Faster-比YOLO和SSD更准确"><span class="nav-text">说一下为什么Faster 比YOLO和SSD更准确</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#样本采样的理论化值是"><span class="nav-text">样本采样的理论化值是</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#anchor的参数设值怎么选的？-为什么这么设置"><span class="nav-text">anchor的参数设值怎么选的？  为什么这么设置</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#在调试RPN网络时有没有遇到什么问题？"><span class="nav-text">在调试RPN网络时有没有遇到什么问题？</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#简述一下faster-rcnn模型"><span class="nav-text">简述一下faster rcnn模型</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#简述一下ResNet模型及它解决的问题"><span class="nav-text">简述一下ResNet模型及它解决的问题</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#如何优化CNN-Backbone"><span class="nav-text">如何优化CNN Backbone</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#你的显存利用率和GPU算力利用率如何达到最高？"><span class="nav-text">你的显存利用率和GPU算力利用率如何达到最高？</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#为什么要压缩模型，而不是直接训练一个小模型"><span class="nav-text">为什么要压缩模型，而不是直接训练一个小模型</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#分类问题为什么使用交叉熵损失函数-而不是平方误差"><span class="nav-text">分类问题为什么使用交叉熵损失函数, 而不是平方误差</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#你知道-mixed-precision-training-吗"><span class="nav-text">你知道 mixed precision training 吗?</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#手写-K-Means-伪代码"><span class="nav-text">手写 K-Means 伪代码</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Adam-优化器的迭代公式"><span class="nav-text">Adam 优化器的迭代公式</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#找完全二叉树的最后一个节点"><span class="nav-text">找完全二叉树的最后一个节点</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#手推两层神经网络的反向传播"><span class="nav-text">手推两层神经网络的反向传播</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#其他的例如softmax与cross-entropy的推导，过拟合与正则化，BiLSTM，Gradient-Explosion，Top-N，特征选择都是常规问题就不仔细说了。"><span class="nav-text">其他的例如softmax与cross entropy的推导，过拟合与正则化，BiLSTM，Gradient Explosion，Top N，特征选择都是常规问题就不仔细说了。</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#2020-秋招时间表"><span class="nav-text">2020 秋招时间表</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      
        <div class="back-to-top">
          <i class="fa fa-arrow-up"></i>
          
        </div>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2017 &mdash; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">ZeroZone</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
    <span title="站点总字数">2.7m</span>
  

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    
    <span title="站点阅读时长">41:12</span>
  
</div>










  <div class="footer-custom">勤练带来力量</div>


        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv" title="总访客量">
      <i class="fa fa-user"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
    </span>
  

  
    <span class="site-pv" title="总访问量">
      <i class="fa fa-eye"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
    </span>
  
</div>









        
      </div>
    </footer>

    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>












  















  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=6.3.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=6.3.0"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=6.3.0"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=6.3.0"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=6.3.0"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=6.3.0"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=6.3.0"></script>



  



  





  








  <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
  
  
  <script src="//unpkg.com/valine/dist/Valine.min.js"></script>
  
  <script type="text/javascript">
    var GUEST = ['nick','mail','link'];
    var guest = 'nick,mail';
    guest = guest.split(',').filter(function (item) {
      return GUEST.indexOf(item)>-1;
    });
    new Valine({
        el: '#comments' ,
        verify: false,
        notify: true,
        appId: 'o5ny24Rtrv0pjlRYjBoj9rfz-gzGzoHsz',
        appKey: 'o9SAGYkO04n5xjXkeWXaq1pm',
        placeholder: '无需注册即可评论, 支持在 Gravatar(https://cn.gravatar.com) 上自定义头像, 评论时只需填写对应邮箱即可显示自定义头像, 邮箱不会暴露在评论处, 大可放心, 由于无登陆选项, 因此邮箱会作为我联系你的唯一方式',
        avatar:'',
        guest_info:guest,
        pageSize:'10' || 10,
    });
  </script>



  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>





  
  

  
  

  
    
      <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      },
      TeX: {equationNumbers: { autoNumber: "AMS" }}
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<script type="text/javascript" src="//cdn.jsdelivr.net/npm/mathjax@2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

    
  


  
  

  

  

  

  

  
  <style>
    .copy-btn {
      display: inline-block;
      padding: 6px 12px;
      font-size: 13px;
      font-weight: 700;
      line-height: 20px;
      color: #333;
      white-space: nowrap;
      vertical-align: middle;
      cursor: pointer;
      background-color: #eee;
      background-image: linear-gradient(#fcfcfc, #eee);
      border: 1px solid #d5d5d5;
      border-radius: 3px;
      user-select: none;
      outline: 0;
    }

    .highlight-wrap .copy-btn {
      transition: opacity .3s ease-in-out;
      opacity: 0;
      padding: 2px 6px;
      position: absolute;
      right: 4px;
      top: 8px;
    }

    .highlight-wrap:hover .copy-btn,
    .highlight-wrap .copy-btn:focus {
      opacity: 1
    }

    .highlight-wrap {
      position: relative;
    }
  </style>
  <script>
    $('.highlight').each(function (i, e) {
      var $wrap = $('<div>').addClass('highlight-wrap')
      $(e).after($wrap)
      $wrap.append($('<button>').addClass('copy-btn').append('复制').on('click', function (e) {
        var code = $(this).parent().find('.code').find('.line').map(function (i, e) {
          return $(e).text()
        }).toArray().join('\n')
        var ta = document.createElement('textarea')
        document.body.appendChild(ta)
        ta.style.position = 'absolute'
        ta.style.top = '0px'
        ta.style.left = '0px'
        ta.value = code
        ta.select()
        ta.focus()
        var result = document.execCommand('copy')
        document.body.removeChild(ta)
        
        $(this).blur()
      })).on('mouseleave', function (e) {
        var $b = $(this).find('.copy-btn')
        setTimeout(function () {
          $b.text('复制')
        }, 300)
      }).append(e)
    })
  </script>


</body>
</html>
