<!DOCTYPE html>













<html class="theme-next gemini" lang="zh-CN">
<head>
  <meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=2"/>
<meta name="theme-color" content="#222">

<meta name="google-site-verification" content="jgw73iXouBAJcOuff0yi9vdSNDecBSOUXacsHJszpmo" />
<meta name="baidu-site-verification" content="xyf9WD2vvl" />











<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=6.3.0" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=6.3.0">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=6.3.0">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=6.3.0">


  <link rel="mask-icon" href="/images/apple-icon-57x57.png?v=6.3.0" color="#222">









<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Gemini',
    version: '6.3.0',
    sidebar: {"position":"left","display":"post","offset":12,"b2t":true,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    fastclick: false,
    lazyload: false,
    tabs: true,
    motion: {"enable":false,"async":false,"transition":{"post_body":"slideDownIn"}},
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>


  




  <meta name="description" content="总目录篇机器学习: 逻辑回归, 支持向量机, 决策树, 降维, 聚类 深度学习: 优化方法, 初始化方法, 损失函数, 激活函数, 正则化, 归一化, 感受野, 全连接层, 卷积层, 反卷积层, 池化层, 训练问题 网络结构: AlexNet, VGGNet, InceptionV1, InceptionV2, InceptionV3, InceptionV4, Xception, ResNet,">
<meta name="keywords" content="知识点梳理,计算机视觉,面试">
<meta property="og:type" content="article">
<meta property="og:title" content="【置顶】计算机视觉知识点总结">
<meta property="og:url" content="https://hellozhaozheng.github.io/z_post/面试-计算机视觉知识点总结/index.html">
<meta property="og:site_name" content="从零开始的BLOG">
<meta property="og:description" content="总目录篇机器学习: 逻辑回归, 支持向量机, 决策树, 降维, 聚类 深度学习: 优化方法, 初始化方法, 损失函数, 激活函数, 正则化, 归一化, 感受野, 全连接层, 卷积层, 反卷积层, 池化层, 训练问题 网络结构: AlexNet, VGGNet, InceptionV1, InceptionV2, InceptionV3, InceptionV4, Xception, ResNet,">
<meta property="og:locale" content="zh-CN">
<meta property="og:image" content="http://zerozone-blog.oss-cn-beijing.aliyuncs.com/SummaryOfComputerVision/PR.jpg?x-oss-process=style/blog_img">
<meta property="og:image" content="http://zerozone-blog.oss-cn-beijing.aliyuncs.com/SummaryOfComputerVision/ROC.jpg?x-oss-process=style/blog_img">
<meta property="og:image" content="http://zerozone-blog.oss-cn-beijing.aliyuncs.com/SummaryOfComputerVision/auc1.jpg?x-oss-process=style/blog_img">
<meta property="og:image" content="http://zerozone-blog.oss-cn-beijing.aliyuncs.com/SummaryOfComputerVision/auc2.jpg?x-oss-process=style/blog_img">
<meta property="og:image" content="http://zerozone-blog.oss-cn-beijing.aliyuncs.com/SummaryOfComputerVision/kmeans.jpg?x-oss-process=style/blog_img">
<meta property="og:image" content="http://zerozone-blog.oss-cn-beijing.aliyuncs.com/SummaryOfComputerVision/optim1.gif">
<meta property="og:image" content="http://zerozone-blog.oss-cn-beijing.aliyuncs.com/SummaryOfComputerVision/optim2.gif">
<meta property="og:image" content="http://zerozone-blog.oss-cn-beijing.aliyuncs.com/SummaryOfComputerVision/adam_vs_sgd.jpg?x-oss-process=style/blog_img">
<meta property="og:image" content="http://zerozone-blog.oss-cn-beijing.aliyuncs.com/SummaryOfComputerVision/adam.png?x-oss-process=style/blog_img">
<meta property="og:image" content="http://zerozone-blog.oss-cn-beijing.aliyuncs.com/SummaryOfComputerVision/act_sigmoid.jpg?x-oss-process=style/blog_img">
<meta property="og:image" content="http://zerozone-blog.oss-cn-beijing.aliyuncs.com/SummaryOfComputerVision/act_tanh.jpg?x-oss-process=style/blog_img">
<meta property="og:image" content="http://zerozone-blog.oss-cn-beijing.aliyuncs.com/SummaryOfComputerVision/act_relu.jpg?x-oss-process=style/blog_img">
<meta property="og:image" content="http://zerozone-blog.oss-cn-beijing.aliyuncs.com/SummaryOfComputerVision/act_leaky_relu.jpg?x-oss-process=style/blog_img">
<meta property="og:image" content="http://zerozone-blog.oss-cn-beijing.aliyuncs.com/SummaryOfComputerVision/act_prelu.jpg?x-oss-process=style/blog_img">
<meta property="og:image" content="http://zerozone-blog.oss-cn-beijing.aliyuncs.com/SummaryOfComputerVision/act_rrelu.jpg?x-oss-process=style/blog_img">
<meta property="og:image" content="http://zerozone-blog.oss-cn-beijing.aliyuncs.com/SummaryOfComputerVision/act_elu.jpg?x-oss-process=style/blog_img">
<meta property="og:image" content="http://zerozone-blog.oss-cn-beijing.aliyuncs.com/SummaryOfComputerVision/xor.jpg?x-oss-process=style/blog_img">
<meta property="og:image" content="http://zerozone-blog.oss-cn-beijing.aliyuncs.com/SummaryOfComputerVision/l1l2_1.jpg?x-oss-process=style/blog_img">
<meta property="og:image" content="http://zerozone-blog.oss-cn-beijing.aliyuncs.com/SummaryOfComputerVision/l1l2_2.jpg?x-oss-process=style/blog_img">
<meta property="og:image" content="https://wx2.sinaimg.cn/large/d7b90c85ly1fww4hqied3j21kw0esjwt.jpg">
<meta property="og:image" content="http://zerozone-blog.oss-cn-beijing.aliyuncs.com/SummaryOfComputerVision/pool_1.jpg?x-oss-process=style/blog_img">
<meta property="og:image" content="http://zerozone-blog.oss-cn-beijing.aliyuncs.com/SummaryOfComputerVision/pool_2.jpg?x-oss-process=style/blog_img">
<meta property="og:image" content="https://wx2.sinaimg.cn/large/d7b90c85ly1g0ixnfk7w4j20o408q3yr.jpg">
<meta property="og:image" content="https://wx4.sinaimg.cn/large/d7b90c85ly1fxmo2fpvavj21650u079w.jpg">
<meta property="og:image" content="https://wx2.sinaimg.cn/large/d7b90c85ly1g1g5nupi5fj21c80u0doq.jpg">
<meta property="og:image" content="https://wx2.sinaimg.cn/large/d7b90c85ly1g1g6on0w08j21hc0u0b29.jpg">
<meta property="og:image" content="https://wx1.sinaimg.cn/large/d7b90c85ly1g1g6orzjmmj21hc0u0b29.jpg">
<meta property="og:image" content="https://wx1.sinaimg.cn/large/d7b90c85ly1g1g6ox6512j21hc0u0e81.jpg">
<meta property="og:image" content="https://wx3.sinaimg.cn/large/d7b90c85ly1fxc7ewvfr1j20u00wn0y7.jpg">
<meta property="og:image" content="https://wx1.sinaimg.cn/large/d7b90c85ly1fxc7gghlzjj21xt0l1n26.jpg">
<meta property="og:image" content="https://wx1.sinaimg.cn/large/d7b90c85ly1fxsf9g1udsj21q00s3152.jpg">
<meta property="og:image" content="https://wx2.sinaimg.cn/large/d7b90c85ly1fx1toyw0xkj20kc0a5wkw.jpg">
<meta property="og:image" content="https://wx3.sinaimg.cn/large/d7b90c85ly1g1hbfdtyvcj21dg0m6ta3.jpg">
<meta property="og:image" content="http://zerozone-blog.oss-cn-beijing.aliyuncs.com/SummaryOfComputerVision/gpu_nvidia-smi.jpg?x-oss-process=style/blog_img">
<meta property="og:image" content="http://zerozone-blog.oss-cn-beijing.aliyuncs.com/SummaryOfComputerVision/gpu_bottle.jpg?x-oss-process=style/blog_img">
<meta property="og:image" content="http://zerozone-blog.oss-cn-beijing.aliyuncs.com/SummaryOfComputerVision/gpu_RooflineModel.jpg?x-oss-process=style/blog_img">
<meta property="og:image" content="http://zerozone-blog.oss-cn-beijing.aliyuncs.com/SummaryOfComputerVision/gpu_RooflineModel2.png?x-oss-process=style/blog_img">
<meta property="og:image" content="https://hellozhaozheng.github.io/z_post/面试-计算机视觉知识点总结/Batch-Normalization深入解析">
<meta property="og:updated_time" content="2019-07-28T14:35:55.512Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="【置顶】计算机视觉知识点总结">
<meta name="twitter:description" content="总目录篇机器学习: 逻辑回归, 支持向量机, 决策树, 降维, 聚类 深度学习: 优化方法, 初始化方法, 损失函数, 激活函数, 正则化, 归一化, 感受野, 全连接层, 卷积层, 反卷积层, 池化层, 训练问题 网络结构: AlexNet, VGGNet, InceptionV1, InceptionV2, InceptionV3, InceptionV4, Xception, ResNet,">
<meta name="twitter:image" content="http://zerozone-blog.oss-cn-beijing.aliyuncs.com/SummaryOfComputerVision/PR.jpg?x-oss-process=style/blog_img">






  <link rel="canonical" href="https://hellozhaozheng.github.io/z_post/面试-计算机视觉知识点总结/"/>



<script type="text/javascript" id="page.configurations">
  CONFIG.page = {
    sidebar: "",
  };
</script>

  <title>【置顶】计算机视觉知识点总结 | 从零开始的BLOG</title>
  






  <script type="text/javascript">
    var _hmt = _hmt || [];
    (function() {
      var hm = document.createElement("script");
      hm.src = "https://hm.baidu.com/hm.js?21a4899cc63d3c11a3d90ac58074a19c";
      var s = document.getElementsByTagName("script")[0];
      s.parentNode.insertBefore(hm, s);
    })();
  </script>




  <noscript>
  <style type="text/css">
    .use-motion .motion-element,
    .use-motion .brand,
    .use-motion .menu-item,
    .sidebar-inner,
    .use-motion .post-block,
    .use-motion .pagination,
    .use-motion .comments,
    .use-motion .post-header,
    .use-motion .post-body,
    .use-motion .collection-title { opacity: initial; }

    .use-motion .logo,
    .use-motion .site-title,
    .use-motion .site-subtitle {
      opacity: initial;
      top: initial;
    }

    .use-motion {
      .logo-line-before i { left: initial; }
      .logo-line-after i { right: initial; }
    }
  </style>
</noscript>

</head>

<body itemscope itemtype="http://schema.org/WebPage" lang="zh-CN">

  
  
    
  

  <div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/" class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">从零开始的BLOG</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
    
      
        <p class="site-subtitle">与其感慨路难行，不如马上出发</p>
      
    
  </div>

  <div class="site-nav-toggle">
    <button aria-label="切换导航栏">
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>



<nav class="site-nav">
  
    <ul id="menu" class="menu">
      
        
        
        
          
          <li class="menu-item menu-item-home">
    <a href="/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-home"></i> <br />首页</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-archives">
    <a href="/archives/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />归档<span class="badge">268</span></a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-计算机视觉">
    <a href="/categories/计算机视觉/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-tripadvisor"></i> <br />计算机视觉</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-深度学习">
    <a href="/categories/深度学习/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-drupal"></i> <br />深度学习</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-caffe2">
    <a href="/categories/Caffe2/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-coffee"></i> <br />Caffe2</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-pytorch">
    <a href="/categories/PyTorch/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-free-code-camp"></i> <br />PyTorch</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-c++">
    <a href="/categories/Cpp/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-codiepie"></i> <br />C++</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-python">
    <a href="/categories/Python/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-product-hunt"></i> <br />Python</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-项目">
    <a href="/categories/项目/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-connectdevelop"></i> <br />项目</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-cuda">
    <a href="/categories/CUDA/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-braille"></i> <br />CUDA</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-其他">
    <a href="/categories/其他/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-th"></i> <br />其他</a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-tags">
    <a href="/tags/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />标签<span class="badge">41</span></a>
  </li>
        
        
        
          
          <li class="menu-item menu-item-about">
    <a href="/about/" rel="section">
      <i class="menu-item-icon fa fa-fw fa-user"></i> <br />关于我</a>
  </li>

      
      
        <li class="menu-item menu-item-search">
          
            <a href="javascript:;" class="popup-trigger">
          
            
              <i class="menu-item-icon fa fa-search fa-fw"></i> <br />站内搜索(首次加载需3~5秒)</a>
        </li>
      
    </ul>
  

  

  
    <div class="site-search">
      
  <div class="popup search-popup local-search-popup">
  <div class="local-search-header clearfix">
    <span class="search-icon">
      <i class="fa fa-search"></i>
    </span>
    <span class="popup-btn-close">
      <i class="fa fa-times-circle"></i>
    </span>
    <div class="local-search-input-wrapper">
      <input autocomplete="off"
             placeholder="站内搜索..." spellcheck="false"
             type="text" id="local-search-input">
    </div>
  </div>
  <div id="local-search-result"></div>
</div>



    </div>
  
</nav>



  



</div>
    </header>

    
  
  
  
    
      
    
    <a href="https://github.com/hellozhaozheng" class="github-corner" target="_blank" title="Follow me on GitHub" aria-label="Follow me on GitHub"><svg width="80" height="80" viewBox="0 0 250 250" style="fill:#222; color:#fff; position: absolute; top: 0; border: 0; right: 0;" aria-hidden="true"><path d="M0,0 L115,115 L130,115 L142,142 L250,250 L250,0 Z"></path><path d="M128.3,109.0 C113.8,99.7 119.0,89.6 119.0,89.6 C122.0,82.7 120.5,78.6 120.5,78.6 C119.2,72.0 123.4,76.3 123.4,76.3 C127.3,80.9 125.5,87.3 125.5,87.3 C122.9,97.6 130.6,101.9 134.4,103.2" fill="currentColor" style="transform-origin: 130px 106px;" class="octo-arm"></path><path d="M115.0,115.0 C114.9,115.1 118.7,116.5 119.8,115.4 L133.7,101.6 C136.9,99.2 139.9,98.4 142.2,98.6 C133.8,88.0 127.5,74.4 143.8,58.0 C148.5,53.4 154.0,51.2 159.7,51.0 C160.3,49.4 163.2,43.6 171.4,40.1 C171.4,40.1 176.1,42.5 178.8,56.2 C183.1,58.6 187.2,61.8 190.9,65.4 C194.5,69.0 197.7,73.2 200.1,77.6 C213.8,80.2 216.3,84.9 216.3,84.9 C212.7,93.1 206.9,96.0 205.4,96.6 C205.1,102.4 203.0,107.8 198.3,112.5 C181.9,128.9 168.3,122.5 157.7,114.1 C157.9,116.9 156.7,120.9 152.7,124.9 L141.0,136.5 C139.8,137.7 141.6,141.9 141.8,141.8 Z" fill="currentColor" class="octo-body"></path></svg>
    
      </a>
    



    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          
            

          
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="https://hellozhaozheng.github.io/z_post/面试-计算机视觉知识点总结/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="ZeroZone">
      <meta itemprop="description" content="吾乃闪耀的芝士蛋挞!">
      <meta itemprop="image" content="/images/avatar_zz.png">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="从零开始的BLOG">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">【置顶】计算机视觉知识点总结
              
            
          </h1>
        

        <div class="post-meta">
	
	     <i class="fa fa-thumb-tack"></i>
	    <font style="color:#999">置顶</font>
	    <span class="post-meta-divider">|</span>
	
          <span class="post-time">

            
            
            

            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">发表于</span>
              

              
                
              

              <time title="创建时间：2018-10-23 20:32:39" itemprop="dateCreated datePublished" datetime="2018-10-23T20:32:39+08:00">2018-10-23</time>
            

            
          </span>

	  
  	    <span class="post-updated">
    		&nbsp; | &nbsp; 更新于
    		<time itemprop="dateUpdated" datetime="2019-07-28T22:35:55+08:00" content="2019-07-28">
      		  2019-07-28
    		</time>
  	  </span>
	  

          
            <span class="post-category" >
            
              <span class="post-meta-divider">|</span>
            
              <span class="post-meta-item-icon">
                <i class="fa fa-folder-o"></i>
              </span>
              
                <span class="post-meta-item-text">分类于</span>
              
              
                <span itemprop="about" itemscope itemtype="http://schema.org/Thing"><a href="/categories/计算机视觉/" itemprop="url" rel="index"><span itemprop="name">计算机视觉</span></a></span>

                
                
              
            </span>
          

          
            
              <span class="post-comments-count">
                <span class="post-meta-divider">|</span>
                <span class="post-meta-item-icon">
                  <i class="fa fa-comment-o"></i>
                </span>
                <a href="/z_post/面试-计算机视觉知识点总结/#comments" itemprop="discussionUrl">
                  <span class="post-meta-item-text">评论数：</span> <span class="post-comments-count valine-comment-count" data-xid="/z_post/面试-计算机视觉知识点总结/" itemprop="commentCount"></span>
                </a>
              </span>
            
          

          
          

          
            <span class="post-meta-divider">|</span>
            <span class="post-meta-item-icon"
            >
            <i class="fa fa-eye"></i>
             阅读次数： 
            <span class="busuanzi-value" id="busuanzi_value_page_pv" ></span>
            </span>
          

          
            <div class="post-symbolscount">
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-file-word-o"></i>
                </span>
                
                  <span class="post-meta-item-text">本文字数：</span>
                
                <span title="本文字数">60k</span>
              

              
                <span class="post-meta-divider">|</span>
              

              
                <span class="post-meta-item-icon">
                  <i class="fa fa-clock-o"></i>
                </span>
                
                  <span class="post-meta-item-text">阅读时长 &asymp;</span>
                
                <span title="阅读时长">54 分钟</span>
              
            </div>
          

          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="总目录篇"><a href="#总目录篇" class="headerlink" title="总目录篇"></a>总目录篇</h1><p><strong>机器学习:</strong> <a href="#逻辑回归">逻辑回归</a>, <a href="#支持向量机">支持向量机</a>, <a href="#决策树">决策树</a>, <a href="#降维">降维</a>, <a href="#聚类">聚类</a></p>
<p><strong>深度学习:</strong> <a href="#优化方法">优化方法</a>, <a href="#初始化方法">初始化方法</a>, <a href="#损失函数">损失函数</a>, <a href="#激活函数">激活函数</a>, <a href="#正则化">正则化</a>, <a href="#归一化">归一化</a>, <a href="#感受野">感受野</a>, <a href="#全连接层">全连接层</a>, <a href="#卷积层">卷积层</a>, <a href="#反卷积层">反卷积层</a>, <a href="#池化层">池化层</a>, <a href="#训练问题">训练问题</a></p>
<p><strong>网络结构:</strong> <a href="#AlexNet">AlexNet</a>, <a href="#VGGNet">VGGNet</a>, <a href="#InceptionV1">InceptionV1</a>, <a href="#InceptionV2">InceptionV2</a>, <a href="#InceptionV3">InceptionV3</a>, <a href="#InceptionV4">InceptionV4</a>, <a href="#Xception">Xception</a>, <a href="#ResNet">ResNet</a>, <a href="#ResNeXt">ResNeXt</a>, <a href="#DenseNet">DenseNet</a>, <a href="#SqueezeNet">SqueezeNet</a>, <a href="#MobileNet">MobileNet</a>, <a href="#MobileNetV2">MobileNetV2</a>, <a href="#ShuffleNet">ShuffleNet</a>, <a href="#ShuffleNetV2">ShuffleNetV2</a>, <a href="#SENetV2">SENet</a>,</p>
<p><strong>目标检测:</strong> <a href="#NMS">NMS</a></p>
<p><strong>图像处理:</strong> <a href="#图像放缩">图像放缩</a></p>
<p><strong>数学基础:</strong> <a href="#概率分布">概率分布</a>, 矩阵乘法优化</p>
<h1 id="机器学习篇"><a href="#机器学习篇" class="headerlink" title="机器学习篇"></a>机器学习篇</h1><p>各种机器学习算法的应用场景分别是什么(比如朴素贝叶斯、决策树、K 近邻、SVM、逻辑回归最大熵模型)<br><a href="https://www.zhihu.com/question/26726794/answer/151282052" target="_blank" rel="noopener">https://www.zhihu.com/question/26726794/answer/151282052</a></p>
<p><span id="基本概念"></span></p>
<h2 id="基本概念"><a href="#基本概念" class="headerlink" title="基本概念"></a>基本概念</h2><h3 id="TP-TN-FP-FN-及各种比值代表的含义"><a href="#TP-TN-FP-FN-及各种比值代表的含义" class="headerlink" title="TP, TN, FP, FN 及各种比值代表的含义"></a>TP, TN, FP, FN 及各种比值代表的含义</h3><div class="table-container">
<table>
<thead>
<tr>
<th>-</th>
<th>Positive Predictions</th>
<th>Negative Predictions</th>
</tr>
</thead>
<tbody>
<tr>
<td>Positive Label</td>
<td>TP</td>
<td>FN</td>
</tr>
<tr>
<td>Negative Label</td>
<td>FP</td>
<td>TN</td>
</tr>
</tbody>
</table>
</div>
<p>Accuracy(准确率):</p>
<script type="math/tex; mode=display">ACC = \frac{TP+TN}{FP+FN+TP+TN} = \frac{预测正确样本数}{总样本数}</script><p>Precision(精度):</p>
<script type="math/tex; mode=display">PRE = \frac{TP}{TP+FP} = \frac{预测正确的正样本数量}{所有预测为正样本(不论对错)的样本数量}</script><p>TPR(召回率):</p>
<script type="math/tex; mode=display">TPR = \frac{TP}{TP+FN} = \frac{预测正确的正样本数量}{总的正样本数量}</script><p>FPR(误诊率, 误报率):</p>
<script type="math/tex; mode=display">FPR = \frac{FP}{FP+TN} = \frac{预测错误的负样本数量}{总的负样本数量}</script><p>FNR(漏报率):</p>
<script type="math/tex; mode=display">FNR = \frac{FN}{FN+TN} = \frac{将正样本错认成负样本的数量}{预测成负样本的总数量}</script><h3 id="PR-ROC-AUC"><a href="#PR-ROC-AUC" class="headerlink" title="PR, ROC, AUC"></a>PR, ROC, AUC</h3><h4 id="PR-曲线"><a href="#PR-曲线" class="headerlink" title="PR 曲线"></a>PR 曲线</h4><p>精度又名查准率, 关心的是 “查出的所有正例中, 哪些正例是查对的”<br>召回率又名查全率, 关心的是 “对于所有的正例, 正确查出了多少个”</p>
<p>这二者是一对矛盾的度量, 因为我们很容易知道:</p>
<ul>
<li>如果我们希望查准率高, 那么可以认为是 “只有当十成把握认为其是正例时, 才将其挑出”.</li>
<li>而如果我们希望召回率高, 那么可以认为是 “宁错杀一百, 不放过一个”. 查准率和查全率的曲线又叫 PR 曲线, 如下图所示.</li>
</ul>
<p><div style="width: 500px; margin: auto"><img src="http://zerozone-blog.oss-cn-beijing.aliyuncs.com/SummaryOfComputerVision/PR.jpg?x-oss-process=style/blog_img" alt="SummaryOfComputerVision%2FPR.jpg"></div></p>
<p>通常情况下, 如果一个学习器的 PR 曲线被另一个学习器 <strong>完全包住</strong>. 那么我们就认为后者的性能优于前者. 当二者存在交叉时, 我们可以通过四种方式来确定学习器的优劣:</p>
<ol>
<li>计算 PR 曲线与横纵坐标轴围成的面积, 面积越大越好;</li>
<li>利用平衡点 (BEP, 查准率=查全率), BEP 越大越好;</li>
<li>利用 $F_1$ 度量, $F_1$ 越大越好. $F_1$ 度量实际上就是当 $\beta = 1$ 时的 $F_\beta$ 度量, $F_1$ 度量认为查准率和查全率的重要性相同.<script type="math/tex; mode=display">\frac{1}{F_1} = \frac{1}{2}(\frac{1}{P} + \frac{1}{R}), F_1 = \frac{2\times P \times R}{P+R}</script></li>
<li>利用 $F_\beta$ 度量, 当 $\beta &lt; 1$ 时, 查准率权(精度)重更大, 当 $\beta &gt; 1$ 时, 查全率(召回率)权重更大. $F_\beta$ 的计算公式来自于加权调和平均数.<script type="math/tex; mode=display">\frac{1}{F_\beta} = \frac{1}{1+\beta^2}(\frac{1}{P} + \frac{\beta^2}{R}), F_\beta = \frac{(1+\beta^2)\times P \times R}{\beta^2 \times P + R}</script></li>
</ol>
<h4 id="ROC-曲线"><a href="#ROC-曲线" class="headerlink" title="ROC 曲线"></a>ROC 曲线</h4><p>很多学习器是为测试样本产生一个实值或概率预测, 然后将这个预测值与一个分类阈值进行比较, 若大于阈值分为正例, 否则分为负例, 因此分类过程可以看做是选取一个合适的截断点, 那么到底什么样的截断点更合适. ROC 正是从这个角度来研究学习器好坏的工具.</p>
<p>ROC 曲线的纵坐标和横坐标分别是召回率(查全率)和假正率(误诊率), 下图为 ROC 曲线图, 实际任务中会利用有限个测试样本来绘制 ROC 图, 所以产生的大多不是平滑的曲线.</p>
<p><div style="width: 500px; margin: auto"><img src="http://zerozone-blog.oss-cn-beijing.aliyuncs.com/SummaryOfComputerVision/ROC.jpg?x-oss-process=style/blog_img" alt="SummaryOfComputerVision%2FROC.jpg"></div></p>
<p>和 PR 曲线类似, 如果一个学习器的 ROC 曲线被另一个学习器 “完全包住”, 则后者的性能优于前者. 对于 ROC 曲线来说, 我们需要先观察其是否没有剧烈的波动, 如果曲线不够平滑, 波动距离, 那么猜测可能发生了过拟合现象, 如果 ROC 是光滑的, 这个时候就可以通过曲线的 AUC (area under curve) 来判断模型的好坏, AUC 越大的模型越好. 因为 AUC 越大, 说明模型可以在较低的误诊率下达到较高的召回率.</p>
<h4 id="绘制-ROC-曲线"><a href="#绘制-ROC-曲线" class="headerlink" title="绘制 ROC 曲线"></a>绘制 ROC 曲线</h4><p>假设已经得出一系列样本被划分为正类的概率，然后按照大小排序，下图是一个示例，图中共有20个测试样本，”Class” 一栏表示每个测试样本真正的标签（p表示正样本，n表示负样本），”Score” 表示每个测试样本属于正样本的概率。</p>
<p><div style="width: 500px; margin: auto"><img src="http://zerozone-blog.oss-cn-beijing.aliyuncs.com/SummaryOfComputerVision/auc1.jpg?x-oss-process=style/blog_img" alt="SummaryOfComputerVision%2Fauc1.jpg"></div></p>
<p>接下来，我们从高到低，依次将“Score”值作为阈值threshold，当测试样本属于正样本的概率大于或等于这个threshold时，我们认为它为正样本，否则为负样本。举例来说，对于图中的第4个样本，其“Score”值为0.6，那么样本1，2，3，4都被认为是正样本，因为它们的“Score”值都大于等于0.6，而其他样本则都认为是负样本。每次选取一个不同的threshold，我们就可以得到一组FPR和TPR，即ROC曲线上的一点。这样一来，我们一共得到了20组FPR和TPR的值，将它们画在ROC曲线的结果如下图</p>
<p><div style="width: 500px; margin: auto"><img src="http://zerozone-blog.oss-cn-beijing.aliyuncs.com/SummaryOfComputerVision/auc2.jpg?x-oss-process=style/blog_img" alt="SummaryOfComputerVision%2Fauc2.jpg"></div></p>
<p>计算 FPR 和 TPR 的方法:</p>
<ol>
<li>先统计 20 组样本中, 有多少个正样本, 有多少个负样本, 假设为别为 $N$ 和 $M$, $N+M=20$.</li>
<li>对于每一组样本, 选取它的 socre 作为阈值, 那么在 score 之上的预测结果中(包括当前样本), 我们都认为将其预测成正样本, 那么, 假设这些样本的实际正样本数量为 $n$, 实际负样本数量为 $m$, 则 TPR 和 FPR 分别为: $n/N$, $m/M$.</li>
<li>按照 score 的大小从高到低重复执行 2 过程</li>
</ol>
<p><strong>注意1:</strong> 上面的 Score 使用了经过 softmax 转换后的值, 也可以看做是概率, 但是实际上, <strong>我们在画 ROC 图的时候, 只需要获取到样本之间的相对大小即可</strong>, 所以我们可以直接使用为经过 softmax 转换的 socre 来画图, 得到的 ROC 和 AUC 不会发生变化.<br><strong>注意2:</strong> 上图中, 我们可以看到 ROC 曲线是根据一组组的 FPR 和 TPR 的值得到的, 因此呈现出 “阶梯状”, 并且面积均为矩形. <strong>但是如果预测出来的 score 存在有相同分数的情况, 那么就会出现梯形, 此时不利用直接计算面积.</strong></p>
<ul>
<li>形成矩形的原因: 每新增一个样本, 它要么只增加 FPR, 要么只增加 TPR, 所以曲线要么向右延伸, 要么向上延伸;</li>
<li>形成梯形的原因: 如果说, 有多个样本的 score 相同, 那么当选择该 score 作为阈值时, 就会同时增加 TPR 和 FPR, 因此曲线就会想右上方延伸, 故而形成梯形.</li>
</ul>
<h4 id="AUC-的含义及计算"><a href="#AUC-的含义及计算" class="headerlink" title="AUC 的含义及计算"></a>AUC 的含义及计算</h4><p><strong>含义:</strong> 首先, AUC 的值是处于 [0, 1] 区间内的, 实际上, 从 ROC 的绘制过程中我们就可以看出, AUC 可以看做是一个概率值, 它代表着当我们随机挑选一个正样本和负样本时, 当前学习器对正样本的预测值大于负样本的概率, 也就是说当前学习器将这个正样本排在负样本前面的概率. 我们通常希望学习器的 AUC 的值越大越好, 实际上也就是希望当我们随机拿出一个正样本和负样本时, 学习器都能够将这个正样本排在负样本的前面, 很容易知道, 当 AUC 的值为 1 时, 我们按照 score 排列正负样本, 所有的正样本都会处在负样本的前面, 这个时候我们很容易找到一个阈值使得学习器的分类完全正确; 当 AUC 的值为 0 时, 此时按照 score 排列, 所有的负样本都处在正样本的前面, 这个时候学习器的性能最差.(我们这里讲的 socre 代表样本是正样本的概率, 因此不能反过来用). 也就是说, 它衡量的是模型将一堆样本进行分类的能力.</p>
<p><strong>计算:</strong><br>一般情况下, AUC 的计算都是指 ROC 曲线的 AUC, 其计算方式有以下三种</p>
<ol>
<li>计算每一段小矩形的面积, 之后求和. 这种计算方式只适用于 score 均不相等时, ROC 曲线只有小矩形构成的情况, 如果 score 有相等的情况出现, 那么就需要计算梯形, 比较麻烦.</li>
<li>根据 AUC 的含义, 我们可以从另一个角度来计算 AUC. 那就是随机挑选一个正样本和一个负样本, 正样本排在负样本前面的概率就是 AUC 的值. 对于有限的样本数量, 我们认为频率可以近似概率. 因此, 对于具有 $N$ 个正样本, $M$ 个负样本组成的测试集合, 我们总共有 $N\times M$ 组不同的正负样本组合, 然后只需要统计这 $N\times M$ 个组合中, 正样本 score 大于负样本 score 的数量, 将其除以 $N\times M$ 即可. 算法时间复杂度为 $O(N^2M^2)$</li>
<li>方法二的复杂度较高, 方法三用一种更高效的方式来计算. 我们先将样本按照 score 排列, 那么可以知道, 第一个样本与任意的样本组合, 都是前者的 score 大, 于是, 我们按照排列的顺序, 为每一个样本赋予 rank, 其中第一位的 rank 为 $N+M$, 最后一位的 rank 为 1. 然后, 利用下面的公式计算 AUC:</li>
</ol>
<script type="math/tex; mode=display">AUC = \frac{\sum_{i\in positive} rank_i - \frac{N(1+N)}{2}}{M\times N}</script><p>上面的公式非常好理解, 其中分母 $N\times M$ 代表了所有可能的 (正样本, 负样本) 的组合数量, 分子中 rank 的值实际上代表了该样本能够产生多少种 <strong>前大后小</strong> 的组合, 而这些组合中需要减去 $\frac{N(1+N)}{2}$ 中 (正样本, 正样本) 的组合情况. 另外, 需要特别注意的是, 在存在 score 相等的情况时, 需要赋予其相同的 rank (不论正负样本), 具体操作就是将这些样本原来的 rank 求和去平均.</p>
<p><span id="逻辑回归"></span></p>
<h2 id="逻辑回归"><a href="#逻辑回归" class="headerlink" title="逻辑回归"></a>逻辑回归</h2><p><a href="../机器学习-逻辑回归">逻辑回归与线性回归</a></p>
<h3 id="逻辑回归和线性回归的定义"><a href="#逻辑回归和线性回归的定义" class="headerlink" title="逻辑回归和线性回归的定义"></a><a href="../机器学习-逻辑回归/#逻辑回归和线性回归的定义">逻辑回归和线性回归的定义</a></h3><p><strong>逻辑回归定义</strong><br>逻辑回归通常用来解决二分类问题(也可以解决多分类问题), 用于估计某种事物的可能性. 我通过 Logistic 函数将拟合函数的输出值归一化到 (0, 1) 之间, 我们可以将其认为是分类为 1 类的预测概率. Logistic 函数公式(和 Sigmoid 函数形式形式相同)如下:</p>
<script type="math/tex; mode=display">g(z) = \frac{1}{1+e^{-z}}</script><p>Logistic(Sigmoid) 函数的求导公式有一个特性: $g’(z) = g(z)(1 - g(z))$.</p>
<p><strong>线性回归定义:</strong><br>线性回归通常是解决连续数值预测问题, 利用数理统计的回归分析, 来确定变量之间的相互依赖关系. 其公式通常表示如下:</p>
<script type="math/tex; mode=display">y = \theta^T x + e</script><h3 id="逻辑回归和线性回归的区别和联系"><a href="#逻辑回归和线性回归的区别和联系" class="headerlink" title="逻辑回归和线性回归的区别和联系"></a><a href="../机器学习-逻辑回归/#逻辑回归与线性回归的联系和区别">逻辑回归和线性回归的区别和联系</a></h3><p><strong>联系</strong><br>逻辑回归本质上还是线性回归, 只是在特征到结果的映射中加入了一层函数映射, 即先把特征线性求和, 然后使用函数 $g(z)$ 将连续结果值映射到 (0, 1) 之间, 我们将线性回归模型的表达式代入到 Logistic(Sigmoid) 函数之中, 就得到了逻辑回归的表达式:</p>
<script type="math/tex; mode=display">h_\theta (x) = g(\theta^T x) = \frac{1}{1 + e^{-\theta^Tx}}</script><p>实际上, 我们将逻辑回归的公式整理一下, 就可以得到 $log\frac{p}{1-p} = \theta^T x$, 其中, $p = P(y=1 | x)$, 也就是将给定输入 $x$ 预测为正样本的概率. 那也就是说, 逻辑回归实际上也可以看做是对 $log\frac{p}{1-p}$ 的线性回归. 但是在关于逻辑回归的讨论中, 我们均认为 $y$ 是因变量, 而不是 $\frac{p}{1-p}$, 这便引出逻辑回归与线性回归最大的区别, 即 <strong>逻辑回归中的因变量是离散的</strong>, 而 <strong>线性回归中的因变量是连续的</strong>. 并且在自变量 $x$ 和超参数 $\theta$ 确定的情况下, 逻辑回归可以看做是广义线性模型在因变量 $y$ 服从二元分布时的一个特殊情况, 而使用最小二乘法求解线性回归时, 我们认为因变量 $y$ 服从正态分布.</p>
<p><strong>区别:</strong><br>最本质区别: 逻辑回归处理的是分类问题, 线性回归处理的是回归问题. 在逻辑回归中, 因变量的取值是一个 <strong>二元分布(不是二项分布)</strong>. 而线性回归中实际上求解的是对真实函数关系的一个近似拟合.</p>
<h3 id="对于一个二分类问题-如果数据集中存在一些离异值-在不清洗数据的情况下-选择逻辑回归还是-SVM-为什么"><a href="#对于一个二分类问题-如果数据集中存在一些离异值-在不清洗数据的情况下-选择逻辑回归还是-SVM-为什么" class="headerlink" title="对于一个二分类问题, 如果数据集中存在一些离异值, 在不清洗数据的情况下, 选择逻辑回归还是 SVM? 为什么?"></a><a href="../机器学习-逻辑回归/#对于一个二分类问题">对于一个二分类问题, 如果数据集中存在一些离异值, 在不清洗数据的情况下, 选择逻辑回归还是 SVM? 为什么?</a></h3><p>用 SVM, 因为 SVM 的分类只与支持向量有关, 所以对离异值的忍受能力更强.</p>
<h3 id="逻辑回归与-SVM-的区别是什么"><a href="#逻辑回归与-SVM-的区别是什么" class="headerlink" title="逻辑回归与 SVM 的区别是什么"></a><a href="../机器学习-逻辑回归/#逻辑回归和 SVM 的区别是什么">逻辑回归与 SVM 的区别是什么</a></h3><p>两种方法都是常见的分类算法, 从目标函数上看, 区别在于逻辑回归采用的是 log 损失, 而 SVM 采用的是 hinge 损失. 这两个损失函数的目的都是增加对分类影响较大的数据点的权重, 减少与分类关系较小的数据点的权重. SVM 的处理方法是只考虑支持向量, 也就是和分类最相关的少数点, 去学习分类器. 而逻辑回归通过非线性映射, 大大减小了离分类平面较远的点的权重, 相对提升了与分类最相关的数据点的权重. 两者的根本目的都是一样的. 此外, 根据需要, 两个方法都可以增加不同的正则化项, 如 L1, L2 等. 所以在很多实验中, 两种算法的结果是很接近的.<br>但是逻辑回归相对来说模型更加简单, 并且实现起来, 特别是大规模线性分类时比较方便. 而 SVM 的实现和优化相对来说复杂一些, 但是 SVM 的理论基础更加牢固, 有一套结构化风险最小化的理论基础, 另外, SVM 转化成对偶问题后, 分类只需要计算与少数几个支持向量的距离即可, 这在进行复杂核函数计算时有时很明显, 能够大大简化模型和计算量</p>
<p>损失函数: 逻辑回归和 SVM 的损失函数分别为:</p>
<script type="math/tex; mode=display">\text{Logistic: } \frac{1}{n} \sum^n_{i=1} - \log g(y_i [ w_0 + x^T_i w_1]) + \frac{\lambda}{2}\| w_1 \|</script><script type="math/tex; mode=display">\text{SVM: } \frac{1}{n}\sum^n_{i=1}(1 - y_i[w_0 + x^T_i w_1])^{+} + \frac{\lambda}{2}\| w_1 \|</script><p>上式中, $g(z) = \frac{1}{1 + exp^(-z)}$. 可以看出, 逻辑回归采用的是对数损失(log loss), 而 SVM 采用的是铰链损失(hinge loss), 即:</p>
<ul>
<li>LR 损失: $Loss(z) = log(1 + exp(-z))$</li>
<li>SVM 损失: $Loss(z) = (1 - z)^{+}$</li>
</ul>
<p>逻辑回归产出的是概率值, 而 SVM 只能产出正负类, 因此 LR 的预估结果更容易解释.<br>SVM 主要关注的是 “支持向量”, 也就是和分类最相关的少数点, 即关注局部关键信息; 而逻辑回归是在全局进行优化的, 这导致 SVM 天然比逻辑回归有更好的泛化能力, 防止过拟合.</p>
<h3 id="逻辑回归和-SVM-哪个是参数模型-哪个是非参数模型"><a href="#逻辑回归和-SVM-哪个是参数模型-哪个是非参数模型" class="headerlink" title="逻辑回归和 SVM 哪个是参数模型, 哪个是非参数模型"></a>逻辑回归和 SVM 哪个是参数模型, 哪个是非参数模型</h3><p><strong>LR 是参数模型, SVM 是非参数模型</strong></p>
<p>定义: 参数模型通常假设总体随机变量服从某一个分布, 该分布由一些参数确定(比如正态分布的均值和方差), 在此基础上构建的模型称为参数模型; 非参数模型对于总体的分布不做任何假设, 只是知道总体是一个随机变量, 其分布是存在的(分布中也可能存在参数), 但是无法知道其分布的形式, 更不知道分布的相关参数, 只有在给定一些样本的条件下, 能够依据非参数统计的方法进行推断. 因此, <strong>问题中有没有参数, 并不是参数模型和非参数模型的区别. 其主要区别在于总体的分布形式是否已知.</strong> 为何强调 “参数” 与 “非参数”, 主要原因在于参数模型的分布可以由参数直接确定.</p>
<p>参数算法包括两部分: (1) 选择目标函数的形式; (2) 从训练数据中学习目标函数的系数. LR 会预先假设目标函数(直线或其他), 因此它是参数模型. 其他参数模型还有: 线性成分分析, 感知机.<br>参数模型的优点:</p>
<ul>
<li>简单: 理论容易理解, 结果容易解释</li>
<li>快速: 参数模型的学习和训练速度较快</li>
<li>数据更少: 通常不需要大量的数据也可以较好的拟合?</li>
</ul>
<p>参数模型的缺点:</p>
<ul>
<li>约束: 以选定函数形式的方式来学习本身就限制了模型的解空间</li>
<li>有限的复杂度: 通常只能应对简单的问题</li>
<li>拟合度小: 实际中通常无法和潜在的目标函数温和.</li>
</ul>
<p>非参数算法: 对于目标函数的形式不作过多的假设. 当有用许多数据而先验知识很少时, 非参数学习通常很有用, 因为此时不需要关注参数的选取. 常用的非参数算法包括: K 最近邻, 决策树, SVM, 朴素贝叶斯, 神经网络.<br>非参数算法的优点:</p>
<ul>
<li>可变性: 可以拟合许多不同的函数形式</li>
<li>模型强大: 对于目标函数不作假设或者作微小的假设</li>
<li>表现良好: 对于预测结果表现通常较好</li>
</ul>
<p>非参数算法的局限性:</p>
<ul>
<li>需要更多数据: 对于拟合目标函数需要更多的训练数据</li>
<li>速度慢: 参数更多, 所以训练通常较慢</li>
</ul>
<h3 id="逻辑回归和-SVM-分别适合在什么情况下使用"><a href="#逻辑回归和-SVM-分别适合在什么情况下使用" class="headerlink" title="逻辑回归和 SVM 分别适合在什么情况下使用"></a>逻辑回归和 SVM 分别适合在什么情况下使用</h3><p>令 $n = 特征数量$, $m = 训练样本数量$, 则:</p>
<ul>
<li>如果 $n &gt; m$, 则使用 LR 或者不带核函数的 SVM, 因为特征数相对于训练样本数已经够大了, 使用线性模型就能取得不错的效果, 不需要过于复杂的模型;</li>
<li>如果 $n &lt; m$, 则使用 SVM(高斯核函数), 因为在训练样本数量足够大而特征数量较小的情况下, 可以通过复杂核函数的 SVM 来获得更好的预测性能, 而且因为训练样本数量并没有达到百万级, 使用复杂核函数的 SVM 也不会导致运算过慢;</li>
<li>如果 $n &lt;&lt; m$, 此时因为训练样本数量特别大, 使用复杂核函数的 SVM 会导致训练过慢, 因此应该考虑通过引入更多特征, 然后使用 LR 或者不带核函数的 SVM 来训练更好的模型</li>
</ul>
<p>在实际使用中, 通常当数据非常非常大(几个 G, 几万维度特征), 跑不动 SVM 时, 用 LR. 如今数据量大幅增加, 相比来说 LR 反而用的更多了.</p>
<p><span id="KNN"></span></p>
<h2 id="KNN"><a href="#KNN" class="headerlink" title="KNN"></a>KNN</h2><h3 id="简述-KNN-算法的原理"><a href="#简述-KNN-算法的原理" class="headerlink" title="简述 KNN 算法的原理"></a>简述 KNN 算法的原理</h3><h3 id="KNN-算法进行分类和回归时的区别"><a href="#KNN-算法进行分类和回归时的区别" class="headerlink" title="KNN 算法进行分类和回归时的区别"></a>KNN 算法进行分类和回归时的区别</h3><p>KNN做回归和分类的主要区别在于最后做预测时候的决策方式不同。KNN做分类预测时，一般是选择多数表决法，即训练集里和预测的样本特征最近的K个样本，预测为里面有最多类别数的类别。而KNN做回归时，一般是选择平均法，即最近的K个样本的样本输出的平均值作为回归预测值。</p>
<h3 id="KNN-算法的三要素"><a href="#KNN-算法的三要素" class="headerlink" title="KNN 算法的三要素"></a>KNN 算法的三要素</h3><ol>
<li>K 值的选取: 对于k值的选择，没有一个固定的经验，一般根据样本的分布，选择一个较小的值，可以通过交叉验证选择一个合适的k值。选择较小的k值，就相当于用较小的领域中的训练实例进行预测，训练误差会减小，只有与输入实例较近或相似的训练实例才会对预测结果起作用，与此同时带来的问题是泛化误差会增大，换句话说，K值的减小就意味着整体模型变得复杂，容易发生过拟合；选择较大的k值，就相当于用较大领域中的训练实例进行预测，其优点是可以减少泛化误差，但缺点是训练误差会增大。这时候，与输入实例较远（不相似的）训练实例也会对预测器作用，使预测发生错误，且K值的增大就意味着整体的模型变得简单。一个极端是k等于样本数m，则完全没有分类，此时无论输入实例是什么，都只是简单的预测它属于在训练实例中最多的类，模型过于简单。</li>
<li>距离的度量方式: 曼哈顿距离($p=1$), 欧氏距离($p=2$), 闵可夫斯基距离($p=3$)<script type="math/tex; mode=display">D(x, y) = \sqrt[p] {(\vert x_1 - y_1 \vert)^p + (\vert x_2 - y_2 \vert)^p + ... + (\vert x_n - y_n \vert)^p} = \sqrt[p] {\sum_{i=1}^n (\vert x_i - y_i \vert)^p}</script></li>
<li>分类决策规则: 一般使用 “多数表决法”</li>
</ol>
<h3 id="KNN-算法是否可微"><a href="#KNN-算法是否可微" class="headerlink" title="KNN 算法是否可微"></a>KNN 算法是否可微</h3><p>不可微, 因为求 K 近邻(argmax)的操作是不可微的</p>
<h3 id="编程实现-KNN-算法"><a href="#编程实现-KNN-算法" class="headerlink" title="编程实现 KNN 算法"></a>编程实现 KNN 算法</h3><p><strong>暴力实现:</strong>(实际算法中会采用更高效的实现, 如 KD 树实现, Ball 树实现等)<br>计算预测样本和所有训练集中的样本的距离，然后选出最小的k个距离即可，接着多数表决，很容易做出预测. 复杂度过大, 通常样本量成千上万.<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">KNearestNeighbor</span><span class="params">(object)</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self)</span>:</span></span><br><span class="line">        self.train_data = <span class="keyword">None</span></span><br><span class="line">        self.train_label = <span class="keyword">None</span></span><br><span class="line">        self.dists = []</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">train</span><span class="params">(self, train_data, train_label)</span>:</span></span><br><span class="line">        <span class="comment"># train_data: [N x d] 的数组, N 为样本数量, d 为样本维度</span></span><br><span class="line">        <span class="comment"># train_label: [N x 1] 的数组, N 为样本数量, 1 代表类别标签维度(1维)</span></span><br><span class="line">        self.train_data = train_data</span><br><span class="line">        self.train_label = train_label</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">predict</span><span class="params">(self, test_data, k=<span class="number">3</span>, distance=<span class="string">'l2'</span>)</span>:</span></span><br><span class="line">        test_num = test_data.shape[<span class="number">0</span>]</span><br><span class="line">        preds = []</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(test_num):</span><br><span class="line">            <span class="keyword">if</span> distance == <span class="string">'l1'</span>:</span><br><span class="line">                self.dists = L1Distance(test_data[i])</span><br><span class="line">            <span class="keyword">elif</span> distance == <span class="string">'l2'</span>:</span><br><span class="line">                self.dists = L2Distance(test_data[i])</span><br><span class="line">            dists_argsort = np.argsort(self.dists)</span><br><span class="line">            knearest_class = self.train_label(dists_argsort)[<span class="number">1</span>:k+<span class="number">1</span>]</span><br><span class="line">            class_count = np.bincount(knearest_class)</span><br><span class="line">            pred = np.argmax(class_count)</span><br><span class="line">            preds.append(pred)</span><br><span class="line">        <span class="keyword">return</span> np.array(preds)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">L1Distance</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> np.sum(np.abs(self.train_data - x), axis=<span class="number">1</span>)<span class="comment"># 千万不要忘了求和时 axis=1</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">L2Distance</span><span class="params">(self, x)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> np.sqrt(np.sum(np.square(self.train_data-x), axis=<span class="number">1</span>))<span class="comment"># 千万不要忘了求和时 axis=1</span></span><br></pre></td></tr></table></figure></p>
<p><span id="支持向量机"></span></p>
<h2 id="支持向量机"><a href="#支持向量机" class="headerlink" title="支持向量机"></a>支持向量机</h2><p><a href="../机器学习-SVM深入解析">SVM深入解析</a></p>
<h3 id="简述-SVM-的基本概念和原理"><a href="#简述-SVM-的基本概念和原理" class="headerlink" title="简述 SVM 的基本概念和原理"></a><a href="../机器学习-SVM深入解析/#简述 SVM 的基本概念和原理">简述 SVM 的基本概念和原理</a></h3><p>最简单的 SVM 从线性分类器导出, 根据最大化样本点分类间隔的目标, 我们可以得到线性可分问题的 SVM 目标函数. 然后可以利用拉格朗日乘子法得到其对偶问题, 并根据 KKT 条件和 SMO 算法就可以高效的求出超平面的解. 但是实际任务中, 原始样本空间内也许并不存在一个能正确划分两类样本的超平面. 因此, 我们需要利用核函数将样本从原始空间映射到一个更高为的特征空间, 使得样本在这个特征空间内线性可分. 核函数的选择对于支持向量机的性能至关重要. 但是现实任务中往往很难确定合适的核函数使得训练样本在特征空间内线性可分, 因此, 我们引入了 “软间隔” 的概念, 也就是松弛变量和惩罚因子, 其基本思想就是, 允许支持向量机在一些样本上出错, 并对违反约束条件的训练样本进行惩罚. 所以, 最终的优化目标就是在最大化间隔的同时, 使得不满足约束的样本尽可能地少.</p>
<h3 id="SVM-推导过程"><a href="#SVM-推导过程" class="headerlink" title="SVM 推导过程"></a><a href="../机器学习-SVM深入解析/#SVM 推导过程">SVM 推导过程</a></h3><p>过长, 建议点击题目链接查看</p>
<h3 id="SVM-如何解决线性不可分问题"><a href="#SVM-如何解决线性不可分问题" class="headerlink" title="SVM 如何解决线性不可分问题"></a><a href="../机器学习-SVM深入解析/#SVM 如何解决线性不可分问题">SVM 如何解决线性不可分问题</a></h3><p>解决线性不可分的基本思路有两个:</p>
<ul>
<li>加入松弛变量和惩罚因子, 找到 <strong>相对较好</strong> 的超平面, 这里的 <strong>相对较好</strong> 可以理解为 <strong>尽可能</strong> 的将数据正确分类</li>
<li>使用核函数, 将低维的数据映射到更高维的空间, 使得高维空间中的数据是线性可分的, 那么在高维空间吗使用线性分类模型即可.</li>
</ul>
<h3 id="为什么SVM的分类结果仅依赖于支持向量"><a href="#为什么SVM的分类结果仅依赖于支持向量" class="headerlink" title="为什么SVM的分类结果仅依赖于支持向量?"></a><a href="../机器学习-SVM深入解析/#为什么SVM的分类结果仅依赖于支持向量?">为什么SVM的分类结果仅依赖于支持向量?</a></h3><p>百机p53</p>
<h3 id="如何选取核函数"><a href="#如何选取核函数" class="headerlink" title="如何选取核函数"></a><a href="../机器学习-SVM深入解析/#如何选取核函数">如何选取核函数</a></h3><p>最常用的是线性核与高斯核, 也就是 Linear 核与 RBF 核. 一般情况下 RBF 效果不会差于 Linear, 但是时间上 RBF 会耗费更多.</p>
<ul>
<li>Linear 核: 主要用于线性可分的情形. 参数少, 速度快, 对于一般数据, 分类效果已经很理想了.</li>
<li>RBF 核: 主要用于线性不可分的情况. 参数多, 分类结果非常依赖于参数. 有很多人是通过训练数据的交叉验证来寻找合适的参数, 不过这个过程比较耗时. 个人体会是: 使用 libsvm, 默认参数, RBF 核比 Linear 核效果稍差. 通过进行大量参数的尝试, 一般能找到比 linear 核更好的效果. 至于到底该采用哪种核, 要根据具体问题和数据分析, 需要多尝试不同核以及不同参数. 如果特征提取的好, 包含的信息量足够大, 很多问题都是线性可分的. 当然, 如果有足够的时间去寻找合适的 RBF 核参数, 应该能取得更好的效果.</li>
</ul>
<p>吴恩达的观点:</p>
<ol>
<li>如果 Feature 的数量很大, 跟样本数量差不多, 这时候可以使用 LR 或者是 Linear Kernel 的 SVM. (因为核函数需要计算内积, 两两样本都得算, 所以样本过多的话时间消耗太大, 很明显高斯核比线性核复杂的多)</li>
<li>如果 Feature 的数量比较小, 样本数量一般, 不算大也不算小, 就选用 SVM + Gaussian Kernel</li>
<li>如果 Feature 的数量比较小, 而样本数量比较多, 就需要手工添加一些 feature, 使之变成第一种情况.</li>
</ol>
<h3 id="为什么说高斯核函数将原始特征空间映射成了无限维空间"><a href="#为什么说高斯核函数将原始特征空间映射成了无限维空间" class="headerlink" title="为什么说高斯核函数将原始特征空间映射成了无限维空间?"></a><a href="../机器学习-SVM深入解析/#为什么说高斯核函数将原始特征空间映射成了无限维空间?">为什么说高斯核函数将原始特征空间映射成了无限维空间?</a></h3><p><a href="https://blog.csdn.net/lin_limin/article/details/81135754" target="_blank" rel="noopener">https://blog.csdn.net/lin_limin/article/details/81135754</a></p>
<h3 id="核函数中不同参数的影响"><a href="#核函数中不同参数的影响" class="headerlink" title="核函数中不同参数的影响"></a><a href="../机器学习-SVM深入解析/#核函数中不同参数的影响">核函数中不同参数的影响</a></h3><p><a href="https://blog.csdn.net/lin_limin/article/details/81135754" target="_blank" rel="noopener">https://blog.csdn.net/lin_limin/article/details/81135754</a></p>
<p><a href="https://mp.weixin.qq.com/s?__biz=MzU4MjQ3MDkwNA==&amp;mid=2247484495&amp;idx=1&amp;sn=4f3a6ce21cdd1a048e402ed05c9ead91&amp;chksm=fdb699d8cac110ce53f4fc5e417e107f839059cb76d3cbf640c6f56620f90f8fb4e7f6ee02f9&amp;scene=21#wechat_redirect" target="_blank" rel="noopener">https://mp.weixin.qq.com/s?__biz=MzU4MjQ3MDkwNA==&amp;mid=2247484495&amp;idx=1&amp;sn=4f3a6ce21cdd1a048e402ed05c9ead91&amp;chksm=fdb699d8cac110ce53f4fc5e417e107f839059cb76d3cbf640c6f56620f90f8fb4e7f6ee02f9&amp;scene=21#wechat_redirect</a></p>
<h3 id="既然深度学习技术性能表现以及全面超越-SVM-SVM-还有存在的必要吗"><a href="#既然深度学习技术性能表现以及全面超越-SVM-SVM-还有存在的必要吗" class="headerlink" title="既然深度学习技术性能表现以及全面超越 SVM, SVM 还有存在的必要吗?"></a><a href="../机器学习-SVM深入解析/#既然深度学习技术性能表现已经全面超越 SVM, SVM 还有存在的必要吗?">既然深度学习技术性能表现以及全面超越 SVM, SVM 还有存在的必要吗?</a></h3><p>待补充</p>
<p><span id="决策树"></span></p>
<h2 id="决策树"><a href="#决策树" class="headerlink" title="决策树"></a>决策树</h2><p><span id="朴素贝叶斯"></span></p>
<h2 id="朴素贝叶斯"><a href="#朴素贝叶斯" class="headerlink" title="朴素贝叶斯"></a>朴素贝叶斯</h2><p><span id="降维"></span></p>
<h2 id="降维"><a href="#降维" class="headerlink" title="降维"></a>降维</h2><p><span id="聚类"></span></p>
<h2 id="聚类"><a href="#聚类" class="headerlink" title="聚类"></a>聚类</h2><h3 id="简述-K-Means-聚类的原理"><a href="#简述-K-Means-聚类的原理" class="headerlink" title="简述 K-Means 聚类的原理"></a>简述 K-Means 聚类的原理</h3><p>K-Means算法是无监督的聚类算法，它对于给定的样本集, 会按照样本之间的距离大小, 将样本集划分为 K 个簇, 让簇内的样本尽量紧密的连在一起, 而让簇间的距离尽量的大.<br>如果用数据表达式表示, 则假设簇划分为 $(C_1, C_2, …, C_k)$, 则我们的目标是最小化平方误差 $E$:</p>
<script type="math/tex; mode=display">E = \sum_{i=1}^{k} \sum_{x\in C_i} \Vert x - u_i \Vert_2^2</script><p>其中 $\mu_i$ 是簇 $C_i$ 的均值向量, 有时也称为质心, 表达式为:</p>
<script type="math/tex; mode=display">\mu_i = \frac{1}{C_i} \sum_{x\in C_i} x</script><h3 id="K-Means-算法的优点和缺点"><a href="#K-Means-算法的优点和缺点" class="headerlink" title="K-Means 算法的优点和缺点"></a>K-Means 算法的优点和缺点</h3><p>K-Means 算法对于初始点非常敏感, 如果初始点全部处于一点, 则最终可能无法迭代到合适的解, 原因在于所有的样本都会属于某一个点类, 此时其他的点会无法更新.</p>
<h3 id="K-Means-实现流程"><a href="#K-Means-实现流程" class="headerlink" title="K-Means 实现流程"></a>K-Means 实现流程</h3><p>想直接求上式的最小值并不容易，这是一个NP难的问题，因此只能采用启发式的迭代方法, 如下图所示。</p>
<p><div style="width: 500px; margin: auto"><img src="http://zerozone-blog.oss-cn-beijing.aliyuncs.com/SummaryOfComputerVision/kmeans.jpg?x-oss-process=style/blog_img" alt="SummaryOfComputerVision%2Fkmeans.jpg"></div></p>
<ol>
<li>上图a表达了初始的数据集，假设k=2。</li>
<li>在图b中，我们 <strong>随机</strong> 选择了两个k类所对应的类别质心，即图中的红色质心和蓝色质心</li>
<li>然后分别求样本中所有点到这两个质心的距离，并标记每个样本的类别为和该样本距离最小的质心的类别，如图c所示，经过计算样本和红色质心和蓝色质心的距离，我们得到了所有样本点的第一轮迭代后的类别。</li>
<li>此时我们对我们当前标记为红色和蓝色的点分别求其新的质心，如图d所示，新的红色质心和蓝色质心的位置已经发生了变动。</li>
<li>图e和图f重复了我们在图c和图d的过程，即将所有点的类别标记为距离最近的质心的类别并求新的质心。最终我们得到的两个类别如图f。</li>
</ol>
<p><strong>算法实现流程:</strong> 输入是样本集 $D = \{x_1, x_2, …, x_m\}$, 聚类的簇为 $k$, 最大的迭代次数为 $N$.</p>
<ol>
<li>从数据集 $D$ 中随机选择 $k$ 个样本作为初始的 $k$ 个质心向量: $\{\mu_1, \mu_2, …, \mu_k \}$</li>
<li>对于 $n = 1, 2, …, N$<ol>
<li>将簇的划分 $C$ 初始化为 $C_t = \emptyset, t = 1, 2, …, k$;</li>
<li>对于 $i=1,2,…,m$, 计算样本 $x_i$ 和各个质心向量 $\mu_j(j=1, 2, …, k)$ 的距离, $d_{ij} = \Vert x_i - \mu_j \Vert_2^2$, 将 $x_i$ 标记为距离最小的簇所对应的类别 $\lambda_i$. 更新 $C_{\lambda_i} = C_{\lambda_i} \cup \{x_i\}$</li>
<li>对于 $j = 1, 2, …, k$, 对 $C_j$ 中的所有样本点重新计算新的质心 $\mu_j = \frac{1}{\vert C_j \vert} \sum_{x\in C_j} x$</li>
<li>如果所有的 $k$ 个质心向量都不再发生变化, 则可提前跳出循环, 无序执行 N 次迭代</li>
</ol>
</li>
<li>输出簇划分 $C = \{C_1, C_2, …, C_k \}$</li>
</ol>
<h3 id="K-Means-常规实现代码"><a href="#K-Means-常规实现代码" class="headerlink" title="K-Means 常规实现代码"></a>K-Means 常规实现代码</h3><p>输入为 <code>[N, d]</code> 维度的样本集合, 其中, <code>N</code>代表样本的数量, <code>d</code>代表每个样本的维度, 算法的实现思路为:</p>
<ol>
<li><code>__init__</code>函数初始化相关变量</li>
<li><code>fit</code>函数首先确定最初的<code>n_cluster</code>个<code>center</code>;</li>
<li><code>fit</code>函数循环执行以下两个过程:<ol>
<li>更新各个点到<code>centers</code>的距离</li>
<li>更新各个<code>centers</code>的位置</li>
</ol>
</li>
</ol>
<p>PyTorch 实现: <a href="https://www.jianshu.com/p/1c000d9296ae" target="_blank" rel="noopener">https://www.jianshu.com/p/1c000d9296ae</a></p>
<p>Numpy 实现:<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">KMeans</span>:</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">__init__</span><span class="params">(self, k, max_iter=<span class="number">1000</span>, stop_var=<span class="number">1e-03</span>, dist_type=<span class="string">'l1'</span>)</span>:</span></span><br><span class="line">        self.num_cluster = k</span><br><span class="line">        self.max_iter = max_iter</span><br><span class="line">        self.stop_var = stop_var</span><br><span class="line">        self.dist_type = dist_type</span><br><span class="line">        self.variance = <span class="number">10</span> * stop_var</span><br><span class="line">        self.dists = <span class="keyword">None</span></span><br><span class="line">        self.labels = <span class="keyword">None</span></span><br><span class="line">        self.centers = <span class="keyword">None</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">fit</span><span class="params">(self, samples)</span>:</span></span><br><span class="line">        <span class="comment"># 随机初始化 centers 点, 更好的方法可以使用 sklearn 的 kmeans++ 初始化方法</span></span><br><span class="line">        init_row = np.random.randint(<span class="number">0</span>, samples.shape[<span class="number">0</span>], self.num_cluster)</span><br><span class="line">        init_points = samples[init_row]</span><br><span class="line">        self.centers = init_points</span><br><span class="line">        <span class="keyword">for</span> cur_iter <span class="keyword">in</span> range(self.max_iter):</span><br><span class="line">            self.update_dists(samples) <span class="comment"># 更新样本到各个 centers 的距离, 同时更新每个样本点对应的center类</span></span><br><span class="line">            self.update_centers(samples) <span class="comment"># 更新各个 centers</span></span><br><span class="line">            <span class="keyword">if</span> self.variance &lt; self.stop_var: <span class="comment"># 如果 centers 更新停止, 则提前退出</span></span><br><span class="line">                print(<span class="string">"cur_iter:"</span>, cur_iter)</span><br><span class="line">                <span class="keyword">break</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">l1_distance</span><span class="params">(self, sample)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> np.sum(np.abs(sample - self.centers), axis=<span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">l2_distance</span><span class="params">(self, sample)</span>:</span></span><br><span class="line">        <span class="keyword">return</span> np.sqrt(np.sum(np.square(sample - self.centers), axis=<span class="number">1</span>))</span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">update_dists</span><span class="params">(self, samples)</span>:</span></span><br><span class="line">        labels = np.empty(samples.shape[<span class="number">0</span>]) <span class="comment"># shape: [N, 1]</span></span><br><span class="line">        dists = np.empty((<span class="number">0</span>, self.num_cluster)) <span class="comment"># shape: [N, n_cluster]</span></span><br><span class="line">        <span class="keyword">for</span> i, sample <span class="keyword">in</span> enumerate(samples):</span><br><span class="line">            <span class="keyword">if</span> self.dist_type == <span class="string">'l1'</span>:</span><br><span class="line">                dist = self.l1_distance(sample)</span><br><span class="line">            <span class="keyword">elif</span> self.dist_type == <span class="string">'l2'</span>:</span><br><span class="line">                dist = self.l2_distance(sample)</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                <span class="keyword">assert</span> <span class="keyword">True</span></span><br><span class="line">            labels[i] = np.argmin(dist) <span class="comment"># 距离最小的center就是该样本对应的类</span></span><br><span class="line">            dists = np.vstack((dists, dist[np.newaxis, :])) <span class="comment"># 将该样本对应的各个center距离加入到dists中</span></span><br><span class="line">        <span class="keyword">if</span> self.dists <span class="keyword">is</span> <span class="keyword">not</span> <span class="keyword">None</span>:</span><br><span class="line">            self.variance = np.sum(np.abs(self.dists - dists))</span><br><span class="line">        self.dists = dists <span class="comment"># 更新</span></span><br><span class="line">        self.labels = labels <span class="comment"># 更新</span></span><br><span class="line"></span><br><span class="line">    <span class="function"><span class="keyword">def</span> <span class="title">update_centers</span><span class="params">(self, samples)</span>:</span></span><br><span class="line">        centers = np.empty((<span class="number">0</span>, samples.shape[<span class="number">1</span>]))</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(self.num_cluster):</span><br><span class="line">            mask = (self.labels == i)</span><br><span class="line">            center_samples = samples[mask]</span><br><span class="line">            <span class="keyword">if</span> len(center_samples) != <span class="number">0</span>:</span><br><span class="line">                center = np.mean(center_samples, axis=<span class="number">0</span>)</span><br><span class="line">            <span class="keyword">else</span>:<span class="comment"># 说明 centers 点出现了重复情况, 导致某个点类没有样本与它对应, 这种情况要报警告, 因为最终解通常无法形成合理的簇划分</span></span><br><span class="line">                center = self.centers[i]</span><br><span class="line">            centers = np.vstack((centers, center[np.newaxis, :]))</span><br><span class="line">        self.centers = centers</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    samples = np.random.rand(<span class="number">1000</span>, <span class="number">4</span>) <span class="comment"># 样本量 N=1000, 每个样本特征维度为 d=10</span></span><br><span class="line">    print(samples.shape)</span><br><span class="line">    num_cluster = <span class="number">5</span> <span class="comment"># 簇个数为 5</span></span><br><span class="line">    kmeans = KMeans(num_cluster)</span><br><span class="line">    kmeans.fit(samples)</span><br><span class="line">    print(kmeans.centers)</span><br></pre></td></tr></table></figure></p>
<h3 id="K-Means-实现-anchor-划分"><a href="#K-Means-实现-anchor-划分" class="headerlink" title="K-Means 实现 anchor 划分"></a>K-Means 实现 anchor 划分</h3><p>实现堆 anchor 的 K-Means 聚类算法, 核心思想和常规的聚类实现相同, 不同之处在于 “距离” 的定义, 和更新<code>centers</code>的方式, 具体来说就是:</p>
<ul>
<li>距离: 用<code>1-iou</code>定义每个框与<code>centers</code>之间的距离, iou越大, 距离越近</li>
<li>更新: <code>centers</code>更新时, 采用<code>np.median</code>选择当前类中的中位数box作为新的 center.</li>
</ul>
<p><strong>注意, 由于确定 anchor 时, 我们仅仅只需要样本框的宽和高这两个信息即可, 不需要知道样本的具体location, 所以, 在传入<code>boxes</code>时, 我们传入的是 [N, 2] 维度的数据, 其中 N 代表 box 的数量, 2 代表每个 box 的 (w, h)</strong></p>
<p>K-Means 算法 numpy 实现:<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cal_iou</span><span class="params">(box, clusters)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Calculates the Intersection over Union (IoU) between a box and k clusters.</span></span><br><span class="line"><span class="string">    :param box: tuple or array, shifted to the origin (i. e. width and height)</span></span><br><span class="line"><span class="string">    :param clusters: numpy array of shape (k, 2) where k is the number of clusters</span></span><br><span class="line"><span class="string">    :return: numpy array of shape (k, 0) where k is the number of clusters</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    min_w = np.minimum(box[<span class="number">0</span>], clusters[:, <span class="number">0</span>])</span><br><span class="line">    min_h = np.minimum(box[<span class="number">1</span>], clusters[:, <span class="number">1</span>])</span><br><span class="line">    intersection = min_w * min_h</span><br><span class="line">    <span class="keyword">if</span> (np.count_nonzero(intersection == <span class="number">0</span>) &gt; <span class="number">0</span>):</span><br><span class="line">        <span class="keyword">raise</span> ValueError(<span class="string">"Boxes has no areaes"</span>)</span><br><span class="line">    box_area = box[<span class="number">0</span>] * box[<span class="number">1</span>]</span><br><span class="line">    clusters_area = clusters[:, <span class="number">0</span>] * clusters[:, <span class="number">1</span>]</span><br><span class="line">    iou = (intersection) / (box_area + clusters_area - intersection)</span><br><span class="line">    <span class="keyword">return</span> iou</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">cal_avg_iou</span><span class="params">(boxes, clusters)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Calculates the average Intersection over Union (IoU) between a numpy array of boxes and k clusters.</span></span><br><span class="line"><span class="string">    :param boxes: numpy array of shape (r, 2), where r is the number of rows</span></span><br><span class="line"><span class="string">    :param clusters: numpy array of shape (k, 2) where k is the number of clusters</span></span><br><span class="line"><span class="string">    :return: average IoU as a single float</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    <span class="keyword">return</span> np.mean([np.max(cal_iou(boxes[i], clusters)) <span class="keyword">for</span> i <span class="keyword">in</span> range(boxes.shape[<span class="number">0</span>])])</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">kmeans_anchor</span><span class="params">(boxes, n_clusters)</span>:</span></span><br><span class="line">    <span class="string">"""</span></span><br><span class="line"><span class="string">    Calculates k-means clustering with the Intersection over Union (IoU) metric.</span></span><br><span class="line"><span class="string">    :param boxes: numpy array of shape (r, 2), where r is the number of rows</span></span><br><span class="line"><span class="string">    :param n_clusters: number of clusters</span></span><br><span class="line"><span class="string">    :return: numpy array of shape (k, 2)</span></span><br><span class="line"><span class="string">    """</span></span><br><span class="line">    n_boxes = boxes.shape[<span class="number">0</span>]</span><br><span class="line">    distances = np.empty([n_boxes, n_clusters]) <span class="comment"># 占位, 记录每个box与center的iou距离</span></span><br><span class="line">    last_clusters = np.empty([n_boxes])</span><br><span class="line">    clusters = boxes[np.random.choice(n_boxes, n_clusters, replace=<span class="keyword">False</span>)]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">while</span> <span class="keyword">True</span>:</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(n_boxes):</span><br><span class="line">            distances[i] = <span class="number">1</span> - cal_iou(boxes[i], clusters) <span class="comment"># 距离定义为 1 - iou, iou越大, 距离越近</span></span><br><span class="line"></span><br><span class="line">        nearest_clusters = np.argmin(distances, axis = <span class="number">1</span>) <span class="comment"># 选择距离最近的作为box的类别</span></span><br><span class="line"></span><br><span class="line">        <span class="keyword">if</span> (last_clusters == nearest_clusters).all(): <span class="comment"># 如果距离不再更新, 则退出</span></span><br><span class="line">            <span class="keyword">return</span> clusters</span><br><span class="line"></span><br><span class="line">        <span class="keyword">for</span>  i <span class="keyword">in</span> range(n_clusters): <span class="comment"># 更新 centers, 使用所有属于该类的中位数box作为新center</span></span><br><span class="line">            clusters[i] = np.median(boxes[(nearest_clusters==i)], axis=<span class="number">0</span>)</span><br><span class="line"></span><br><span class="line">        last_clusters = nearest_clusters</span><br></pre></td></tr></table></figure></p>
<p>下面我们以 VOC 数据格式为例, 来使用上面的 K-Means 算法<br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> glob</span><br><span class="line"><span class="keyword">import</span> xml.etree.ElementTree <span class="keyword">as</span> ET</span><br><span class="line"></span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="keyword">from</span> kmeans_anchor <span class="keyword">import</span> kmeans_anchor, cal_avg_iou</span><br><span class="line"></span><br><span class="line"><span class="comment"># VOC 格式的数据标注</span></span><br><span class="line">ANNOTATIONS_PATH = <span class="string">"/media/zerozone/WinD/DataSets/VOC/VOCdevkit/VOC2007/Annotations/"</span></span><br><span class="line"><span class="comment"># ANNOTATIONS_PATH = "/media/zerozone/WinD/Ubuntu/BackUp/Works/Competition/DC/VOC_trans/Annotations"</span></span><br><span class="line">CLUSTERS = <span class="number">5</span></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">load_dataset</span><span class="params">(path)</span>:</span></span><br><span class="line">	dataset = []</span><br><span class="line">	<span class="keyword">for</span> xml_file <span class="keyword">in</span> glob.glob(<span class="string">"&#123;&#125;/*xml"</span>.format(path)):</span><br><span class="line">		tree = ET.parse(xml_file)</span><br><span class="line"></span><br><span class="line">		height = int(tree.findtext(<span class="string">"./size/height"</span>))</span><br><span class="line">		width = int(tree.findtext(<span class="string">"./size/width"</span>))</span><br><span class="line"></span><br><span class="line">		<span class="keyword">for</span> obj <span class="keyword">in</span> tree.iter(<span class="string">"object"</span>):</span><br><span class="line">			xmin = int(obj.findtext(<span class="string">"bndbox/xmin"</span>)) / width</span><br><span class="line">			ymin = int(obj.findtext(<span class="string">"bndbox/ymin"</span>)) / height</span><br><span class="line">			xmax = int(obj.findtext(<span class="string">"bndbox/xmax"</span>)) / width</span><br><span class="line">			ymax = int(obj.findtext(<span class="string">"bndbox/ymax"</span>)) / height</span><br><span class="line"></span><br><span class="line">			dataset.append([xmax - xmin, ymax - ymin])</span><br><span class="line"></span><br><span class="line">	<span class="keyword">return</span> np.array(dataset)</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">print(<span class="string">"loading dataset:"</span>, ANNOTATIONS_PATH)</span><br><span class="line">data = load_dataset(ANNOTATIONS_PATH)</span><br><span class="line">print(<span class="string">"loaded successfully!"</span>)</span><br><span class="line">print(<span class="string">"calculating kmeans: cluster_num=&#123;&#125;"</span>.format(CLUSTERS))</span><br><span class="line">out = kmeans_anchor(data, CLUSTERS) <span class="comment"># 计算 kmeans</span></span><br><span class="line">print(<span class="string">"Accuracy: &#123;:.2f&#125;%"</span>.format(cal_avg_iou(data, out) * <span class="number">100</span>)) <span class="comment"># 计算 avg_iou</span></span><br><span class="line">print(<span class="string">"Boxes:\n &#123;&#125;"</span>.format(out))</span><br><span class="line"></span><br><span class="line">ratios = np.around(out[:, <span class="number">0</span>] / out[:, <span class="number">1</span>], decimals=<span class="number">2</span>).tolist()</span><br><span class="line">print(<span class="string">"Ratios:\n &#123;&#125;"</span>.format(sorted(ratios)))</span><br></pre></td></tr></table></figure></p>
<p><span id="XGBoost"></span></p>
<h2 id="XGBoost"><a href="#XGBoost" class="headerlink" title="XGBoost"></a>XGBoost</h2><p><span id="Bagging"></span></p>
<h2 id="Bagging"><a href="#Bagging" class="headerlink" title="Bagging"></a>Bagging</h2><ul>
<li><a href="../机器学习-聚类分析/#简单介绍常用的聚类方法">简单介绍常用的聚类方法</a></li>
</ul>
<h1 id="深度学习篇"><a href="#深度学习篇" class="headerlink" title="深度学习篇"></a>深度学习篇</h1><p><span id="优化方法"></span></p>
<h2 id="优化方法"><a href="#优化方法" class="headerlink" title="优化方法"></a>优化方法</h2><p><a href="../深度学习-各种优化方法整理总结">各种优化方法整理总结</a></p>
<p><strong>梯度下降:</strong> SGD, Momentum, Nesterov, Adagrad, Adadelta, RMSprop, Adam, Adamax<br><strong>牛顿法:</strong><br><strong>拟牛顿法:</strong><br><strong>共轭梯度法:</strong></p>
<h3 id="简述各种优化方法的概念及其优缺点"><a href="#简述各种优化方法的概念及其优缺点" class="headerlink" title="简述各种优化方法的概念及其优缺点"></a><a href="../深度学习-各种优化方法整理总结/#简述各种优化方法的概念及其优缺点">简述各种优化方法的概念及其优缺点</a></h3><script type="math/tex; mode=display">\theta_t = \theta_{t-1} + \Delta \theta_t</script><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">名称</th>
<th style="text-align:center">公式</th>
<th style="text-align:left">优化方法简述</th>
<th style="text-align:left">优点</th>
<th style="text-align:left">缺点</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">SGD</td>
<td style="text-align:center">$g_t = \nabla_{\theta_{t-1}} f(\theta_{t-1})$ <br> $\Delta \theta_t = - \eta \times g_t$</td>
<td style="text-align:left">每一次都计算mini-batch的梯度, 然后对参数进行更新. 公式中的 $\eta$ 是学习率, $g_t$ 是当前 batch 的梯度</td>
<td style="text-align:left">在合理的学习率和相应的衰减策略下, 通常能够优化到一个不错的点, 配合下面的 Momentum, 通常可以获得比自适应方法更优的点</td>
<td style="text-align:left">(1) 因为要兼顾整个神经网络中所有参数的训练效果, 因此对学习率的选择比较敏感. (2) SGD 容易收敛到局部最优, 并且在某些情况下容易被困在鞍点( <strong>这句话是不对的, 只有在特定的 inital point 时才会被困在鞍点, 通常情况下, 我们使用 random inital point, 被困在鞍点的概率非常小, 当使用合适的初始化和步长时, 几乎不会出现鞍点问题</strong> ); (3) 参数的更新仅仅依赖于当前 batch 中的数据, 当数据分布波动较大时, 更新往往不够稳定</td>
</tr>
<tr>
<td style="text-align:center">SGD+Momentum</td>
<td style="text-align:center">$g_t = \nabla_{\theta_{t-1}} f(\theta_{t-1})$ <br> $m_t = \mu \times m_{t-1} + g_t$ <br> $\Delta \theta_t = -\eta \times m_t$</td>
<td style="text-align:left">公式中的 $\mu$ 为动量因子, 通常取值 0.9 或 0.99, 借助于物理学里面动量的概念, 通过动量的积累来在相关方向上加速 SGD 优化速度, 抑制震荡, 同时有助于跳出局部最优, 进而加快收敛. <strong>注意, 这里动量的添加并不是滑动平均</strong></td>
<td style="text-align:left">(1) 下降初期, 动量因子可以加速网络的训练速度; (2) 当遇到鞍点时, 梯度虽然为零, 但是动量不为零, 可以跳出鞍点(局部最优) ; (3) 在梯度改变方向时, 能够降低更新幅度, 减小震荡, 加速网络收敛; 总之, momentum 项能够在相关方向加速 SGD, 抑制震荡, 从而加快收敛</td>
<td style="text-align:left">需要人工设置学习率</td>
</tr>
<tr>
<td style="text-align:center">SGD+Nesterov</td>
<td style="text-align:center">$g_t=\nabla_{\theta_{t-1}} f(\theta_{t-1} - \eta \times \mu \times m_{t-1})$ <br> $m_t = \mu \times m_{t-1} + g_t$ <br> $\Delta \theta_t = -\eta \times m_t$</td>
<td style="text-align:left">可以看出, Nesterov 与 Momentum 公式的区别在于, 前者不是在当前的位置上求梯度, 而是根据本来计划要走的那一步提前前进一步以后, 再在新的位置上求梯度, 然后对这个新求得的梯度进行 Momentum 梯度下降计算</td>
<td style="text-align:left">(1) 先站在下一步的位置看看, 再进行更新, 使得梯度更新方向更具前瞻性; (2) 实际使用中, NAG 会比 Momentum 收敛的速度更快</td>
<td style="text-align:left">(1) 需要人工设置学习率</td>
</tr>
<tr>
<td style="text-align:center">AdaGrad</td>
<td style="text-align:center">$n_t = n_{t-1} + g^2_t$ <br> $\Delta \theta_t = -\frac{\eta}{\sqrt{n_t + \epsilon}} \times g_t$</td>
<td style="text-align:left">Adagrad相当于在学习率前面乘了一个约束项 $\frac{1}{\sqrt {n_t + \epsilon}}$, 该约束项会随着算法的不断迭代而越来越大, 那么对应学习率就会越来越小, 也就是说 Adagrad 算法在开始时是大步前进的, 而在后面则会减小步伐, 缓慢收敛</td>
<td style="text-align:left">(1) 在整个更新期间学习率不是固定的, 会随着训练过程变化; (2) 适合面对稀疏梯度; (3) 对于每一个不同的参数, 其具有不同的学习率, 当参数梯度较大时, 其约束项会使得步长变小, 返回, 会令步长变大, 动态调节</td>
<td style="text-align:left">(1) 仍然依赖于一个人工设置的全局学习率; (2) 中后期, 分母上的梯度累加和会越来越大, 使得更新提早停滞, 训练提前结束</td>
</tr>
<tr>
<td style="text-align:center">AdaDelta</td>
<td style="text-align:center">$Eg^2_t = \rho\times Eg^2_{t-1} + (1-\rho)\times g^2_t$ <br> $\Delta \theta_t = -\frac{\eta}{\sqrt{Eg^2_t + \epsilon}} g_t$ <br> $= -\frac{\eta}{RMS[g]_t} g_t$ <br> $= -\frac{RMS[\Delta\theta]_{t-1}}{RMS[g]_t} g_t$ <br> $RMS[\Delta \theta]_t = \sqrt{E[\Delta \theta^2]_t + \epsilon}$ <br> $E[\Delta \theta^2]_t = \gamma E[\Delta \theta^2]_{t-1} + (1-\gamma)\Delta \theta^2_t$</td>
<td style="text-align:left">Adadelta是对Adagrad的扩展, 和 Adagrad 相比, 其改进是将分母约束项换成了 <strong>过去的梯度平方的衰减平均值</strong>, 相当于梯度的均方根(root mean squared, RMS), 此外, 如果将学习率也换成 $RMS[\Delta \theta]$ 的话, 甚至可以不用设置学习率了</td>
<td style="text-align:left">(1) 对 Adagrad 的扩展, 约束项只计算梯度平方一段时间内的平均值, 而不是累计值, 不容易产生太大值而使得更新提早结束; (2) 无需人工设置学习率, 可以动态改变学习率的大小;</td>
<td style="text-align:left">(1) 训练后期会反复在局部最小值附近抖动(why?)</td>
</tr>
<tr>
<td style="text-align:center">RMSprop</td>
<td style="text-align:center">$Eg^2_t = \rho\times Eg^2_{t-1} + (1-\rho)\times g^2_t$ <br> $\Delta \theta_t = -\frac{\eta}{\sqrt{Eg^2_t + \epsilon}} g_t$</td>
<td style="text-align:left">RMSprop可以算作是Adadelta的一个特例, 可以看出 RMSprop 仍然需要设置全局学习率</td>
<td style="text-align:left">(1) Adadelta 的特例, 也是对学习率添加约束, 适合处理非平稳目标, 对 RNN 效果较好</td>
<td style="text-align:left">(1) …</td>
</tr>
<tr>
<td style="text-align:center">Adam</td>
<td style="text-align:center">$m_t = \beta_1 \times m_{t-1} + (1-\beta_1) \times g_t$ <br> $n_t = \beta_2 \times n_{t-1} + (1 - \beta_2) \times g^2_t$ <br> $\hat m_t = \frac{m_t}{1-\beta_1^t}$ <br> $\hat n_t = \frac{n_t}{1- \beta_2^t}$ <br> $\Delta \theta_t = -\frac{\hat m_t}{\sqrt{\hat n_t} + \epsilon} \times \eta$</td>
<td style="text-align:left">Adam本质上是带有 <strong>动量项(分子部分)</strong> 的 RMSprop, 它利用 <strong>修正后的</strong> 梯度的一阶矩估计和二阶矩估计动态调整每个参数的学习率. 公式中, $m_t, n_t$ 分别是对梯度的一阶矩估计和二阶矩估计, 可以看做是对期望 $E g_t$, $E g^2_t$ 的估计, $\hat m_t$, $\hat n_t$ 是对 $m_t$, $n_t$ 的校正, 这样可以近似为对期望的无偏估计</td>
<td style="text-align:left">(1) 经过偏置校正后, 每一次迭代学习率都有一个确定的范围, 使得参数更新比较平稳; (2) 结合了动量 RMSprop 的优点; 既可以加速收敛, 又可以根据梯度的大小动态调节每个参数的学习步长 (3) 对内存需求较小; (4) 适用于大多非凸优化, 适用于大数据集和高维空间; (5) 超参数可以比较直观的解释, 同时只需要极少量的调参</td>
<td style="text-align:left">最终的收敛点通常比经过精心调参后的 SGD+Momentum 的收敛点差一些. 常取参数值: $\beta_1 = 0.9$, $\beta_2 = 0.999$, $\epsilon = 10^{-8}$</td>
</tr>
<tr>
<td style="text-align:center">Adamax</td>
<td style="text-align:center">$n_t = max(\nu \times, abs(g_t))$ <br> $\Delta x = -\frac{\hat m_t}{n_t + \epsilon}\times\eta$</td>
<td style="text-align:left">Adamax 是 Adam 的一种变体, 此方法对学习率的上限提供了一个更简单的范围, 可以看出, 学习率的边界范围更加简单</td>
<td style="text-align:left">…</td>
<td style="text-align:left">…</td>
</tr>
<tr>
<td style="text-align:center">Nadam(PyTorch 目前未实现该接口)</td>
<td style="text-align:center">…</td>
<td style="text-align:left">…</td>
<td style="text-align:left">…</td>
<td style="text-align:left">…</td>
</tr>
</tbody>
</table>
</div>
<h3 id="各损失函数更新动画"><a href="#各损失函数更新动画" class="headerlink" title="各损失函数更新动画"></a>各损失函数更新动画</h3><p><div style="width: 500px; margin: auto"><img src="http://zerozone-blog.oss-cn-beijing.aliyuncs.com/SummaryOfComputerVision/optim1.gif" alt="SummaryOfComputerVision%2Foptim1.gif"></div></p>
<p><div style="width: 500px; margin: auto"><img src="http://zerozone-blog.oss-cn-beijing.aliyuncs.com/SummaryOfComputerVision/optim2.gif" alt="SummaryOfComputerVision%2Foptim2.gif"></div></p>
<h3 id="如何选择合适的优化方法"><a href="#如何选择合适的优化方法" class="headerlink" title="如何选择合适的优化方法"></a>如何选择合适的优化方法</h3><ul>
<li>SGD+Momentum 相比于自适应优化器通常训练时间长, 但是经过多次调节后, 在好的学习率和衰减方案的情况下, 结果更优</li>
<li>AdaGrad, RMSprop, Adam 等适合希望得到快速结果的情况下使用</li>
<li>在训练较深层的网络时, 也推荐先使用 Adam 方法进行正确性验证, 然后再使用 SGD+Momentum 微调.</li>
<li>在使用 RMSprop 和 Adam 的地方, 大多可以使用 Nadam 取得更好的效果.</li>
<li>在实际训练中比较好的方法是: 先用 Adam 预训练一段时间, 然后使用 SGD+Momentum, 以达到最佳性能. Adam vs SGD 的表现通常如下图所示, 由于鲁棒性和自适应的学习速率, Adam 在一开始表现更好, 而 SGD 最终更容易达到全局最优.</li>
</ul>
<p><div style="width: 500px; margin: auto"><img src="http://zerozone-blog.oss-cn-beijing.aliyuncs.com/SummaryOfComputerVision/adam_vs_sgd.jpg?x-oss-process=style/blog_img" alt="SummaryOfComputerVision%2Fadam_vs_sgd.jpg"></div></p>
<h3 id="一阶矩-二阶矩的计算方法及其代表的含义"><a href="#一阶矩-二阶矩的计算方法及其代表的含义" class="headerlink" title="一阶矩, 二阶矩的计算方法及其代表的含义"></a>一阶矩, 二阶矩的计算方法及其代表的含义</h3><p>原点矩: 设 $X$ 是随机变量, 则称 $E(X^k)$ 为 $X$ 的 $k$ 阶矩估计; 零阶原点矩恒为 1, 一阶原点矩代表期望, 二阶原点距为平方的期望;<br>中心距: 设 $X$ 是随机变量, 则称 $E\{ [X - E(X)]^k\}$ 为随机变量 $X$ 的 $k$ 阶中心矩; 零阶中心矩恒为 1, 一阶中心矩恒为 0, 二阶中心距为方差;</p>
<p>期望: 一阶样本原点矩来估计总体的期望<br>方差: 二阶样本中心距来估计总体的方差</p>
<p>由此可看出, Adam, RMSprop 等算法, 使用的都是一阶原点矩和二阶原点矩. 并且是利用滑动平均法来对一阶矩和二阶矩进行估计.</p>
<h3 id="简述-Adam-中使用的指数加权滑动平均法"><a href="#简述-Adam-中使用的指数加权滑动平均法" class="headerlink" title="简述 Adam 中使用的指数加权滑动平均法"></a><a href="../深度学习-各种优化方法整理总结/#简述 Adam 中使用的指数加权滑动平均法">简述 Adam 中使用的指数加权滑动平均法</a></h3><p>加权滑动平均法, 就是对观察值分别属于不同的权重, 按不同的权重来求最终的滑动平均值.  而指数加权滑动平均法就是指各个观察值的加权系数随着时间呈指数递减, 越靠近当前时刻的观察值权重越大. 公式如下:</p>
<script type="math/tex; mode=display">v_t = \beta v_{t-1} + (1 - \beta) \theta_t</script><p>上式中, $\theta_t$ 代表当前时刻的观察值, 系数 $\beta$ 代表加权下降的速率, 其值越小下降的越快, $v_t$ 代表当前时刻的指数加权滑动平均值.</p>
<p>PS: 在数学中一般会以 $\frac{1}{e}$ 来作为一个临界值, 小于该值的加权系数对应的值不作考虑. 因此, 当 $\beta = 0.9$ 时, $0.9^{10}$ 约等于 $\frac{1}{e}$, 认为此时是约 10 个数值的加权平均.</p>
<p><strong>偏差修正:</strong> 当初始化 $v_0 = 0$ 时, 由于初始化的值太小, 导致初期的滑动平均值偏小, 随着时间的增长, 初期的值影响减小, 滑动平均值才逐渐正常. 为了让初期的滑动平均值也相对正常, 我们利用下面的式子进行修正:</p>
<script type="math/tex; mode=display">v_t = \frac{\beta v_{t-1} + (1 - \beta)\theta_t}{1 - \beta^t}</script><h3 id="Adam-算法的原理机制是怎么样的"><a href="#Adam-算法的原理机制是怎么样的" class="headerlink" title="Adam 算法的原理机制是怎么样的"></a>Adam 算法的原理机制是怎么样的</h3><p>Adam 算法和传统的随机梯度下降不同。随机梯度下降保持单一的学习率（即 alpha）更新所有的权重，学习率在训练过程中并不会改变。而 Adam 通过计算梯度的一阶矩估计和二阶矩估计而为不同的参数设计独立的自适应性学习率。</p>
<p>Adam 算法和传统的随机梯度下降不同。随机梯度下降保持单一的学习率（即 alpha）更新所有的权重，学习率在训练过程中并不会改变。而 Adam 通过计算梯度的一阶矩估计和二阶矩估计而为不同的参数设计独立的自适应性学习率。</p>
<p>Adam 算法的提出者描述其为两种随机梯度下降扩展式的优点集合，即：</p>
<p>适应性梯度算法（AdaGrad）为每一个参数保留一个学习率以提升在稀疏梯度（即自然语言和计算机视觉问题）上的性能。<br>均方根传播（RMSprop）基于权重梯度最近量级的均值为每一个参数适应性地保留学习率。这意味着算法在非稳态和在线问题上有很有优秀的性能。</p>
<h3 id="Adam-算法与相关的-AdaGrad-和-RMSprop-方法有什么区别"><a href="#Adam-算法与相关的-AdaGrad-和-RMSprop-方法有什么区别" class="headerlink" title="Adam 算法与相关的 AdaGrad 和 RMSprop 方法有什么区别"></a>Adam 算法与相关的 AdaGrad 和 RMSprop 方法有什么区别</h3><p>Adam 算法同时获得了 AdaGrad 和 RMSprop 算法的优点。Adam 不仅如 RMSprop 算法那样基于一阶矩均值计算适应性参数学习率，它同时还充分利用了梯度的二阶矩均值（即有偏方差/uncentered variance）。具体来说，算法计算了梯度的指数移动均值（exponential moving average），超参数 beta1 和 beta2 控制了这些移动均值的衰减率。</p>
<p>移动均值的初始值和 beta1、beta2 值接近于 1（推荐值），因此矩估计的偏差接近于 0。该偏差通过首先计算带偏差的估计而后计算偏差修正后的估计而得到提升。</p>
<p>事实上，Insofar、RMSprop、Adadelta 和 Adam 算法都是比较类似的优化算法，他们都在类似的情景下都可以执行地非常好。但是 Adam 算法的偏差修正令其在梯度变得稀疏时要比 RMSprop 算法更快速和优秀。Insofar 和 Adam 优化算法基本是最好的全局选择。同样在 CS231n 课程中，Adam 算法也推荐作为默认的优化算法。</p>
<p>虽然 Adam 算法在实践中要比 RMSprop 更加优秀，但同时我们也可以尝试 SGD+Nesterov 动量来作为 Adam 的替代。即我们通常推荐在深度学习模型中使用 Adam 算法或 SGD+Nesterov 动量法。</p>
<h3 id="Adam-算法如何调参-其常用的参数配置是怎么样的"><a href="#Adam-算法如何调参-其常用的参数配置是怎么样的" class="headerlink" title="Adam 算法如何调参, 其常用的参数配置是怎么样的"></a>Adam 算法如何调参, 其常用的参数配置是怎么样的</h3><ul>
<li>alpha：同样也称为学习率或步长因子，它控制了权重的更新比率（如 0.001）。较大的值（如 0.3）在学习率更新前会有更快的初始学习，而较小的值（如 1.0E-5）会令训练收敛到更好的性能。</li>
<li>beta1：一阶矩估计的指数衰减率（如 0.9）。</li>
<li>beta2：二阶矩估计的指数衰减率（如 0.999）。该超参数在稀疏梯度（如在 NLP 或计算机视觉任务中）中应该设置为接近 1 的数。</li>
<li>epsilon：该参数是非常小的数，其为了防止在实现中除以零（如 10E-8）。</li>
</ul>
<p>另外，学习率衰减同样可以应用到 Adam 中。原论文使用衰减率 alpha = alpha/sqrt(t) 在 logistic 回归每个 epoch(t) 中都得到更新。</p>
<p>Adam 论文建议的参数设定, 默认参数设定为：alpha=0.001、beta1=0.9、beta2=0.999 和 epsilon=10E−8。</p>
<p>我们也可以看到流行的深度学习库都采用了该论文推荐的参数作为默认设定。</p>
<ul>
<li>TensorFlow：learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-08.</li>
<li>Keras：lr=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0.</li>
<li>Blocks：learning_rate=0.002, beta1=0.9, beta2=0.999, epsilon=1e-08, decay_factor=1.</li>
<li>Lasagne：learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-08</li>
<li>Caffe：learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-08</li>
<li>MxNet：learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-8</li>
<li>Torch：learning_rate=0.001, beta1=0.9, beta2=0.999, epsilon=1e-8</li>
</ul>
<h3 id="Adam-实现优化的过程和权重更新规则"><a href="#Adam-实现优化的过程和权重更新规则" class="headerlink" title="Adam 实现优化的过程和权重更新规则"></a>Adam 实现优化的过程和权重更新规则</h3><p><div style="width: 500px; margin: auto"><img src="http://zerozone-blog.oss-cn-beijing.aliyuncs.com/SummaryOfComputerVision/adam.png?x-oss-process=style/blog_img" alt="SummaryOfComputerVision%2Fadam.png"></div></p>
<p>如上图所示, 首先确定超参 $\eta$ (学习率步长, 也就是上面的 $\alpha$), $\beta_1$, $\beta_2$, 以及目标函数 $f(\theta)$. 然后初始化参数量 $\theta = \theta_0$, 一阶矩向量 $m_0$ 和而结局向量 $n_0$ (也就是上图中的 $v_0$). 然后进行循环迭代, 直至 $\theta_t$ 收敛, 更新过程如下:</p>
<ol>
<li>时间戳 $t$ 增 1;</li>
<li>获取目标函数在当前时间戳 $t$ 上对各个参数 $\theta$ 的梯度;</li>
<li>利用当前时间戳的梯度 $g_t$ 和滑动平均公式更新当前时间戳的有偏一阶矩估计和二阶矩估计.</li>
<li>将一阶矩估计和二阶矩估计更新成无偏的;</li>
<li>有矩估计更新参数 $\theta$, 对于每一个参数, 其矩估计的值都不尽相同, 因此起到了自适应调节学习率的作用.</li>
</ol>
<h3 id="Adam-的初始化偏差修正的推导"><a href="#Adam-的初始化偏差修正的推导" class="headerlink" title="Adam 的初始化偏差修正的推导"></a>Adam 的初始化偏差修正的推导</h3><p><a href="https://www.jiqizhixin.com/articles/2017-07-12" target="_blank" rel="noopener">https://www.jiqizhixin.com/articles/2017-07-12</a></p>
<p>我们以二阶原点矩的无偏估计为例进行推导, 一阶原点矩的推导完全类似.</p>
<p>首先我们可以求得目标函数 $f$ 的梯度, 然后我们利用 <strong>梯度平方</strong> 的衰减率为 $beta_2$ 的指数滑动平均值来近似估计该梯度的 <strong>有偏的二阶原点矩</strong>.<br>令 $g_1, …, g_T$ 为时间序列上的梯度, 其中每个梯度都服从一个潜在的梯度分布 $g_t \sim P(g_t)$. 我们将指数滑动平均值初始化为 $n_0 = 0$, 然后用下面的公式更新滑动平均值($g_t^2$ 代表 element-wise multiply):</p>
<script type="math/tex; mode=display">n_t = \beta_2 \times n_{t-1} + (1-\beta_2)\times g_t^2 = (1-\beta_2) \sum_{i=1}{t} \beta_2^{t-i} \times g_i^2</script><p>我们希望知道时间戳 $t$ 上的指数滑动平均值的期望 $E[n_t]$ 如何与真实的二阶矩 $E[g_t^2]$ 相关联, 于是我们先对上式的两边分别取期望, 如下:</p>
<script type="math/tex; mode=display">E[n_t] = E[(1-\beta_2) \sum_{i=1}^{t} \beta_2^{t-i} \times g_i^2] = E[g_t^2]\times (1 - \beta_2) \sum_{i=1}^{t} \beta_2^{t-i} + C = E[g_t^2]\times (1 - \beta_2^t) + C'</script><p>通常 $C’$ 的值很小, 因此可以将其去除, 于是乎就得到了无偏估计的式子.</p>
<h3 id="Adam-的扩展形式-AdaMax"><a href="#Adam-的扩展形式-AdaMax" class="headerlink" title="Adam 的扩展形式: AdaMax"></a>Adam 的扩展形式: AdaMax</h3><h3 id="各种优化方法的源码实现"><a href="#各种优化方法的源码实现" class="headerlink" title="各种优化方法的源码实现"></a><a href="../深度学习-各种优化方法整理总结/#各种优化方法的源码实现">各种优化方法的源码实现</a></h3><h3 id="参考文献及其他"><a href="#参考文献及其他" class="headerlink" title="参考文献及其他"></a>参考文献及其他</h3><p>Adam 无法收敛?: <a href="https://www.jiqizhixin.com/articles/2017-12-06" target="_blank" rel="noopener">https://www.jiqizhixin.com/articles/2017-12-06</a><br>SGD 的参数设置</p>
<p><a href="https://www.cnblogs.com/happylion/p/4172632.html" target="_blank" rel="noopener">https://www.cnblogs.com/happylion/p/4172632.html</a></p>
<p><a href="https://www.cnblogs.com/shixiangwan/p/7532830.html" target="_blank" rel="noopener">https://www.cnblogs.com/shixiangwan/p/7532830.html</a></p>
<p><a href="https://www.cnblogs.com/hlongch/p/5734105.html" target="_blank" rel="noopener">https://www.cnblogs.com/hlongch/p/5734105.html</a></p>
<p><a href="https://www.baidu.com/link?url=8EyCqGYnldJzHuqBBGagV9juEA_nhCYvRElM2Tw0lBdewSmc0qshAy_AHAEegO-wT3vLsrcY1xSDdyLOmL09Ltm_UICAFX_C02QdkkSCcWW&amp;wd=&amp;eqid=ce9adcb10004685c000000035b5d4fb6" target="_blank" rel="noopener">https://www.baidu.com/link?url=8EyCqGYnldJzHuqBBGagV9juEA_nhCYvRElM2Tw0lBdewSmc0qshAy_AHAEegO-wT3vLsrcY1xSDdyLOmL09Ltm_UICAFX_C02QdkkSCcWW&amp;wd=&amp;eqid=ce9adcb10004685c000000035b5d4fb6</a></p>
<p><a href="https://mp.weixin.qq.com/s/lh4jTYJroq6AKb2fYsP-GQ" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/lh4jTYJroq6AKb2fYsP-GQ</a></p>
<p><span id="初始化方法"></span></p>
<h2 id="初始化方法"><a href="#初始化方法" class="headerlink" title="初始化方法"></a>初始化方法</h2><p><a href="../深度学习-各种初始化方法深入分析">深度学习-各种初始化方法深入分析</a></p>
<p>constant, uniform, gaussian, xavier, msra(kaiming), bilinear</p>
<h3 id="各个初始化方法的形式"><a href="#各个初始化方法的形式" class="headerlink" title="各个初始化方法的形式,"></a>各个初始化方法的形式,</h3><div class="table-container">
<table>
<thead>
<tr>
<th>初始化方法</th>
<th>服从分布</th>
<th>说明</th>
</tr>
</thead>
<tbody>
<tr>
<td>均匀分布</td>
<td>…</td>
<td>将权值与偏置进行均匀分布的初始化</td>
</tr>
<tr>
<td>高斯分布</td>
<td>…</td>
<td>初始化为服从 $N(\mu, \sigma ^2)$ 的高斯分布</td>
</tr>
<tr>
<td>Xavier</td>
<td>$W \sim U\Big[-\frac{\sqrt{6}}{\sqrt{n_j+n_{j+1}}},\frac{\sqrt{6}}{\sqrt{n_j + n_{j+1}}}  \Big]$, <br> 服从均值为 0, 方差为 $\frac{2}{n_i + n_{i+1}}$ 的均匀分布</td>
<td>公式中, $n_i$ 为本层输入的神经元个数, $n_{i+1}$ 为本层输出的神经元个数, 适合于线性激活函数(原文公式推导的假设)</td>
</tr>
<tr>
<td>MSRA(Kaiming)</td>
<td>基于均值为0, 方差为 $\sqrt{\frac{2}{(1+a^2)\times fan_{in}}}$ 的高斯分布</td>
<td>它特别适合 ReLU 激活函数(非线性)</td>
</tr>
<tr>
<td>双线性初始化</td>
<td>…</td>
<td>常用在反卷积网络里的权值初始化</td>
</tr>
</tbody>
</table>
</div>
<h3 id="Xavier-初始化推导"><a href="#Xavier-初始化推导" class="headerlink" title="Xavier 初始化推导"></a>Xavier 初始化推导</h3><p><strong>核心理念是: 优秀的初始化方法应该使得各层的激活值和状态梯度在传播过程中的方差保持一致</strong></p>
<p>再继续推导之前, 需要先提出以下假设:</p>
<ul>
<li>首先,输入数据来说,其均值和方差应满足: $E(x)=0, Var(x)=1$ (通过BN,较容易满足)</li>
<li>权重矩阵 $W$ 和 网络输入 $x$ 互相独立</li>
<li>每层输入的每个特征方差一样</li>
<li>激活函数对称: 这主要是为了满足均值为0的假设</li>
<li>激活函数是线性的, 也就是说其导数为1</li>
<li>初始时, 状态值落在激活函数的线性区域, 即此时导数为1</li>
</ul>
<p>现在假设有一个 $n$ 维的输入向量 $\vec X$ 和一个单层的线性神经网络, 它的权重向量是 $\vec W$, 网络的输出是 $Y$, 则有:</p>
<script type="math/tex; mode=display">Y = W_1 X_1 + W_2 X_2 + ... + W_n X_n</script><p>对于每个 $W_i X_i$, 它对应的方差为:</p>
<script type="math/tex; mode=display">Var(W_i X_i) = E(X_i)^2 Var(W_i) + E(W_i)^2 Var(X_i) + Var(X_i) Var(W_i)</script><p>当输入的 $X$ 均值为 0 时(通过 BN, 较容易满足), 输出的方差就是:</p>
<script type="math/tex; mode=display">Var(W_i X_i) = Var(W_i)Var(X_i)</script><p>进一步假设 $W_i$ 和 $X_i$ 是独立同分布的, 就可以得到:</p>
<script type="math/tex; mode=display">Var(Y) = n\times Var(W_i) Var(X_i)</script><p>也就是说输出的方差跟输入的方差只是相差了一个倍数 $nVar(W_i)$, 因此, 为了保证前向传播和反向传播时每一层的方差一致, 则有下面的公式成立:</p>
<script type="math/tex; mode=display">\forall i, n_i Var[W^i] = 1</script><p>同时考虑反向传播时输入输出刚好相反, 于是就有:</p>
<script type="math/tex; mode=display">\forall i, n_{i+1} Var[W^i] =1</script><p>权衡上面两个公式, 最终给出的权重方差为:</p>
<script type="math/tex; mode=display">\forall, Var[W^i] = \frac {2}{n_i + n_{i+1}}</script><p>再由概率统计中均匀分布方差的性质反推,可以得到Xavier最终的初始化分布如下:</p>
<script type="math/tex; mode=display">W \sim U\Big[-\frac{\sqrt{6}}{\sqrt{n_j+n_{j+1}}},\frac{\sqrt{6}}{\sqrt{n_j+n_{j+1}}}  \Big]</script><p><strong>Xavier在Caffe中的具体实现:</strong></p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">template</span> &lt;<span class="keyword">typename</span> Dtype&gt;</span><br><span class="line"><span class="class"><span class="keyword">class</span> <span class="title">XavierFiller</span> :</span> <span class="keyword">public</span> Filler&lt;Dtype&gt; &#123;</span><br><span class="line"> <span class="keyword">public</span>:</span><br><span class="line">  <span class="function"><span class="keyword">explicit</span> <span class="title">XavierFiller</span><span class="params">(<span class="keyword">const</span> FillerParameter&amp; param)</span></span></span><br><span class="line">      : Filler&lt;Dtype&gt;(param) &#123;&#125;</span><br><span class="line">  <span class="function"><span class="keyword">virtual</span> <span class="keyword">void</span> <span class="title">Fill</span><span class="params">(Blob&lt;Dtype&gt;* blob)</span> </span>&#123;</span><br><span class="line">    CHECK(blob-&gt;count());</span><br><span class="line">    <span class="keyword">int</span> fan_in = blob-&gt;count() / blob-&gt;num();</span><br><span class="line">    <span class="keyword">int</span> fan_out = blob-&gt;count() / blob-&gt;channels();</span><br><span class="line">    Dtype n = fan_in;  <span class="comment">// default to fan_in</span></span><br><span class="line">    <span class="keyword">if</span> (<span class="keyword">this</span>-&gt;filler_param_.variance_norm() ==</span><br><span class="line">        FillerParameter_VarianceNorm_AVERAGE) &#123;</span><br><span class="line">      n = (fan_in + fan_out) / Dtype(<span class="number">2</span>);</span><br><span class="line">    &#125; <span class="keyword">else</span> <span class="keyword">if</span> (<span class="keyword">this</span>-&gt;filler_param_.variance_norm() ==</span><br><span class="line">        FillerParameter_VarianceNorm_FAN_OUT) &#123;</span><br><span class="line">      n = fan_out;</span><br><span class="line">    &#125;</span><br><span class="line">    Dtype scale = <span class="built_in">sqrt</span>(Dtype(<span class="number">3</span>) / n);</span><br><span class="line">    caffe_rng_uniform&lt;Dtype&gt;(blob-&gt;count(), -scale, scale,</span><br><span class="line">        blob-&gt;mutable_cpu_data());</span><br><span class="line">    CHECK_EQ(<span class="keyword">this</span>-&gt;filler_param_.sparse(), <span class="number">-1</span>)</span><br><span class="line">         &lt;&lt; <span class="string">"Sparsity not supported by this Filler."</span>;</span><br><span class="line">  &#125;</span><br><span class="line">&#125;;</span><br></pre></td></tr></table></figure>
<p>可以看出, Caffe的Xavier实现有三种选择:</p>
<p>(1) FAN_IN, 方差只考虑输入个数:</p>
<script type="math/tex; mode=display">Var[W^i] = \frac{1}{n_i}</script><p>(2) FAN_OUT, 方差只考虑输出个数:</p>
<script type="math/tex; mode=display">Var[W^i] = \frac{1}{n_{i+1}}</script><p>(3) AVERAGE, 方差同时考虑输入和输出个数:</p>
<script type="math/tex; mode=display">Var[W^i] = \frac{2}{n_i + n_{i+1}}</script><h3 id="训练时是否可以将全部参数初始化为-0"><a href="#训练时是否可以将全部参数初始化为-0" class="headerlink" title="训练时是否可以将全部参数初始化为 0"></a>训练时是否可以将全部参数初始化为 0</h3><p>不能<br>首先, 在神经网络中, 每一层中的任意神经元都是同构的, 它们拥有相同的输入, 如果再将参数全部初始化为同样的值(如0), 那么输出也就是相同的, 反过来它们的梯度也都是相同的. 那么无论是前向传播还是反向传播的取值都是完全相同的, 那么每一个神经元都是基于input做相同的事情, 这样一来, 不同的神经元根本无法学到不同的特征, 这样就失去网络学习特征的意义了</p>
<p><span id="损失函数"></span></p>
<h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h2><p><a href="../深度学习-各种损失函数深入解析">深度学习-各种损失函数深入解析</a></p>
<h3 id="绝对值损失-L1"><a href="#绝对值损失-L1" class="headerlink" title="绝对值损失(L1)"></a>绝对值损失(L1)</h3><h3 id="平方损失-L2"><a href="#平方损失-L2" class="headerlink" title="平方损失(L2)"></a>平方损失(L2)</h3><script type="math/tex; mode=display">J(\theta) = \frac{1}{2} \sum_{i=1}^{m}{(h_\theta(x^{(i)}) - y^{(i)})^2}</script><h3 id="Softmax-交叉熵"><a href="#Softmax-交叉熵" class="headerlink" title="Softmax 交叉熵"></a>Softmax 交叉熵</h3><script type="math/tex; mode=display">y_i = softmax(z_j) = \frac{e^{z_j}}{\sum_j e^{z_j}}</script><script type="math/tex; mode=display">E(t,y) = -\sum_j t_j log y_j</script><p>上式中, $t$ 和 $y$ 分别表示神经网络的真实标签和预测输出, 第一个公式代表 softmax 激活函数.</p>
<h3 id="交叉熵损失"><a href="#交叉熵损失" class="headerlink" title="交叉熵损失"></a>交叉熵损失</h3><p>首先定义符号说明:</p>
<ul>
<li>$p^{(i)}$: 第i个样本类别为1的真实概率(如第i个样本真实类别为1, 则概率为1, 否则为0)</li>
<li>$o^{(i)}$: 第i个样本预测类别为1的概率</li>
<li>$p_k^{(i)}$: 第i个样本类别为k的真实概率(如第i个样本真实类别为k, 则概率为1, 否则为0)</li>
<li>$o_k^{(i)}$: 第i个样本预测类别为k的概率</li>
</ul>
<p>面对二分类问题, 损失函数形式为:</p>
<script type="math/tex; mode=display">J(W,b) = -\Big[\frac{1}{m} \sum_{i=1}{m}\big(y^{(i)}logo^{(i)} + (1-y^{(i)})log(1-o^{(i)})  \big) \Big]</script><p>面对多分类问题, 损失函数形式为:</p>
<script type="math/tex; mode=display">J(W,b) = -\Big[\frac{1}{m} \sum_{i=1}^{m} \sum_{k=1}^{n} y_k^{(i)} log o_k^{(i)}  \Big]</script><p>交叉熵衡量了两个分布之间的差异性, 当概率相等时, 交叉熵最大, 则损失函数达到最小(因为加了负号)</p>
<h3 id="Smooth-L1"><a href="#Smooth-L1" class="headerlink" title="Smooth L1"></a>Smooth L1</h3><h3 id="Focal-Loss"><a href="#Focal-Loss" class="headerlink" title="Focal Loss"></a>Focal Loss</h3><h3 id="DR-Loss"><a href="#DR-Loss" class="headerlink" title="DR Loss"></a>DR Loss</h3><h3 id="写出多层感知机的平方误差和交叉熵误差损失函数"><a href="#写出多层感知机的平方误差和交叉熵误差损失函数" class="headerlink" title="写出多层感知机的平方误差和交叉熵误差损失函数"></a>写出多层感知机的平方误差和交叉熵误差损失函数</h3><h3 id="推导平方误差和交叉熵误差损失函数的各层参数更新的梯度计算公式"><a href="#推导平方误差和交叉熵误差损失函数的各层参数更新的梯度计算公式" class="headerlink" title="推导平方误差和交叉熵误差损失函数的各层参数更新的梯度计算公式"></a>推导平方误差和交叉熵误差损失函数的各层参数更新的梯度计算公式</h3><p><span id="激活函数"></span></p>
<h2 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h2><p>Sigmoid, Tanh, ReLU, Leaky ReLU, PReLU, RReLU, ELU, Maxout</p>
<p><a href="../深度学习-各种激活函数深入解析">深度学习-各种激活函数深入解析</a></p>
<h3 id="写出常用的激活函数的公式及其导数形式"><a href="#写出常用的激活函数的公式及其导数形式" class="headerlink" title="写出常用的激活函数的公式及其导数形式"></a>写出常用的激活函数的公式及其导数形式</h3><div class="table-container">
<table>
<thead>
<tr>
<th>激活函数</th>
<th>形式</th>
<th>导数形式</th>
</tr>
</thead>
<tbody>
<tr>
<td>Sigmoid</td>
<td>$f(x) =\frac{1}{1+e^{-x}}$</td>
<td>$f’(x) = f(x)(1-f(x))$</td>
</tr>
<tr>
<td>Tanh</td>
<td>$f(x) = tanh(x)= \frac{e^x-e^{-x}}{e^x+e^{-x}}$</td>
<td>$f’(x) = 1-(f(z))^2$</td>
</tr>
<tr>
<td>ReLU</td>
<td>$f(x)=max(0,x)=\begin{cases} 0 &amp; x \leq 0 \\ x &amp; x&gt;0 \end{cases}$</td>
<td>$f’(x)=\begin{cases} 0 &amp; x\leq 0 \\ 1 &amp; x&gt;0 \end{cases}$</td>
</tr>
<tr>
<td>Leaky ReLU</td>
<td>$f(x)=max(0.001 x,x)=\begin{cases} 0.001x &amp; x \leq 0 \\ x &amp; x&gt;0 \end{cases}a$</td>
<td>$f(x)=max(0.001 x,x)=\begin{cases} 0.001  &amp; x \leq 0 \\ 1 &amp; x&gt;0 \end{cases}$</td>
</tr>
<tr>
<td>PReLU</td>
<td>$f(x)=max(\alpha x,x)=\begin{cases} \alpha x &amp; x \leq 0 \\ x &amp; x&gt;0 \end{cases}$</td>
<td>$f(x)=max(\alpha x,x)=\begin{cases} \alpha  &amp; x \leq 0 \\ 1 &amp; x&gt;0 \end{cases}$</td>
</tr>
<tr>
<td>RReLU</td>
<td>PReLU中的 $\alpha$ 随机取值</td>
<td>$f(x)=max(\alpha x,x)=\begin{cases} \alpha  &amp; x \leq 0 \\ 1 &amp; x&gt;0 \end{cases}$</td>
</tr>
<tr>
<td>ELU</td>
<td>$f(x) = \begin{cases} x &amp; x \geq 0 \\ \alpha(e^x - 1) &amp; x&lt;0 \end{cases}$</td>
<td>$f(x) = \begin{cases} 1 &amp; x \geq 0 \\ \alpha e^x &amp; x&lt;0 \end{cases}$</td>
</tr>
<tr>
<td>Maxout</td>
<td>$f(x) = max(w_1^T x + b_1, w_2^T x + b_2)$</td>
<td>$f(x) = max(w_1, w_2)$</td>
</tr>
</tbody>
</table>
</div>
<h3 id="简单画出常用激活函数的图像"><a href="#简单画出常用激活函数的图像" class="headerlink" title="简单画出常用激活函数的图像"></a>简单画出常用激活函数的图像</h3><p>sigmoid:</p>
<p><div style="width: 500px; margin: auto"><img src="http://zerozone-blog.oss-cn-beijing.aliyuncs.com/SummaryOfComputerVision/act_sigmoid.jpg?x-oss-process=style/blog_img" alt="SummaryOfComputerVision%2Fact_sigmoid.jpg"></div></p>
<p>tanh:</p>
<p><div style="width: 500px; margin: auto"><img src="http://zerozone-blog.oss-cn-beijing.aliyuncs.com/SummaryOfComputerVision/act_tanh.jpg?x-oss-process=style/blog_img" alt="SummaryOfComputerVision%2Fact_tanh.jpg"></div></p>
<p>relu</p>
<p><div style="width: 500px; margin: auto"><img src="http://zerozone-blog.oss-cn-beijing.aliyuncs.com/SummaryOfComputerVision/act_relu.jpg?x-oss-process=style/blog_img" alt="SummaryOfComputerVision%2Fact_relu.jpg"></div></p>
<p>leaky_relu</p>
<p><div style="width: 500px; margin: auto"><img src="http://zerozone-blog.oss-cn-beijing.aliyuncs.com/SummaryOfComputerVision/act_leaky_relu.jpg?x-oss-process=style/blog_img" alt="SummaryOfComputerVision%2Fact_leaky_relu.jpg"></div></p>
<p>prelu:</p>
<p><div style="width: 500px; margin: auto"><img src="http://zerozone-blog.oss-cn-beijing.aliyuncs.com/SummaryOfComputerVision/act_prelu.jpg?x-oss-process=style/blog_img" alt="SummaryOfComputerVision%2Fact_prelu.jpg"></div></p>
<p>rrelu:</p>
<p><div style="width: 500px; margin: auto"><img src="http://zerozone-blog.oss-cn-beijing.aliyuncs.com/SummaryOfComputerVision/act_rrelu.jpg?x-oss-process=style/blog_img" alt="SummaryOfComputerVision%2Fact_rrelu.jpg"></div></p>
<p>elu</p>
<p><div style="width: 500px; margin: auto"><img src="http://zerozone-blog.oss-cn-beijing.aliyuncs.com/SummaryOfComputerVision/act_elu.jpg?x-oss-process=style/blog_img" alt="SummaryOfComputerVision%2Fact_elu.jpg"></div></p>
<h3 id="为什么需要激活函数"><a href="#为什么需要激活函数" class="headerlink" title="为什么需要激活函数?"></a>为什么需要激活函数?</h3><h4 id="标准说法"><a href="#标准说法" class="headerlink" title="标准说法"></a>标准说法</h4><p>这是由激活函数的性质所决定来, 一般来说, 激活函数都具有以下性质:</p>
<ul>
<li><strong>非线性:</strong> 首先,线性函数可以高效可靠对数据进行拟合, 但是现实生活中往往存在一些非线性的问题(如XOR), 这个时候, 我们就需要借助激活函数的非线性来对数据的分布进行重新映射, 从而获得更强大的拟合能力. (这个是最主要的原因, 其他还有下面这些性质也使得我们选择激活函数作为网络常用层)</li>
<li><strong>可微性:</strong> 这一点有助于我们使用梯度下降发来对网络进行优化</li>
<li><strong>单调性:</strong> 激活函数的单调性在可以使单层网络保证网络是凸优化的</li>
<li><strong>$f(x) \approx x:$</strong> 当激活满足这个性质的时候, 如果参数初值是很小的值, 那么神经网络的训练将会很高效(参考ResNet训练残差模块的恒等映射); 如果不满足这个性质, 那么就需要用心的设值初始值( <strong>这一条有待商榷</strong> )</li>
</ul>
<p>如果不使用激活函数, 多层线性网络的叠加就会退化成单层网络,因为经过多层神经网络的加权计算，都可以展开成一次的加权计算</p>
<h4 id="更形象的解释"><a href="#更形象的解释" class="headerlink" title="更形象的解释"></a>更形象的解释</h4><p>对于一些线性不可分的情况, 比如XOR, 没有办法直接画出一条直线来将数据区分开, 这个时候, 一般有两个选择.</p>
<p>如果已知数据分布规律, 那么可以对数据做线性变换, 将其投影到合适的坐标轴上, 然后在新的坐标轴上进行线性分类</p>
<p>而另一种更常用的办法, 就是使用激活函数, 以XOR问题为例, XOR问题本身不是线性可分的,</p>
<p><a href="https://www.zhihu.com/question/22334626" target="_blank" rel="noopener">https://www.zhihu.com/question/22334626</a></p>
<h3 id="举例说明为什么激活函数可以解决-XOR-问题"><a href="#举例说明为什么激活函数可以解决-XOR-问题" class="headerlink" title="举例说明为什么激活函数可以解决 XOR 问题"></a>举例说明为什么激活函数可以解决 XOR 问题</h3><p>首先, XOR问题如下所示:</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>$x_1$</th>
<th>$x_2$</th>
<th>y</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>0</td>
<td>1</td>
</tr>
<tr>
<td>0</td>
<td>1</td>
<td>1</td>
</tr>
<tr>
<td>1</td>
<td>1</td>
<td>0</td>
</tr>
<tr>
<td>0</td>
<td>0</td>
<td>0</td>
</tr>
</tbody>
</table>
</div>
<p>首先构造一个简单的神经网络来尝试解决XOR问题, 网络结构如下图所示:</p>
<p><div style="width: 500px; margin: auto"><img src="http://zerozone-blog.oss-cn-beijing.aliyuncs.com/SummaryOfComputerVision/xor.jpg?x-oss-process=style/blog_img" alt="SummaryOfComputerVision%2Fxor.jpg"></div></p>
<p>先来看看不使用激活函数时的情况, 当不使用激活函数时, 整个网络的函数表达式如下所示:</p>
<script type="math/tex; mode=display">y = f(x_1, x_2; W, c, w ,b) = [w_1, w_2] \bigg( \bigg[\begin{matrix} W_{11} & W_{12} \\ W_{21} & W_{22} \end{matrix} \bigg] \Big[\begin{matrix} x_1 \\ x_2 \end{matrix} \Big]+ \Big[\begin{matrix} c_1 \\ c_2 \end{matrix} \Big] \bigg) + b = (w^TW^T)x + (w^Tc+b) = w'^Tx+b'</script><p>可以看到, 多层无激活函数的网络叠加, 首先是会退化成单层网络, 而对于单层网络, 求解出来的参数 $w’$ 和 $b’$ 无法对非线性的数据进行分类.</p>
<p>再来看看进入ReLU以后, 是如何解决XOR问题的, 首先, 引入后的公式如下所示:</p>
<script type="math/tex; mode=display">y = f(x_1, x_2; W, c, w ,b) = [w_1, w_2] max \bigg(0 , \bigg[\begin{matrix} W_{11} & W_{12} \\ W_{21} & W_{22} \end{matrix} \bigg] \Big[\begin{matrix} x_1 \\ x_2 \end{matrix} \Big]+ \Big[\begin{matrix} c_1 \\ c_2 \end{matrix} \Big] \bigg) + b</script><p>可以看到, 此时函数是无法化简, 因为此时引入了非线性的ReLU函数, 于是 ,就可以求得一个参数组合${w,W,c,b}$ 使得对于特定的输入$x_1, x_2$ ,能够得到正确的分类结果 $y$. 至于这个参数组合具体是什么, 这是需要通过梯度下降来不断学习的, 假如我们现在找到了一组参数如下(当然不一定是最优的), 来看看这组参数具体是如何解决XOR问题的:</p>
<script type="math/tex; mode=display">W=\bigg[ \begin{matrix} 1 & 1 \\ 1 & 1 \end{matrix} \bigg]</script><script type="math/tex; mode=display">c =\Big[ \begin{matrix} 0 \\ -1 \end{matrix}  \Big]</script><script type="math/tex; mode=display">w =\Big[ \begin{matrix} 1 \\ -1 \end{matrix} \Big]</script><script type="math/tex; mode=display">b = 0</script><p>然后, 分别将4种 $x_1, x_2$的值代入上式, 可以得到, y的值如下:</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>$x_1$</th>
<th>$x_2$</th>
<th>计算过程</th>
<th>y</th>
</tr>
</thead>
<tbody>
<tr>
<td>1</td>
<td>0</td>
<td>$[1, -2] max \bigg(0 , \bigg[\begin{matrix} 1 &amp; 1 \\ 1 &amp; 1 \end{matrix} \bigg] \Big[\begin{matrix} 1 \\ 0 \end{matrix} \Big]+ \Big[\begin{matrix} 0 \\ -1 \end{matrix} \Big] \bigg) + 0$</td>
<td>1</td>
</tr>
<tr>
<td>0</td>
<td>1</td>
<td>$[1, -2] max \bigg(0 , \bigg[\begin{matrix} 1 &amp; 1 \\ 1 &amp; 1 \end{matrix} \bigg] \Big[\begin{matrix} 0 \\ 1 \end{matrix} \Big]+ \Big[\begin{matrix} 0 \\ -1 \end{matrix} \Big] \bigg) + 0$</td>
<td>1</td>
</tr>
<tr>
<td>1</td>
<td>1</td>
<td>$[1, -2] max \bigg(0 , \bigg[\begin{matrix} 1 &amp; 1 \\ 1 &amp; 1 \end{matrix} \bigg] \Big[\begin{matrix} 1 \\ 1 \end{matrix} \Big]+ \Big[\begin{matrix} 0 \\ -1 \end{matrix} \Big] \bigg) + 0$</td>
<td>0</td>
</tr>
<tr>
<td>0</td>
<td>0</td>
<td>$[1, -2] max \bigg(0 , \bigg[\begin{matrix} 1 &amp; 1 \\ 1 &amp; 1 \end{matrix} \bigg] \Big[\begin{matrix} 0 \\ 0 \end{matrix} \Big]+ \Big[\begin{matrix} 0 \\ -1 \end{matrix} \Big] \bigg) + 0$</td>
<td>0</td>
</tr>
</tbody>
</table>
</div>
<h3 id="各个激活函数的优缺点和适用场景是什么"><a href="#各个激活函数的优缺点和适用场景是什么" class="headerlink" title="各个激活函数的优缺点和适用场景是什么"></a>各个激活函数的优缺点和适用场景是什么</h3><p><strong>神经元饱和问题:</strong> 当输入值很大或者很小时, 其梯度值接近于0, 此时, 不管从深层网络中传来何种梯度值, 它向浅层网络中传过去的, 都是趋近于0的数, 进而引发梯度消失问题</p>
<p><strong>zero-centered:</strong> 如果数据分布不是zero-centered的话就会导致后一层的神经元接受的输入永远为正或者永远为负, 因为 $\frac{\partial f}{\partial w} = x$ , 所以如果x的符号固定,那么 $\frac{\partial f}{\partial w}$ 的符号也就固定了, 这样在训练时, weight的更新只会沿着一个方向更新, 但是我们希望的是类似于zig-zag形式的更新路径 (关于非0均值问题, 由于通常训练时是按batch训练的, 所以每个batch会得到不同的信号, 这在一定程度上可以缓解非0均值问题带来的影响, 这也是ReLU虽然不是非0 均值, 但是却称为主流激活函数的原因之一)</p>
<div class="table-container">
<table>
<thead>
<tr>
<th>激活函数</th>
<th>优势</th>
<th>劣势</th>
<th>适用场景</th>
</tr>
</thead>
<tbody>
<tr>
<td>Sigmoid</td>
<td>可以将数据值压缩到[0,1]区间内</td>
<td>1. 神经元饱和问题  <br> 2.sigmoid的输出值域不是zero-centered的  <br> 3. 指数计算在计算机中相对来说比较复杂</td>
<td>在logistic回归中有重要地位</td>
</tr>
<tr>
<td>Tanh</td>
<td>1. zero-centered: 可以将 $(-\infty, +\infty)$ 的数据压缩到 $[-1,1]$ 区间内 <br> 2.完全可微分的，反对称，对称中心在原点</td>
<td>1. 神经元饱和问题 <br> 2. 计算复杂</td>
<td>在分类任务中，双曲正切函数（Tanh）逐渐取代 Sigmoid 函数作为标准的激活函数</td>
</tr>
<tr>
<td>ReLU</td>
<td>1. 在 $(0,+\infty)$ ,梯度始终为1, 没有神经元饱和问题 <br> 2. 不论是函数形式本身,还是其导数, 计算起来都十分高效 3. 可以让训练过程更快收敛(实验结果表明比sigmoid收敛速度快6倍) <br> 4. 从生物神经理论角度来看, 比sigmoid更加合理</td>
<td>1. 非zero-centered   <br> 2. 如果输入值为负值, ReLU由于导数为0, 权重无法更新, 其学习速度可能会变的很慢,很容易就会”死”掉(为了克服这个问题, 在实际中, 人们常常在初始化ReLU神经元时, 会倾向于给它附加一个正数偏好,如0.01)</td>
<td>在卷积神经网络中比较主流</td>
</tr>
<tr>
<td>LeakyReLU</td>
<td>1. 没有神经元饱和问题 <br> 2. 计算高效 <br> 3. 收敛迅速(继承了ReLU的优点) <br> 4. 神经元不会”死”掉(因为在负值时, 输出不为0, 而是x的系数0.001)</td>
<td></td>
<td></td>
</tr>
<tr>
<td>PReLU</td>
<td>1. 没有神经元饱和问题 <br> 2. 计算高效 <br> 3. 收敛迅速(继承了ReLU的优点) <br> 4. 神经元不会”死”掉(因为在负值时, 输出不为0, 而是x的系数 $\alpha$ ) <br> 5. 相对于Leaky ReLU需要通过先验知识人工赋值, PReLU通过迭代优化来自动找到一个较好的值, 更加科学合理, 同时省去人工调参的麻烦</td>
<td></td>
<td></td>
</tr>
<tr>
<td>ELU</td>
<td>1. 拥有ReLU所有的优点 <br> 2. 形式上更接近于zero-centered <br> 3. 在面对负值输入时,更加健壮</td>
<td>1. 引入了指数计算, 使计算变的复杂</td>
<td></td>
</tr>
<tr>
<td>Maxout</td>
<td>1. 跳出了点乘的基本形式 <br> 2. 可以看作是ReLU和Leaky ReLU 的一般化形式 3. linear Regime(啥意思?)! <br> 4. 在所有输入范围上都没有神经元饱和问题 <br> 5. 神经元永远不会”死”掉 <br> 6. 拟合能力非常强，它可以拟合任意的的凸函数。作者从数学的角度上也证明了这个结论，即只需2个maxout节点就可以拟合任意的凸函数了(相减)，前提是”隐含层”节点的个数可以任意多</td>
<td>1. 使得神经元个数和参数个数加倍, 导致优化困难</td>
</tr>
</tbody>
</table>
</div>
<h3 id="Sigmoid-激活函数和-Softmax-激活函数的区别"><a href="#Sigmoid-激活函数和-Softmax-激活函数的区别" class="headerlink" title="Sigmoid 激活函数和 Softmax 激活函数的区别"></a>Sigmoid 激活函数和 Softmax 激活函数的区别</h3><p>sigmoid是将一个正负无穷区间的值映射到(0,1)区间, 通常用作二分类问题,而softmax把一个k维的实值向量映射成一个$(b_1,b_2,…,b_k)$ ,其中$b_i$为一个0~1的常数, 且它们的和为1, 可以看作是属于每一类的概率,通常用作多分类问题. 在二分类问题中, sigmoid和softmax是差不多的, 都是求交叉熵损失函数, softmax可以看作是sigmoid的扩展, 当类别k为2时, 根据softmax回归参数冗余的特点, 可以将softmax函数推导成sigmoid函数</p>
<p><a href="https://www.jianshu.com/p/22d9720dbf1a" target="_blank" rel="noopener">https://www.jianshu.com/p/22d9720dbf1a</a></p>
<h3 id="什么情况下-ReLU-的神经元会死亡-为什么-可以复活吗"><a href="#什么情况下-ReLU-的神经元会死亡-为什么-可以复活吗" class="headerlink" title="什么情况下 ReLU 的神经元会死亡? 为什么? 可以复活吗?"></a>什么情况下 ReLU 的神经元会死亡? 为什么? 可以复活吗?</h3><p>对于 ReLU 来说, <strong>如果某次更新过程中, 梯度值过大, 同时学习率又不小心设置的过大, 就会导致权重一下走更新过多, 那么就有一定概率出现这种情况: 对于任意的训练样本 $x_i$, 当前神经元的输出都是小于 0</strong>, 那么该神经元流向 ReLU 时, 其所有的激活值都会小于 0, 那么对应的激活输出就均为 0. 此时, 反向传播回去的梯度也都变成了 0. 此时我们就认为该神经元死亡.</p>
<p>举个确切的例子说明, 现在假设，这个神经元已经经过若干次迭代，其参数 $(\vec w, b)$ 已经迭代得趋于稳定。现在，神经元接收到了一个异常的输入 $\vec x$ 。比方说，它的某一维特征 $x_i$ 与对应的权重 $w_i$ 的乘积 $w_i x_i$ 非常大。一般来说，这意味着 $x_i$ 的绝对值非常大。于是，ReLU 的输入就会很大，对应 ReLU 的输出 $y$ 也就会很大。好了，假设这个 ReLU 神经元期望的输出（ground truth）是 $\hat y$ ，这个时候损失就会很大——损失一般是 $\vert y − \hat y\vert$ 的增函数，记为 $f(\vert y − \hat y \vert)$。</p>
<p>于是，在反向传播过程中，传递到 ReLU 的输入时的梯度就 $g$ 相应的就会很大。考虑对于偏置 $b$ 有更新</p>
<script type="math/tex; mode=display">b \rightarrow b - g\eta</script><p>考虑到 $g$ 是一个很大的正数，于是 $b$ 可能被更新为一个远小于 0 的负数。此后，对于常规输入来说，ReLU 的输入大概率是个负数。这也就是说，ReLU 大概率是关闭的。这时，梯度无法经 ReLU 反向传播至 ReLU 的输入函数。也就是说，这个神经元的参数再也不会更新了。这就是所谓的「神经元死亡」。</p>
<p>复活问题: 如果是 ReLU 的话, 几乎就无法复活了, 因为由于此时大部分的输入都是小于 0 的, 这样导致反向传播回来的梯度一直为 0, 那么就无法一点点的更新权重, 使之回归正常值, 也就无法复活神经元了. 由此也可以看出, LeakyReLU 可以在负半区一点点的更新权重, 使之有可能复活.</p>
<p>谈谈由异常输入导致的 ReLU 神经元死亡的问题: <a href="https://liam.page/2018/11/30/vanishing-gradient-of-ReLU-due-to-unusual-input/" target="_blank" rel="noopener">https://liam.page/2018/11/30/vanishing-gradient-of-ReLU-due-to-unusual-input/</a><br>深度学习中，使用relu存在梯度过大导致神经元“死亡”，怎么理解？: <a href="https://www.zhihu.com/question/67151971" target="_blank" rel="noopener">https://www.zhihu.com/question/67151971</a></p>
<h3 id="如何解决-ReLU-神经元死亡问题"><a href="#如何解决-ReLU-神经元死亡问题" class="headerlink" title="如何解决 ReLU 神经元死亡问题"></a>如何解决 ReLU 神经元死亡问题</h3><ol>
<li>把 ReLU 换成 LReLU 或者 PReLU，保证让激活函数在输入小于零的情况下也有非零的输出。</li>
<li>采用较小的学习率</li>
<li>采用自适应的优化算法，动态调整学习率</li>
</ol>
<h3 id="激活函数的使用原则"><a href="#激活函数的使用原则" class="headerlink" title="激活函数的使用原则"></a>激活函数的使用原则</h3><ol>
<li>优先使用ReLU, 同时要谨慎设置初值和学习率 ( 实际操作中，如果你的learning rate 很大，那么很有可能你网络中的40%的神经元都 “dead” 了。 当然，如果你设置了一个合适的较小的learning rate，这个问题发生的情况其实也不会太频繁 )</li>
<li>尝试使用LeakyReLU/PReLU/Maxout/ELU等激活函数</li>
<li>可以试下tanh, 但是一般不会有太好的结果</li>
<li><strong>不要使用sigmoid</strong></li>
</ol>
<p><span id="正则化"></span></p>
<h2 id="正则化"><a href="#正则化" class="headerlink" title="正则化"></a>正则化</h2><p>L1, L2</p>
<p><a href="../深度学习-正则化方法深入解析">深度学习-正则化方法深入解析</a></p>
<h3 id="简述-L1-正则和-L2-正则的形式"><a href="#简述-L1-正则和-L2-正则的形式" class="headerlink" title="简述 L1 正则和 L2 正则的形式"></a>简述 L1 正则和 L2 正则的形式</h3><h4 id="L1-正则"><a href="#L1-正则" class="headerlink" title="L1 正则"></a>L1 正则</h4><script type="math/tex; mode=display">\vert w\vert_1 = |w_1| + |w_2| + ... + |w_n|</script><p>L1正则项如下所示, 其中 $L_0$ 代表原始的不加正则项的损失函数, $L$ 代表加了正则项以后的损失函数, <del>$m$ 则代表训练batch的样本大小</del> :</p>
<script type="math/tex; mode=display">L = L_0 + \lambda\vert w\vert_1 = L_0 + \lambda \sum_{w}|w|</script><p>将上式对参数 $w$ 求导如下(由于正则项与 $b$ 无关, 因此参数 $b$ 的导数不变):</p>
<script type="math/tex; mode=display">\frac{\partial L}{\partial w} = \frac{\partial L_0}{\partial w} + \lambda sign(w)</script><p>上式中 $sign(w)$ 表示 $w$ 的符号, 当 $w&gt;0$ 时, $sign(w)=1$ , 当 $w&lt;0$ 时, $sign(w)=-1$, 为了实现方便, 我们特意规定, 当 $w=0$ 时,  $sign(w) = 0$ , 相当于去掉了正则项.</p>
<p>因此, 权重 $w$ 的更新表达式可如下表示:</p>
<script type="math/tex; mode=display">w \to w' = w - \eta \frac{\partial L_0}{\partial w} - \eta \lambda sign(w)</script><h4 id="L2-正则"><a href="#L2-正则" class="headerlink" title="L2 正则"></a>L2 正则</h4><script type="math/tex; mode=display">\vert w\vert_1 = \sqrt {w_1^2 + w_2^2 + ... + w_n^2 }</script><p>L2正则项如下所示, 其中 $L_0$ 代表原始的不加正则项的损失函数, $L$ 代表加了正则项以后的损失函数, <del>式中的系数 $\frac{1}{2}$ 主要是为了消去求导后产生的常数 $2$, 方便表示 (因为可以根据 $\lambda$ 的值来替代这些常数)</del>:</p>
<script type="math/tex; mode=display">L = L_0 + \lambda\vert w\vert^2_2 =L_0 + \lambda \sum_{w}w^2</script><p>将上式对参数 $w$ 求导如下:</p>
<script type="math/tex; mode=display">\frac{\partial L}{\partial w} = \frac{\partial L_0}{\partial w} + 2\lambda w</script><p>则, 权重 $w$ 的更新表达式可如下表示:</p>
<script type="math/tex; mode=display">w \to w' = w - \eta \frac{\partial L_0}{\partial w} - \eta 2\lambda w</script><p>由于, $\eta, \lambda, m$ 三个值都是正的, 因此, 加上 $L2$ 正则化以后, 权重整体减小了, 这也是”权重衰减”的由来.</p>
<h3 id="L1-正则和-L2-正则的特点是什么-各有什么优势"><a href="#L1-正则和-L2-正则的特点是什么-各有什么优势" class="headerlink" title="L1 正则和 L2 正则的特点是什么? 各有什么优势?"></a>L1 正则和 L2 正则的特点是什么? 各有什么优势?</h3><p>二者共同的特点都是能够防止过拟合问题.</p>
<p>L1 的优点: 能够获得更加稀疏的模型, 权重参数最终大部分会变成 0<br>L1 的缺点: 加入 L1 后会使得目标函数在原点不可导, 需要做特殊处理</p>
<p>L2 的有点: 在任意位置都可导, 优化求解过程比较方便, 而且更加稳定<br>L2 的缺点: 无法获得真正的稀疏模型, 参数值只是缓慢趋近于0, 不是直接变成 0</p>
<p><strong>在实际应用过程中, 大部分情况下都是 L2 正则的效果更好, 因此推荐优先使用 L2 正则</strong></p>
<h3 id="L1-和-L2-的区别有哪些"><a href="#L1-和-L2-的区别有哪些" class="headerlink" title="L1 和 L2 的区别有哪些?"></a>L1 和 L2 的区别有哪些?</h3><ol>
<li>L1 相对于 L2 能够产生更加稀疏的模型</li>
<li>L2 相比于 L1 对于离异值更敏感(因为平方的原因, L2 对于大数的乘法比对小数的惩罚大)</li>
<li>L1 和 L2 梯度下降速度不同: 前者梯度恒定, 并且接接近于 0 的时候会很快将参数更新成0, 后者在接近于0 时, 权重的更新速度放缓, 使得不那么容易更新为0 (这也解释了为什么 L1 具有稀疏性)</li>
<li>二者解空间性状不同</li>
</ol>
<p>下图是 L1 和 L2 对向量中值的分布的先验假设, L1 是蓝色的线, L2 是红色的线, 可以看出, L1 的分布对于极端值更能容忍. L1 和 L2 分别对应拉普拉斯先验和高斯先验(why)</p>
<p><div style="width: 500px; margin: auto"><img src="http://zerozone-blog.oss-cn-beijing.aliyuncs.com/SummaryOfComputerVision/l1l2_1.jpg?x-oss-process=style/blog_img" alt="SummaryOfComputerVision%2Fl1l2_1.jpg"></div></p>
<p>下图是 L1 和 L2 的示意图</p>
<p><div style="width: 500px; margin: auto"><img src="http://zerozone-blog.oss-cn-beijing.aliyuncs.com/SummaryOfComputerVision/l1l2_2.jpg?x-oss-process=style/blog_img" alt="SummaryOfComputerVision%2Fl1l2_2.jpg"></div></p>
<h3 id="L1正则化使模型参数稀疏的原理是什么"><a href="#L1正则化使模型参数稀疏的原理是什么" class="headerlink" title="L1正则化使模型参数稀疏的原理是什么?"></a>L1正则化使模型参数稀疏的原理是什么?</h3><p>角度一: 函数图像</p>
<p>L1 在 0 处迅速下降到 0, L2 在 0 处会变得缓慢, 并不会直接更新为 0.</p>
<p>角度二: 函数叠加(梯度下降更新公式)</p>
<script type="math/tex; mode=display">w \to w' = w - \eta \frac{\partial L_0}{\partial w} - \eta \lambda sign(w) \tag{L1}</script><script type="math/tex; mode=display">w \to w' = w - \eta \frac{\partial L_0}{\partial w} - \eta 2\lambda \tag{L2}w</script><p>从以上的更新表达式我们可以看出, 当 $w$ 为正时, L1正则化会将更新后的 $w$ 变的再小一点, 而当 $w$ 为负时, L1正则化会将其变的更大一点—-<strong>因此L1的正则化效果就是让 $w$ 尽可能的向 $0$ 靠近, 即最终的 $w$ 参数矩阵会变的更加稀疏</strong></p>
<p>角度三: 贝叶斯先验, “百面机器学习”<br>角度四: 解空间性状, “百面机器学习”</p>
<h3 id="为什么-L1-和-L2-分别对应拉普拉斯先验和高斯先验"><a href="#为什么-L1-和-L2-分别对应拉普拉斯先验和高斯先验" class="headerlink" title="为什么 L1 和 L2 分别对应拉普拉斯先验和高斯先验?"></a>为什么 L1 和 L2 分别对应拉普拉斯先验和高斯先验?</h3><h3 id="为什么权重矩阵稀疏可以防止过拟合"><a href="#为什么权重矩阵稀疏可以防止过拟合" class="headerlink" title="为什么权重矩阵稀疏可以防止过拟合?"></a>为什么权重矩阵稀疏可以防止过拟合?</h3><p>可以从两个方面来理解:</p>
<p>1）特征选择(Feature Selection)：稀疏性可以实现特征的自动选择, 可以在进行预测时减少无用信息的干扰</p>
<p>大家对稀疏规则化趋之若鹜的一个关键原因在于它能实现特征的自动选择。一般来说，$x_i$ 的大部分元素（也就是特征）都是和最终的输出 $y_i$ 没有关系或者不提供任何信息的，在最小化目标函数的时候考虑 $x_i$ 这些额外的特征，虽然可以获得更小的训练误差，但在预测新的样本时，这些没用的信息反而会被考虑，从而干扰了对正确 $y_i$ 的预测。稀疏规则化算子的引入就是为了完成特征自动选择的光荣使命，它会学习地去掉这些没有信息的特征，也就是把这些特征对应的权重置为 0。</p>
<p>2）可解释性(Interpretability)：较稀疏的模型表示最终的预测结果只与个别关键特征有关, 这符合实际生活中的历史经验</p>
<p>另一个青睐于稀疏的理由是，模型更容易解释。例如患某种病的概率是y，然后我们收集到的数据x是1000维的，也就是我们需要寻找这1000种因素到底是怎么影响患上这种病的概率的。假设我们这个是个回归模型： $y=w_1 \times x_1+w_2 \times x_2+…+w_{1000} \times x_{1000}+b$ （当然了，为了让 $y$ 限定在 $[0,1]$ 的范围，一般还得加个Logistic函数）。通过学习，如果最后学习到的 $w$ 就只有很少的非零元素，例如只有 5 个非零的 $wi$ ，那么我们就有理由相信，这些对应的特征在患病分析上面提供的信息是巨大的，决策性的。也就是说，患不患这种病只和这5个因素有关，那医生就好分析多了。但如果 1000 个 $w_i$ 都非 0，医生面对这 1000 种因素，累觉不爱.</p>
<h3 id="为何权重参数-w-减小就可以防止过拟合"><a href="#为何权重参数-w-减小就可以防止过拟合" class="headerlink" title="为何权重参数 $w$ 减小就可以防止过拟合?"></a>为何权重参数 $w$ 减小就可以防止过拟合?</h3><p>直观解释:</p>
<p>更小的权值w，从某种意义上说，表示网络的复杂度更低，对数据的拟合刚刚好（这个法则也叫做奥卡姆剃刀），而在实际应用中，也验证了这一点，L2正则化的效果往往好于未经正则化的效果</p>
<p>“数学一点”的解释:</p>
<p>过拟合的时候，拟合函数的系数往往非常大，为什么？因为过拟合说明拟合函数会顾忌每一个点，最终形成的拟合函数波动很大。在某些很小的区间里，函数值的变化很剧烈。这就意味着函数在某些小区间里的导数值（绝对值）非常大，由于自变量值可大可小，所以只有系数足够大，才能保证导数值很大. 而正则化是通过约束参数的范数使其不要太大，所以可以在一定程度上减少过拟合情况。</p>
<p>就比如二维平面上的直线拟合, 过拟合时, 由于会顾及每一个点, 最终会形成非常复杂的曲线, 而较好的你和方式是一条顾及大多数点的直线即可.</p>
<h3 id="L0-范式和-L1-范式都能实现稀疏-为什么不选择用-L0-而要用-L1"><a href="#L0-范式和-L1-范式都能实现稀疏-为什么不选择用-L0-而要用-L1" class="headerlink" title="L0 范式和 L1 范式都能实现稀疏, 为什么不选择用 L0 而要用 L1?"></a>L0 范式和 L1 范式都能实现稀疏, 为什么不选择用 L0 而要用 L1?</h3><p>L0范数是指向量中非零元素的个数</p>
<p>一是因为L0范数很难优化求解（NP难问题），二是L1范数是L0范数的最优凸近似，而且它比L0范数要容易优化求解</p>
<h3 id="为什么说-L2-范式可以优化计算"><a href="#为什么说-L2-范式可以优化计算" class="headerlink" title="为什么说 L2 范式可以优化计算?"></a>为什么说 L2 范式可以优化计算?</h3><p><strong>防止过拟合:</strong></p>
<p>最基本的好处是可以提高模型泛化能力, 防止过拟合</p>
<p><strong>优化计算:</strong></p>
<p>从优化或者数值计算的角度来说, L2正则化有利于提高模型训练速度, 加快计算</p>
<p>原因: <a href="https://www.cnblogs.com/callyblog/p/8094745.html" target="_blank" rel="noopener">https://www.cnblogs.com/callyblog/p/8094745.html</a></p>
<h3 id="正则项前面的系数一般怎么设置"><a href="#正则项前面的系数一般怎么设置" class="headerlink" title="正则项前面的系数一般怎么设置?"></a>正则项前面的系数一般怎么设置?</h3><p>通常做法是一开始将正则项系数 $\lambda$ 设置为 0, 然后先确定出一个比较好的 learning rate, 接着固定该 learning rate, 给 $lambda$ 一个初始值, 如 1e-4. 然后根据验证集上的准确率, 将 $\lambda$ 增大或者缩小 10 倍, 这里增减 10 倍是粗调节, 当确定了 $\lambda$ 合适的数量级以后, 再进一步的细调节.</p>
<p><span id="归一化"></span></p>
<h2 id="归一化"><a href="#归一化" class="headerlink" title="归一化"></a>归一化</h2><p><div style="width: 550px; margin: auto"><img src="https://wx2.sinaimg.cn/large/d7b90c85ly1fww4hqied3j21kw0esjwt.jpg" alt="图2"></div></p>
<ul>
<li>Batch Normalization<ul>
<li><a href="../深度学习-Batch-Normalization深入解析/#为什么要进行归一化">为什么要进行归一化</a></li>
<li><a href="../深度学习-Batch-Normalization深入解析/#简述 BN 的原理">简述 BN 的原理</a></li>
<li><a href="../深度学习-Batch-Normalization深入解析/#BN 解决了什么问题">BN 解决了什么问题</a></li>
<li><a href="../深度学习-Batch-Normalization深入解析/#使用 BN 有什么好处">使用 BN 有什么好处</a></li>
<li><a href="../深度学习-Batch-Normalization深入解析/#BN 层通常处于网络中的什么位置">BN 层通常处于网络中的什么位置</a></li>
<li><a href="../深度学习-Batch-Normalization深入解析/#BN 中 batch 的大小对网络性能有什么影响">BN 中 batch 的大小对网络性能有什么影响</a></li>
<li><a href="../深度学习-Batch-Normalization深入解析/#BN 中线性偏移的参数个数怎么计算的">BN 中线性偏移的参数个数怎么计算的</a></li>
<li><a href="../深度学习-Batch-Normalization深入解析/#BN 中使用的均值和方差是如何求得的">BN 中的使用的均值和方差是如何求得的</a></li>
<li><a href="../深度学习-Batch-Normalization深入解析/#在多卡训练使用 BN 时, 需要注意什么问题">在多卡训练使用 BN 时, 需要注意什么问题</a></li>
<li><a href="../深度学习-Batch-Normalization深入解析/#使用 BN 时, 前一层的卷积网络需不需要偏置项, 为什么">使用 BN 时, 前一层的卷积网络需不需要偏置项, 为什么</a></li>
</ul>
</li>
<li>Group Normalization<ul>
<li><a href="../计算机视觉-GroupNormalization-ECCV2018/#简述 GN 的原理">简述 GN 的原理</a></li>
<li><a href="../计算机视觉-GroupNormalization-ECCV2018/#为什么 GN 效果好">为什么 GN 效果好</a></li>
<li><a href="../计算机视觉-GroupNormalization-ECCV2018/#简述 BN, LN, IN, GN 的区别">简述 BN, LN, IN, GN 的区别</a></li>
<li><a href="../计算机视觉-GroupNormalization-ECCV2018/#GN 中线性偏移的参数个数怎么计算的">GN 中线性偏移的参数个数怎么计算的</a></li>
</ul>
</li>
<li>Layer Normalization</li>
<li>Instance Normalization</li>
<li>Switchable Normalization</li>
</ul>
<p><span id="感受野"></span></p>
<h2 id="感受野"><a href="#感受野" class="headerlink" title="感受野"></a>感受野</h2><ul>
<li>感受野的作用</li>
<li>理论感受野和有效感受野的区别? <a href="https://mp.weixin.qq.com/s/R8rEngNI31w0DQwjjeS6kw" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/R8rEngNI31w0DQwjjeS6kw</a></li>
<li>目标检测中的 anchor 的设置和感受野的大小之间有什么关系? <a href="https://mp.weixin.qq.com/s/R8rEngNI31w0DQwjjeS6kw" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/R8rEngNI31w0DQwjjeS6kw</a></li>
</ul>
<p><span id="全连接层"></span></p>
<h2 id="全连接层"><a href="#全连接层" class="headerlink" title="全连接层"></a>全连接层</h2><h3 id="全连接层的作用是什么"><a href="#全连接层的作用是什么" class="headerlink" title="全连接层的作用是什么"></a>全连接层的作用是什么</h3><p><a href="https://www.zhihu.com/question/41037974" target="_blank" rel="noopener">https://www.zhihu.com/question/41037974</a></p>
<ol>
<li>最直观的作用, 起到 “分类器” 的作用. 通常在网络的最后, 会利用全连接层将网络学习到的 “分布式特征表示” 映射到 <strong>样本标记空间</strong>. 在实际使用中, 全连接层也可以利用卷积操作来实现, 如果前一层是全连接层, 那么可以把前一层的全连接层当做是 $h=1, w=1, c = len(FC)$ 的特征图谱, 然后利用核大小为 $1\times 1$, 通道数为前一层神经元个数的卷积层进行计算, 卷积核的个数根据当前层的神经元个数决定. 如果前一层是卷积层, 则只需核的大小设置为前一层的特征图谱的大小, 进行全局卷积即可, 核的通道数由前一层的卷积结果决定, 核的个数由当前层的神经元个数决定.</li>
<li>特征融合, 全连接的任意一个神经元, 都能够 “看到” 前一层网络层输出的所有特征信息(FC 认为下一层的输出与上一层所有输入都有关, 实际上这样很容易 overfitting), 全连接层会根据这些信息, 决定它当前某一个神经元的输出. 这样也就弥补了卷积层只能 “看到” 局部信息的缺点.</li>
<li>不太直观的作用, 目前由于 FC 存在大量的参数冗余, 所有大多数时候我们会用全局平均池化来代替 FC. 但是我之前有看过一篇论文说 FC 的参数冗余也并不是一无是处, 它可以在一定程度上保证模型的迁移能力, 当原模型和目标数据集相差较大的时候, 使用 FC 的模型比不使用 FC 的模型的迁移效果好. 原因可能是冗余的参数对于特征的表示可能更加丰富.</li>
</ol>
<h3 id="将全连接层转换成卷积层由什么好处"><a href="#将全连接层转换成卷积层由什么好处" class="headerlink" title="将全连接层转换成卷积层由什么好处"></a>将全连接层转换成卷积层由什么好处</h3><p><a href="https://www.cnblogs.com/liuzhan709/p/9356960.html" target="_blank" rel="noopener">https://www.cnblogs.com/liuzhan709/p/9356960.html</a></p>
<ol>
<li>可以接受更多尺寸的图片输入, 我们只需要固定网络的通道数符合要求, 然后利用卷积层即可完全最终的分类.</li>
<li>高效, 当我们需要在一张图片上以一定大小的滑动窗口进行多次计算时, 由于这些窗口之间有大量的重合区域, 因此直接使用全连接层会造成会多的计算浪费, 而卷积操作在大多数框架中都得到了性能优化, 十分擅长处理这种操作, 因此在时间上更占优势.</li>
</ol>
<h3 id="推导两层全连接网络的反向传播公式"><a href="#推导两层全连接网络的反向传播公式" class="headerlink" title="推导两层全连接网络的反向传播公式"></a>推导两层全连接网络的反向传播公式</h3><p><a href="https://zhuanlan.zhihu.com/p/39195266" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/39195266</a></p>
<p>全连接层失宠原因之一: 目前大多数的任务，如目标检测，或是分割，并不要求提取全图特征，只需要提取能够覆盖目标物体的大小的感受野内特征即可。尤其是小物体检测问题，感受野很小即可，如果还去接全连接提取全图特征，我们待检测的目标会被淹没在和其它背景的平均特征之中变得不可识别。</p>
<p><span id="卷积层"></span></p>
<h2 id="卷积层"><a href="#卷积层" class="headerlink" title="卷积层"></a>卷积层</h2><p>卷积层的作用?</p>
<ul>
<li><a href="../深度学习-各种网络层/#简述 1x1 卷积层的作用">简述 1x1 卷积层的作用</a></li>
<li><a href="../深度学习-各种网络层/#卷积操作的本质特性包括稀疏交互和参数共享, 具体解释这两种特性及其作用">卷积操作的本质特性包括稀疏交互和参数共享, 具体解释这两种特性及其作用</a></li>
<li><a href="../深度学习-各种网络层/#卷积层底层是如何实现的">卷积层底层是如何实现的</a></li>
<li><a href="../深度学习-各种网络层/#简述矩阵乘法的优化方法">简述矩阵乘法的优化方法</a></li>
</ul>
<p><strong>卷积操作通常由 GEMM 实现</strong>, 但是需要在内存进行名为 im2col 的初始重新排序, 以便将其映射到 GEMM 当中.</p>
<p>卷积核的大小如何确定?<br>卷积核的大小决定了该卷积核在上一层特征图谱上的感受野大小，在确定卷积核的大小时有以下原则（并非通用性原则，实际设计时需要结合具体情况决定）：在网络的起始层，选用较大的卷积核（7×7），这样可以使得卷积核“看到”更多的原图特征；在网络中中间层，可以用两个3×3大小的卷积层来代替一个5×5大小的卷积层，这样做可以在保持感受野大小不变的情况下降低参数个数，减少模型复杂度；通常使用奇数大小的卷积核，原因有二，一是可以更加方便的进行padding，二是奇数核相对于偶数核，具有天然的中心点，并且对边沿、对线条更加敏感，可以更有效的提取边沿信息</p>
<p><span id="池化层"></span></p>
<h2 id="池化层"><a href="#池化层" class="headerlink" title="池化层"></a>池化层</h2><h3 id="池化层的作用是什么"><a href="#池化层的作用是什么" class="headerlink" title="池化层的作用是什么"></a>池化层的作用是什么</h3><ol>
<li><strong>降低优化难度和参数个数:</strong> 池化层可以降低特征图谱的维度，从而降低网络整体的复杂度，不仅可以加速计算，也能起到 <strong>一定的防止过拟合的作用(只保留最大值, 相于不保留非关键信息).</strong></li>
<li><strong>增大感受野:</strong> 当没有池化层时，一个3×3，步长为1的卷积，它输出的一个像素的感受野就是3×3的区域，再加一个stride=1的3×3卷积，则感受野为5×5。当使用pooling后，很明显感受野迅速增大，感受野的增加对于模型的能力的提升是必要的, 当然还有其他更有效的提升感受野的方法, 只不过池化对于感受野的提升也有一定作用.</li>
<li><strong>增加网络平移不变性:</strong> 池化层只会关注核内的值，而不会关注该值的位置，因此，当目标位置发生移动时，池化层也可以得到相同的结果，所以池化层在一定程度上可以增加CNN网络的平移不变性. 同时一定程度上也具有旋转不变性(旋转可以看做是特殊的平移)和尺度不变性(与具体的缩放插值方式有关, 但通常也能保持池化输出值不变)</li>
</ol>
<h3 id="池化层反向传播的梯度时如何求的"><a href="#池化层反向传播的梯度时如何求的" class="headerlink" title="池化层反向传播的梯度时如何求的"></a>池化层反向传播的梯度时如何求的</h3><p>无论是最大池化还是均值池化, 都没有需要学习的参数。因此，在卷积神经网络的训练中，Pooling层需要做的仅仅是将误差项传递到上一层，而没有梯度的计算。</p>
<ul>
<li><p>对于 mean pooling，backward的时候，把一个值分成四等分放到前面2x2的格子里面就好了。如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">forward: [1 3;2 2] -&gt; [2]</span><br><span class="line">backward: [2] -&gt; [0.5 0.5;0.5 0.5]</span><br></pre></td></tr></table></figure>
</li>
<li><p>对于 max pooling，backward的时候把当前的值放到之前那个最大的位置，其他的三个位置都设置成0。如下</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">forward: [1 3;2 2] -&gt; 3</span><br><span class="line">backward: [3] -&gt; [0 3;0 0]</span><br></pre></td></tr></table></figure>
</li>
</ul>
<p><div style="width: 500px; margin: auto"><img src="http://zerozone-blog.oss-cn-beijing.aliyuncs.com/SummaryOfComputerVision/pool_1.jpg?x-oss-process=style/blog_img" alt="SummaryOfComputerVision%2Fpool_1.jpg"></div></p>
<p><div style="width: 500px; margin: auto"><img src="http://zerozone-blog.oss-cn-beijing.aliyuncs.com/SummaryOfComputerVision/pool_2.jpg?x-oss-process=style/blog_img" alt="SummaryOfComputerVision%2Fpool_2.jpg"></div></p>
<h3 id="最大池化和平均池化有什么异同-分别适用于什么场景"><a href="#最大池化和平均池化有什么异同-分别适用于什么场景" class="headerlink" title="最大池化和平均池化有什么异同, 分别适用于什么场景"></a>最大池化和平均池化有什么异同, 分别适用于什么场景</h3><p>最大池化是取核中的最大值, 平均池化是取核中的最小值.</p>
<p>最大池化多用于提取特征, 因为我们需要提取出物体中最显著的若干特征来帮助我们感知和识别物体, 而最大池化的计算规则将是保留特征相应最大的值, 就像是人眼一样, 我们往往只通过一些很明显的特征就可以判断出一个物体的种类, 最大池化多多少少也有这一层含义. 举一个例子, 比如两处不同的位置进行 mean pooling, 一处的最大值是100, 然后经过mean pooling 之后, 它的输出值变成了 20, 而另一处的最大值是50, 然后经过mean pooling 之后它的输出值也是20, 这样, 对于不同的特征, 我们却得到了重复的结果, 这实际上是一种信息冗余, 也可以认为是一种特征丢失. 在使用中, 由于网络内部的大部分时候都是在进行特征提取, 因此 maxpooling 更常用.</p>
<p>平均池化的作用是可以聚合核内的所有特征信息, 因此通常在整个网络的最后, 我们会使用全局平均池化来整合整体的特征, 此时, 因为特征图谱已经是经过高度提取抽象后的, 所以, 我们不能只关注那些最大的值, 图谱上的每一个值所对应的特征我们都需要综合考虑, 这一点和全连接层本身的计算规则相符合, 因为全连接中的每一个神经元都能够 “看到” 全一层所有的输出, 使得全连接可以通过整合所有的特征信息来决定最终的分类结果, GAP 也能够起到相类似的作用.</p>
<h3 id="全局平均池化层-GAP-的作用"><a href="#全局平均池化层-GAP-的作用" class="headerlink" title="全局平均池化层(GAP)的作用"></a>全局平均池化层(GAP)的作用</h3><ol>
<li>GAP 的第一个作用就是可以替代全连接层, 根据全连接层本身的计算规则可知, 使用全局平均池化, 将池化核的个数设置为全连接的神经元个数, 就可以获得相同维度的计算结果.</li>
<li>全连接层本身用于包含大量的参数, 因此在一定程度上, 全连接层上容易产生过拟合现象, 从而影响整个模型的泛化能力. 而 GAP 本身不包含任何参数, 它直接在 feature map 和样本标签空间内建立了联系, 使得每一个 feature map 本身具有的含义更加清晰, 也就是一个 feature map 对应一个 label. 明确学习目标, 简化学习过程.</li>
<li>全连接层通常需要 dropout 来避免过拟合, 而 GAP 本身就可以看做是一种正则, 因此可以使用模型的泛化性能更好</li>
</ol>
<p><span id="反卷积层"></span></p>
<h2 id="反卷积层"><a href="#反卷积层" class="headerlink" title="反卷积层"></a>反卷积层</h2><p>又名 Transposed Convolution, Deconvolution, Fractionally-strided convolution.</p>
<p>反卷积与上采样.</p>
<ul>
<li>反卷积和双线性插值的区别, 各自的优势</li>
</ul>
<p><span id="空洞卷积"></span></p>
<h2 id="空洞卷积"><a href="#空洞卷积" class="headerlink" title="空洞卷积"></a>空洞卷积</h2><p>Dilated Convolution</p>
<p><span id="训练问题"></span></p>
<h2 id="训练问题"><a href="#训练问题" class="headerlink" title="训练问题"></a>训练问题</h2><p><a href="../深度学习-训练问题">训练过程中遇到的问题及解决方案</a></p>
<ul>
<li><a href="../深度学习-训练问题/#在图像分类任务中, 训练数据不足会带来什么问题, 如何缓解数据量不足带来的问题?">在图像分类任务中, 训练数据不足会带来什么问题, 如何缓解数据量不足带来的问题?</a></li>
<li><a href="../深度学习-训练问题/#如何解决数据不均衡问题?">如何解决数据不均衡问题?</a></li>
</ul>
<p>在很多情况下，您将处理不平衡的 数据，特别是在现实世界的应用程序中。举一个简单而实际的例子：为了安全起见，您正在训练您的深度网络以预测视频流中是否有人持有致命武器。但是在你的训练数据中，你只有50个拿着武器的人的视频和1000个没有武器的人的视频！如果你只是用这些数据来训练你的网络，那么你的模型肯定会非常偏向于预测没有人有武器！有几件事你可以做到这一点：· 在损失函数中使用类权重：本质上，代表性不足的类在损失函数中获得更高的权重，因此对该特定类的任何错误分类将导致损失函数中的非常高的误差。· 过度抽样：重复一些包含代表性不足的训练样例，有助于平衡分配。如果可用的数据很小，这最好。· 欠采样：您可以简单地跳过一些包含过度表示类的训练示例。如果可用数据非常大，这最好。· 数据增加为少数类：您可以综合创建更多的代表性不足的训练示例！例如，在前面检测致命武器的例子中，你可以改变属于具有致命武器的类别的视频的一些颜色和光照。</p>
<ul>
<li><a href="../深度学习-训练问题/#训练不收敛的具体表现是什么? 可能的原因是什么? 如何解决?">训练不收敛的具体表现是什么? 可能的原因是什么? 如何解决?</a></li>
<li><a href="../深度学习-训练问题/#训练过程中出现 Nan 值是什么原因? 如何解决?">训练过程中出现 Nan 值是什么原因? 如何解决?</a></li>
<li><a href="../深度学习-训练问题/#过拟合是什么? 如何处理过拟合?">过拟合是什么? 如何处理过拟合?</a></li>
<li><a href="../深度学习-训练问题/#欠拟合是什么? 如何处理欠拟合?">欠拟合是什么? 如何处理欠拟合?</a></li>
<li><a href="../深度学习-训练问题/#Dropout 的实现方式在训练阶段和测试阶段有什么不同? 如何保持训练和测试阶段的一致性?">Dropout 的实现方式在训练阶段和测试阶段有什么不同? 如何保持训练和测试阶段的一致性?</a></li>
<li><a href="../深度学习-训练问题/#Dropout 为什么可以起到防止过拟合的作用?">Dropout 为什么可以起到防止过拟合的作用?</a></li>
<li><p><a href="../深度学习-训练问题/#如何选取 Batch Size 的值? 显存中通常会存储哪些东西?">如何选取 Batch Size 的值? 显存中通常会存储哪些东西?</a></p>
</li>
<li><p>常用的数据增强方法</p>
</li>
</ul>
<p>· 水平和垂直旋转或翻转图像</p>
<p>· 改变图像的亮度和颜色</p>
<p>· 随机模糊图像</p>
<p>· 随机从图像裁剪补丁</p>
<h1 id="网络结构篇"><a href="#网络结构篇" class="headerlink" title="网络结构篇"></a>网络结构篇</h1><div class="table-container">
<table>
<thead>
<tr>
<th style="text-align:center">模型</th>
<th style="text-align:center">层数</th>
<th style="text-align:center">特点</th>
<th style="text-align:center">参数量</th>
<th style="text-align:center">Top-1 Acc</th>
<th style="text-align:center">Top-5 Acc</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">AlexNet</td>
<td style="text-align:center">8</td>
<td style="text-align:center"></td>
<td style="text-align:center">6000w+</td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
<tr>
<td style="text-align:center">VGGNet</td>
<td style="text-align:center">19</td>
<td style="text-align:center"></td>
<td style="text-align:center">1亿3000w+</td>
<td style="text-align:center">71.1</td>
<td style="text-align:center">89.8</td>
</tr>
<tr>
<td style="text-align:center">InceptionV1 (GoogLeNet)</td>
<td style="text-align:center">22</td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">69.8</td>
<td style="text-align:center">89.6</td>
</tr>
<tr>
<td style="text-align:center">InceptionV2</td>
<td style="text-align:center">22</td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">73.9</td>
<td style="text-align:center">91.8</td>
</tr>
<tr>
<td style="text-align:center">InceptionV3</td>
<td style="text-align:center">22</td>
<td style="text-align:center"></td>
<td style="text-align:center">2000w+</td>
<td style="text-align:center">78.0</td>
<td style="text-align:center">93.9</td>
</tr>
<tr>
<td style="text-align:center">InceptionV4</td>
<td style="text-align:center">22</td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">80.2</td>
<td style="text-align:center">95.2</td>
</tr>
<tr>
<td style="text-align:center">ResNet</td>
<td style="text-align:center">152</td>
<td style="text-align:center"></td>
<td style="text-align:center">200w</td>
<td style="text-align:center">76.8</td>
<td style="text-align:center">93.2</td>
</tr>
<tr>
<td style="text-align:center">InceptionResNet</td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center">80.4</td>
<td style="text-align:center">95.3</td>
</tr>
<tr>
<td style="text-align:center">ResNeXt</td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
<td style="text-align:center"></td>
</tr>
</tbody>
</table>
</div>
<p><span id="AlexNet"></span></p>
<h2 id="AlexNet"><a href="#AlexNet" class="headerlink" title="AlexNet"></a>AlexNet</h2><p><div style="width: 550px; margin: auto"><img src="https://wx2.sinaimg.cn/large/d7b90c85ly1g0ixnfk7w4j20o408q3yr.jpg" alt=""></div></p>
<p>AlexNet 的网络结构相对来说比较简单, 它包括 5 层卷积层, 3 层最大池化层, 以及 3 层全连接层. 池化层被分别放置在 conv1, conv2, 和 conv5 的后面. 虽然 AlexNet 结构简单, 但是由于全连接层的存在, 使得 AlexNet 的参数量较大, 大约有 6000w 个参数.</p>
<p><span id="VGGNet"></span></p>
<h2 id="VGGNet"><a href="#VGGNet" class="headerlink" title="VGGNet"></a>VGGNet</h2><p><div style="width: 550px; margin: auto"><img src="https://wx4.sinaimg.cn/large/d7b90c85ly1fxmo2fpvavj21650u079w.jpg" alt=""></div></p>
<p>VGGNet 的网络结构延续了 AlexNet 的设计思想. 将卷积层分成 5 段, 每一段之间通过池化层分隔开, 后面同样跟了 3 层全连接层, 同时他用多个小卷积核替换了 AlexNet 中的大卷积核, 可以在减少参数量的同时提高感受野的范围, 并且通过统建更深层的网络, 使得提取到的特征图谱的表征能力更强. VGGNet 比较常用的结构有 VGG16 和 VGG19. 二者的区别在于前者每个卷积段的卷积层数量是(2, 2, 3, 3, 3), 后者每个卷积段中的卷积层数量是(2, 2, 4, 4, 4).</p>
<p><span id="InceptionV1"></span></p>
<h2 id="InceptionV1"><a href="#InceptionV1" class="headerlink" title="InceptionV1"></a><a href="../计算机视觉-InceptionV1">InceptionV1</a></h2><p>GoogLeNet 模型的核心思想是 <strong>卷积神经网络中的最优局部稀疏结构可以被现有的组件逼近和覆盖, 因此, 只要找到这个局部最优结构, 并在网络结构中重复使用它, 就可以进一步提升神经网络的拟合能力.</strong> 于是, InceptionV1 跳出了传统卷积神经网络的简单堆叠结构, 首次提出了 Inception 模块. Inception 模块综合了 1x1, 3x3, 5x5 这三种不同尺度的卷积核进行特征提取, 同时, 考虑到池化层的重要作用, 还综合了 3x3 大小的最大池化层. 并且, 还在 3x3 和 5x5 的卷积层之前, 以及池化层之后, 使用了 1x1 的卷积层来降低特征维度, 从而减少计算量. 以 Inception 模块为基本单元就可以构建出 IncetionV1 模型, 构建时仍然遵循了 5 个卷积段的段落形式, 段之间通过最大池化层分隔, 具体来说, 前两段使用的是传统的卷积层, 其中第一段是单层的 7x7 大小的卷积层, 第二段是两层较小尺寸的卷积层(1x1, 3x3), 后三段卷积段都是由 Inception 模块组成, 每一段使用的 Inception 模块数量分别为 2, 5, 2. 最后的分类层由全局平均池化层, 全连接层, Softmax 激活层组成. 另外, 由于网络结构较深, 因此, 为了防止梯度消失, InceptionV1 分别在 4a 和 4d 的 Inception 模块上添加了辅助侧枝分类器, 该分类器由一层平均池化层, 一层 1x1 卷积层, 两层全连接层和 Softmax 激活层组成.</p>
<ul>
<li><a href="../计算机视觉-InceptionV1/#简述一下 GoogLeNet 采用多个卷积核的原因">简述一下 GoogLeNet 采用多个卷积核的原因</a></li>
<li><a href="../计算机视觉-InceptionV1/#Inception 中为什么使用 1×1 卷积层">Inception 中为什么使用 1×1 卷积层</a></li>
<li><a href="../计算机视觉-InceptionV1/#Inception 中为什么使用全局平均池化层">Inception 中为什么使用全局平均池化层</a></li>
<li><a href="../计算机视觉-InceptionV1/#为什么使用侧枝">为什么使用侧枝</a></li>
<li><a href="../计算机视觉-InceptionV1/#GoogLeNet 在哪些地方使用了全连接层">GoogLeNet 在哪些地方使用了全连接层</a></li>
</ul>
<p><span id="InceptionV3"></span></p>
<h2 id="InceptionV3"><a href="#InceptionV3" class="headerlink" title="InceptionV3"></a><a href="../计算机视觉-InceptionV3">InceptionV3</a></h2><h3 id="简述-InceptionV2-相比于-GoogLeNet-有什么区别"><a href="#简述-InceptionV2-相比于-GoogLeNet-有什么区别" class="headerlink" title="简述 InceptionV2 相比于 GoogLeNet 有什么区别"></a>简述 InceptionV2 相比于 GoogLeNet 有什么区别</h3><p>InceptionV2 改进的主要有两点. 一方面加入了 BN 层, 减少了 Internal Covariate Shift 问题(内部网络层的数据分布发生变化), 另一方面参考了 VGGNet 用两个 $3\times 3$ 的卷积核替代了原来 Inception 模块中的 $5\times 5$ 卷积核, 可以在降低参数量的同时加速计算.</p>
<h3 id="简述-InceptionV3-相比于-GoogLeNet-有什么区别"><a href="#简述-InceptionV3-相比于-GoogLeNet-有什么区别" class="headerlink" title="简述 InceptionV3 相比于 GoogLeNet 有什么区别"></a>简述 InceptionV3 相比于 GoogLeNet 有什么区别</h3><p>InceptionV3 最重要的改进是分解(Factorization), 这样做的好处是既可以加速计算(多余的算力可以用来加深网络), 有可以将一个卷积层拆分成多个卷积层, 进一步加深网络深度, 增加神经网络的非线性拟合能力, 还有值得注意的地方是网络输入从 $224\times 224$ 变成了 $299\times 299$, 更加精细设计了 $35\times 35$, $17\times 17$, $8\times 8$ 特征图谱上的 Inception 模块.<br>具体来说, 首先将第一个卷积段的 $7\times 7$ 大小的卷积核分解成了 3 个 $3\times 3$ 大小的卷积核. 在第二个卷积段也由 3 个 $3\times 3$ 大小的卷积核组成. 第三个卷积段使用了 3 个 Inception 模块, 同时将模块中的 $5\times 5$ 卷积分解成了两个 $3\times 3$ 大小的卷积. 在第四个卷积段中, 使用了 5 个分解程度更高的 Inception 模块, 具体来说, 是将 $n\times n$ 大小的卷积核分解成 $1\times n$ 和 $n\times 1$ 大小的卷积核, 在论文中, 对于 $17\times 17$ 大小的特征图谱, 使用了 $n = 7$ 的卷积分解形式. 在第五个卷积段中, 面对 $8\times 8$ 大小的特征图谱, 使用了两个设计更加精细的 Inception 模块. 它将 $3\times 3$ 大小的卷积层分解成 $1\times 3$ 和 $3\times 1$ 的卷积层, 这两个卷积层不是之前的串联关系, 而是并联关系.</p>
<p><div style="width: 550px; margin: auto"><img src="https://wx2.sinaimg.cn/large/d7b90c85ly1g1g5nupi5fj21c80u0doq.jpg" alt="Inception"></div></p>
<ul>
<li><a href="..//#Inception 模块的设计和使用原则是什么">Inception 模块的设计和使用原则是什么</a></li>
</ul>
<p><span id="InceptionV4"></span></p>
<h2 id="InceptionV4-and-Inception-ResNet"><a href="#InceptionV4-and-Inception-ResNet" class="headerlink" title="InceptionV4 and Inception ResNet"></a><a href="../计算机视觉-InceptionV4-InceptionResNet">InceptionV4 and Inception ResNet</a></h2><p><strong>Inception 系列的缺点:</strong> 模块过于复杂, 人工设计的痕迹太重了.</p>
<h3 id="简述-InceptionV4-做了哪些改进"><a href="#简述-InceptionV4-做了哪些改进" class="headerlink" title="简述 InceptionV4 做了哪些改进"></a>简述 InceptionV4 做了哪些改进</h3><p>InceptionV4 使用了更复杂的结构重新设计了 Inception 模型中的每一个模块. 包括 Stem 模块, 三种不同的 Inception 模块以及两种不同的 Reduction 模块. 每一个模块的具体参数设置均不太一样, 但是整体来说都遵循的卷积分解和空间聚合的思想.</p>
<p><div style="width: 550px; margin: auto"><img src="https://wx2.sinaimg.cn/large/d7b90c85ly1g1g6on0w08j21hc0u0b29.jpg" alt="InceptionV4"></div></p>
<h3 id="简述-Inception-Resnet-v1-做了哪些改进"><a href="#简述-Inception-Resnet-v1-做了哪些改进" class="headerlink" title="简述 Inception-Resnet-v1 做了哪些改进"></a>简述 Inception-Resnet-v1 做了哪些改进</h3><p>Inception ResNet v1 网络主要被用来与 Inception v3 模型性能进行比较, 因此它所用的 Inception 子网络的计算相对常规模块有所减少, 这是为了保证使得它的整体计算和内存消耗与 Inception v3 近似, 如此才能保证公平性. 具体来说, Inception ResNet v1 网络主要讲 ResNet 中的残差思想用到了 Inception 模块当中, 对于每一种不太的 Inception 模块, 都添加了一个短接连接来发挥残差模型的优势.</p>
<p><div style="width: 550px; margin: auto"><img src="https://wx1.sinaimg.cn/large/d7b90c85ly1g1g6orzjmmj21hc0u0b29.jpg" alt="InceptionResNetV1"></div></p>
<h3 id="简述-Inception-ResNet-v2-做了哪些改进"><a href="#简述-Inception-ResNet-v2-做了哪些改进" class="headerlink" title="简述 Inception-ResNet-v2 做了哪些改进"></a>简述 Inception-ResNet-v2 做了哪些改进</h3><p>Inception ResNet v2 主要被设计来探索残差模块用于 Inception 网络时所尽可能带来的性能提升. 因此它是论文给出的最终性能最高的网络设计方案, 它和 Inception ResNet v1 的不同主要有两点, 第一是使用了 InceptionV4 中的更复杂的 Stem 结构, 第二是对于每一个 Inception 模块, 其空间聚合的维度都有所提升. 其模型结构如下所示:</p>
<p><div style="width: 550px; margin: auto"><img src="https://wx1.sinaimg.cn/large/d7b90c85ly1g1g6ox6512j21hc0u0e81.jpg" alt="InceptionResNetV2"></div></p>
<p><span id="Xception"></span></p>
<h2 id="Xception"><a href="#Xception" class="headerlink" title="Xception"></a><a href="">Xception</a></h2><p><span id="ResNet"></span></p>
<h2 id="ResNet"><a href="#ResNet" class="headerlink" title="ResNet"></a><a href="../计算机视觉-ResNet-CVPR2016">ResNet</a></h2><ul>
<li><a href="../计算机视觉-ResNet-CVPR2016/#简述 ResNet 的原理">简述 ResNet 的原理</a></li>
<li><a href="../计算机视觉-ResNet-CVPR2016/#ResNet 中可以使用哪些短接方式">ResNet 中可以使用哪些短接方式</a></li>
<li><a href="../计算机视觉-ResNet-CVPR2016/#如何理解所谓的残差比原始目标更容易优化">如何理解所谓的残差 $F(x)$ 比原始目标 $H(x)$ 更容易优化</a></li>
<li><a href="../计算机视觉-ResNet-CVPR2016/#为什么恒等映射x之前的系数是1,而不是其他的值, 比如0.5">为什么恒等映射x之前的系数是1,而不是其他的值, 比如0.5</a></li>
<li><a href="../计算机视觉-ResNet-CVPR2016/#ResNet 到底解决了一个什么问题">ResNet 到底解决了一个什么问题</a></li>
<li><a href="../计算机视觉-ResNet-CVPR2016/#ResNet 残差模块中激活层应该如何放置">ResNet 残差模块中激活层应该如何放置</a></li>
</ul>
<p><span id="ResNeXt"></span></p>
<h2 id="ResNeXt"><a href="#ResNeXt" class="headerlink" title="ResNeXt"></a><a href="../计算机视觉-ResNeXt-CVPR2017">ResNeXt</a></h2><ul>
<li><a href="../计算机视觉-ResNeXt-CVPR2017/#ResNeXt 在 ResNet 上做了哪些改进">ResNeXt 在 ResNet 上做了哪些改进</a></li>
</ul>
<p><div style="width: 550px; margin: auto"><img src="https://wx3.sinaimg.cn/large/d7b90c85ly1fxc7ewvfr1j20u00wn0y7.jpg" alt=""></div></p>
<p><div style="width: 550px; margin: auto"><img src="https://wx1.sinaimg.cn/large/d7b90c85ly1fxc7gghlzjj21xt0l1n26.jpg" alt=""></div></p>
<p><span id="DenseNet"></span></p>
<h2 id="DenseNet"><a href="#DenseNet" class="headerlink" title="DenseNet"></a><a href="">DenseNet</a></h2><ul>
<li><a href="../计算机视觉-DenseNet-CVPR2017/#简述 DenseNet 的原理">简述 DenseNet 的原理</a></li>
</ul>
<p><span id="SqueezeNet"></span></p>
<h2 id="SqueezeNet"><a href="#SqueezeNet" class="headerlink" title="SqueezeNet"></a><a href="">SqueezeNet</a></h2><ul>
<li><a href="../计算机视觉-SqueezeNet/#简述 SqueezeNet 的原理">简述 SqueezeNet 的原理</a></li>
</ul>
<p><span id="MobileNet"></span></p>
<h2 id="MobileNet"><a href="#MobileNet" class="headerlink" title="MobileNet"></a><a href="../计算机视觉-MobileNet">MobileNet</a></h2><ul>
<li><a href="../计算机视觉-MobileNet/#简述 MobileNet 的原理">简述 MobileNet 的原理</a></li>
</ul>
<p><span id="MobileNetV2"></span></p>
<h2 id="MobileNetV2"><a href="#MobileNetV2" class="headerlink" title="MobileNetV2"></a><a href="">MobileNetV2</a></h2><ul>
<li><a href="../计算机视觉-MobileNetV2/#MobileNetV2 做了哪些改进">MobileNetV2 做了哪些改进</a></li>
</ul>
<p><span id="ShuffleNet"></span></p>
<h2 id="ShuffleNet"><a href="#ShuffleNet" class="headerlink" title="ShuffleNet"></a><a href="../计算机视觉-ShuffleNet">ShuffleNet</a></h2><ul>
<li><a href="../计算机视觉-ShuffleNet/#简述 ShuffleNet 的原理">简述 ShuffleNet 的原理</a></li>
<li><a href="../计算机视觉-ShuffleNet/简述 ShuffleNet 和 MobileNet 的区别">简述 ShuffleNet 和 MobileNet 的区别</a></li>
</ul>
<p><span id="ShuffleNetV2"></span></p>
<h2 id="ShuffleNetV2"><a href="#ShuffleNetV2" class="headerlink" title="ShuffleNetV2"></a><a href="">ShuffleNetV2</a></h2><ul>
<li><a href="..//#ShuffleNetV2 做了哪些改进">ShuffleNetV2 做了哪些改进</a></li>
</ul>
<p><span id="SENet"></span></p>
<h2 id="SENet"><a href="#SENet" class="headerlink" title="SENet"></a><a href="">SENet</a></h2><ul>
<li><a href="..//#简述 SENet 的原理">简述 SENet 的原理</a></li>
</ul>
<h1 id="目标检测篇"><a href="#目标检测篇" class="headerlink" title="目标检测篇"></a>目标检测篇</h1><p><span id="NMS"></span></p>
<h2 id="NMS"><a href="#NMS" class="headerlink" title="NMS"></a>NMS</h2><h3 id="简述-NMS-的原理"><a href="#简述-NMS-的原理" class="headerlink" title="简述 NMS 的原理"></a><a href="../计算机视觉-NMS-Implementation/#简述 NMS 的原理">简述 NMS 的原理</a></h3><p>非极大值抑制(Non-Maximum Suppression, NMS), 顾名思义就是抑制那些不是极大值的元素, 可以理解为局部最大值搜索. 对于目标检测来说, 非极大值抑制的含义就是对于重叠度较高的一部分同类候选框来说, 去掉那些置信度较低的框, 只保留置信度最大的那一个进行后面的流程, 这里的重叠度高低与否是通过 NMS 阈值来判断的.</p>
<p>计算两个边框 IoU 的公式如下所示:</p>
<script type="math/tex; mode=display">x1 = \max (box1_{x1}, box2_{x1}), y1 = \max (box1_{y1}, box2_{y1})</script><script type="math/tex; mode=display">x2 = \min (box1_{x2}, box2_{x2}), y2 = \min (box1_{y2}, box2_{y2})</script><script type="math/tex; mode=display">intersection = (x2 - x1 + 1) \times (y2 - y1 + 1)</script><script type="math/tex; mode=display">IoU = \frac{intersection}{area1+area2-intersection}</script><p><span id="NMS 算法源码实现"></span></p>
<h3 id="NMS-算法源码实现"><a href="#NMS-算法源码实现" class="headerlink" title="NMS 算法源码实现"></a><a href="../计算机视觉-NMS-Implementation/#NMS 算法源码实现">NMS 算法源码实现</a></h3><p><strong>算法逻辑:</strong><br>输入: $n$ 行 $4$ 列的候选框数组, 以及对应的 $n$ 行 $1$ 列的置信度数组.<br>输出: $m$ 行 $4$ 列的候选框数组, 以及对应的 $m$ 行 $1$ 列的置信度数组, $m$ 对应的是去重后的候选框数量<br>算法流程:</p>
<ol>
<li>计算 $n$ 个候选框的面积大小</li>
<li>对置信度进行排序, 获取排序后的下标序号, 即采用<code>argsort</code></li>
<li>将当前置信度最大的框加入返回值列表中</li>
<li>获取当前置信度最大的候选框与其他任意候选框的相交面积</li>
<li>利用相交的面积和两个框自身的面积计算框的交并比, 将交并比大于阈值的框删除.</li>
<li>对剩余的框重复以上过程</li>
</ol>
<p><strong>Python 实现:</strong><br><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> cv2</span><br><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">nms</span><span class="params">(bounding_boxes, confidence_score, threshold)</span>:</span></span><br><span class="line">    <span class="keyword">if</span> len(bounding_boxes) == <span class="number">0</span>:</span><br><span class="line">        <span class="keyword">return</span> [], []</span><br><span class="line">    bboxes = np.array(bounding_boxes)</span><br><span class="line">    score = np.array(confidence_score)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算 n 个候选框的面积大小</span></span><br><span class="line">    x1 = bboxes[:, <span class="number">0</span>]</span><br><span class="line">    y1 = bboxes[:, <span class="number">1</span>]</span><br><span class="line">    x2 = bboxes[:, <span class="number">2</span>]</span><br><span class="line">    y2 = bboxes[:, <span class="number">3</span>]</span><br><span class="line">    areas =(x2 - x1 + <span class="number">1</span>) * (y2 - y1 + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 对置信度进行排序, 获取排序后的下标序号, argsort 默认从小到大排序</span></span><br><span class="line">    order = np.argsort(score)</span><br><span class="line"></span><br><span class="line">    picked_boxes = [] <span class="comment"># 返回值</span></span><br><span class="line">    picked_score = [] <span class="comment"># 返回值</span></span><br><span class="line">    <span class="keyword">while</span> order.size &gt; <span class="number">0</span>:</span><br><span class="line">        <span class="comment"># 将当前置信度最大的框加入返回值列表中</span></span><br><span class="line">        index = order[<span class="number">-1</span>]</span><br><span class="line">        picked_boxes.append(bounding_boxes[index])</span><br><span class="line">        picked_score.append(confidence_score[index])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 获取当前置信度最大的候选框与其他任意候选框的相交面积</span></span><br><span class="line">        x11 = np.maximum(x1[index], x1[order[:<span class="number">-1</span>]])</span><br><span class="line">        y11 = np.maximum(y1[index], y1[order[:<span class="number">-1</span>]])</span><br><span class="line">        x22 = np.minimum(x2[index], x2[order[:<span class="number">-1</span>]])</span><br><span class="line">        y22 = np.minimum(y2[index], y2[order[:<span class="number">-1</span>]])</span><br><span class="line">        w = np.maximum(<span class="number">0.0</span>, x22 - x11 + <span class="number">1</span>)</span><br><span class="line">        h = np.maximum(<span class="number">0.0</span>, y22 - y11 + <span class="number">1</span>)</span><br><span class="line">        intersection = w * h</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 利用相交的面积和两个框自身的面积计算框的交并比, 将交并比大于阈值的框删除</span></span><br><span class="line">        ratio = intersection / (areas[index] + areas[order[:<span class="number">-1</span>]] - intersection)</span><br><span class="line">        left = np.where(ratio &lt; threshold)</span><br><span class="line">        order = order[left]</span><br><span class="line"></span><br><span class="line">    <span class="keyword">return</span> picked_boxes, picked_score</span><br></pre></td></tr></table></figure></p>
<p><strong>C++ 实现</strong></p>
<figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;iostream&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;vector&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span> <span class="meta-string">&lt;algorithm&gt;</span></span></span><br><span class="line"></span><br><span class="line"><span class="class"><span class="keyword">struct</span> <span class="title">Bbox</span> &#123;</span></span><br><span class="line">    <span class="keyword">int</span> x1;</span><br><span class="line">    <span class="keyword">int</span> y1;</span><br><span class="line">    <span class="keyword">int</span> x2;</span><br><span class="line">    <span class="keyword">int</span> y2;</span><br><span class="line">    <span class="keyword">float</span> score;</span><br><span class="line">    Bbox(<span class="keyword">int</span> x1_, <span class="keyword">int</span> y1_, <span class="keyword">int</span> x2_, <span class="keyword">int</span> y2_, <span class="keyword">float</span> s):</span><br><span class="line">	x1(x1_), y1(y1_), x2(x2_), y2(y2_), score(s) &#123;&#125;;</span><br><span class="line">&#125;;</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">float</span> <span class="title">iou</span><span class="params">(Bbox box1, Bbox box2)</span> </span>&#123;</span><br><span class="line">    <span class="keyword">float</span> area1 = (box1.x2 - box1.x1 + <span class="number">1</span>) * (box1.y2 - box1.y1 + <span class="number">1</span>);</span><br><span class="line">    <span class="keyword">float</span> area2 = (box2.x2 - box2.x1 + <span class="number">1</span>) * (box2.y2 - box2.y1 + <span class="number">1</span>);</span><br><span class="line">    <span class="keyword">int</span> x11 = <span class="built_in">std</span>::max(box1.x1, box2.x1);</span><br><span class="line">    <span class="keyword">int</span> y11 = <span class="built_in">std</span>::max(box1.y1, box2.y1);</span><br><span class="line">    <span class="keyword">int</span> x22 = <span class="built_in">std</span>::min(box1.x2, box2.x2);</span><br><span class="line">    <span class="keyword">int</span> y22 = <span class="built_in">std</span>::min(box1.y2, box2.y2);</span><br><span class="line">    <span class="keyword">float</span> intersection = (x22 - x11 + <span class="number">1</span>) * (y22 - y11 + <span class="number">1</span>);</span><br><span class="line">    <span class="keyword">return</span> intersection / (area1 + area2 - intersection);</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="built_in">std</span>::<span class="built_in">vector</span>&lt;Bbox&gt; nms(<span class="built_in">std</span>::<span class="built_in">vector</span>&lt;Bbox&gt; &amp;vecBbox, <span class="keyword">float</span> threshold) &#123;</span><br><span class="line">    <span class="keyword">auto</span> cmpScore = [](Bbox box1, Bbox box2) &#123;</span><br><span class="line">	<span class="keyword">return</span> box1.score &lt; box2.score; <span class="comment">// 升序排列, 令score最大的box在vector末端</span></span><br><span class="line">    &#125;;</span><br><span class="line">    <span class="built_in">std</span>::sort(vecBbox.begin(), vecBbox.end(), cmpScore);</span><br><span class="line"></span><br><span class="line">    <span class="built_in">std</span>::<span class="built_in">vector</span>&lt;Bbox&gt; pickedBbox;</span><br><span class="line">    <span class="keyword">while</span> (vecBbox.size() &gt; <span class="number">0</span>) &#123;</span><br><span class="line">        pickedBbox.emplace_back(vecBbox.back());</span><br><span class="line">        vecBbox.pop_back();</span><br><span class="line">        <span class="keyword">for</span> (<span class="keyword">size_t</span> i = <span class="number">0</span>; i &lt; vecBbox.size(); i++) &#123;</span><br><span class="line">            <span class="keyword">if</span> (iou(pickedBbox.back(), vecBbox[i]) &gt;= threshold) &#123;</span><br><span class="line">                vecBbox.erase(vecBbox.begin() + i);</span><br><span class="line">            &#125;</span><br><span class="line">        &#125;</span><br><span class="line">    &#125;</span><br><span class="line">    <span class="keyword">return</span> pickedBbox;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure>
<p><strong>CUDA 实现:</strong></p>
<h3 id="简述-Soft-NMS-的原理"><a href="#简述-Soft-NMS-的原理" class="headerlink" title="简述 Soft-NMS 的原理"></a><a href="../计算机视觉-NMS-Implementation/#简述 Soft-NMS 的原理及算法实现">简述 Soft-NMS 的原理</a></h3><p>在 Soft-NMS 中, 对于那些重叠度大于一定阈值的 box, 我们并不将其删除, 而仅仅只是根据重叠程度来降低那些 box 的 socre, 这样一来, 这些 box 仍旧处于 box 列表中, 只是 socre 的值变低了. 具体来说, 如果 box 的重叠程度高, 那么 score 的值就会变得很低, 如果重叠程度小, 那么 box 的 score 值就只会降低一点, Soft-NMS 算法伪代码如下图所示:</p>
<h3 id="Soft-NMS-算法源码实现"><a href="#Soft-NMS-算法源码实现" class="headerlink" title="Soft-NMS 算法源码实现"></a><a href="../计算机视觉-NMS-Implementation/#Soft-NMS 算法源码实现">Soft-NMS 算法源码实现</a></h3><p><strong>算法逻辑:</strong><br>输入:</p>
<ul>
<li>bboxes: 坐标矩阵, 每个边框表示为 [x1, y1, x2, y2]</li>
<li>scores: 每个 box 对应的分数, 在 Soft-NMS 中, scores 会发生变化(<strong>对外部变量也有影响</strong>)</li>
<li>iou_thresh:   交并比的最低阈值</li>
<li>sigma2: 使用 gaussian 函数的方差, sigma2 代表 $\sigma^2$</li>
<li>score_thresh: 最终分数的最低阈值</li>
<li>method: 使用的惩罚方法, 1 代表线性惩罚, 2 代表高斯惩罚, 其他情况代表默认的 NMS</li>
</ul>
<p>返回值: 最终留下的 boxes 的 index, 同时, scores 值也已经被改变.<br>算法流程:</p>
<ol>
<li>在 bboxes 之后添加对于的下标[0, 1, 2…], 最终 bboxes 的 shape 为 [n, 5], 前四个为坐标, 后一个为下标</li>
<li>计算每个 box 自身的面积</li>
<li><strong>对于每一个下标 $i$</strong>, 找出 i 后面的最大 score 及其下标, 如果当前 i 的得分小于后面的最大 score, 则与之交换, 确保 i 上的 score 最大.</li>
<li>计算 IoU</li>
<li>根据用户选定的方法更新 scores 的值</li>
<li>以上过程循环 $N$ 次后($N$ 为总边框的数量), 将最终得分大于最低阈值的下标返回, 根据下标获取最终存留的 Boxes, <strong>注意, 此时, 外部 scores 的值已经完成更新, 无需借助下标来获取.</strong></li>
</ol>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">soft_nms</span><span class="params">(bboxes, scores, iou_thresh=<span class="number">0.3</span>, sigma2=<span class="number">0.5</span>, score_thresh=<span class="number">0.001</span>, method=<span class="number">2</span>)</span>:</span></span><br><span class="line">    <span class="comment"># 在 bboxes 之后添加对于的下标[0, 1, 2...], 最终 bboxes 的 shape 为 [n, 5], 前四个为坐标, 后一个为下标</span></span><br><span class="line">    N = bboxes.shape[<span class="number">0</span>] <span class="comment"># 总的 box 的数量</span></span><br><span class="line">    indexes = np.array([np.arange(N)])  <span class="comment"># 下标: 0, 1, 2, ..., n-1</span></span><br><span class="line">    bboxes = np.concatenate((bboxes, indexes.T), axis=<span class="number">1</span>) <span class="comment"># concatenate 之后, bboxes 的操作不会对外部变量产生影响</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 计算每个 box 的面积</span></span><br><span class="line">    x1 = bboxes[:, <span class="number">0</span>]</span><br><span class="line">    y1 = bboxes[:, <span class="number">1</span>]</span><br><span class="line">    x2 = bboxes[:, <span class="number">2</span>]</span><br><span class="line">    y2 = bboxes[:, <span class="number">3</span>]</span><br><span class="line">    areas = (x2 - x1 + <span class="number">1</span>) * (y2 - y1 + <span class="number">1</span>)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(N):</span><br><span class="line">        <span class="comment"># 找出 i 后面的最大 score 及其下标</span></span><br><span class="line">        pos = i + <span class="number">1</span></span><br><span class="line">        <span class="keyword">if</span> i != N<span class="number">-1</span>:</span><br><span class="line">            maxscore = np.max(scores[pos:], axis=<span class="number">0</span>)</span><br><span class="line">            maxpos = np.argmax(scores[pos:], axis=<span class="number">0</span>)</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            maxscore = scores[<span class="number">-1</span>]</span><br><span class="line">            maxpos = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        <span class="comment"># 如果当前 i 的得分小于后面的最大 score, 则与之交换, 确保 i 上的 score 最大</span></span><br><span class="line">        <span class="keyword">if</span> scores[i] &lt; maxscore:</span><br><span class="line">            bboxes[[i, maxpos + i + <span class="number">1</span>]] = bboxes[[maxpos + i + <span class="number">1</span>, i]]</span><br><span class="line">            scores[[i, maxpos + i + <span class="number">1</span>]] = scores[[maxpos + i + <span class="number">1</span>, i]]</span><br><span class="line">            areas[[i, maxpos + i + <span class="number">1</span>]] = areas[[maxpos + i + <span class="number">1</span>, i]]</span><br><span class="line"></span><br><span class="line">        <span class="comment"># IoU calculate</span></span><br><span class="line">        xx1 = np.maximum(bboxes[i, <span class="number">0</span>], bboxes[pos:, <span class="number">0</span>])</span><br><span class="line">        yy1 = np.maximum(bboxes[i, <span class="number">1</span>], bboxes[pos:, <span class="number">1</span>])</span><br><span class="line">        xx2 = np.minimum(bboxes[i, <span class="number">2</span>], bboxes[pos:, <span class="number">2</span>])</span><br><span class="line">        yy2 = np.minimum(bboxes[i, <span class="number">3</span>], bboxes[pos:, <span class="number">3</span>])</span><br><span class="line">        w = np.maximum(<span class="number">0.0</span>, xx2 - xx1 + <span class="number">1</span>)</span><br><span class="line">        h = np.maximum(<span class="number">0.0</span>, yy2 - yy1 + <span class="number">1</span>)</span><br><span class="line">        intersection = w * h</span><br><span class="line">        iou = intersection / (areas[i] + areas[pos:] - intersection)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Three methods: 1.linear 2.gaussian 3.original NMS</span></span><br><span class="line">        <span class="keyword">if</span> method == <span class="number">1</span>:  <span class="comment"># linear</span></span><br><span class="line">            weight = np.ones(iou.shape)</span><br><span class="line">            weight[iou &gt; iou_thresh] = weight[iou &gt; iou_thresh] - iou[iou &gt; iou_thresh]</span><br><span class="line">        <span class="keyword">elif</span> method == <span class="number">2</span>:  <span class="comment"># gaussian</span></span><br><span class="line">            weight = np.exp(-(iou * iou) / sigma2)</span><br><span class="line">        <span class="keyword">else</span>:  <span class="comment"># original NMS</span></span><br><span class="line">            weight = np.ones(iou.shape)</span><br><span class="line">            weight[iou &gt; iou_thresh] = <span class="number">0</span></span><br><span class="line"></span><br><span class="line">        scores[pos:] = weight * scores[pos:]</span><br><span class="line"></span><br><span class="line">    <span class="comment"># select the boxes and keep the corresponding indexes</span></span><br><span class="line">    inds = bboxes[:, <span class="number">4</span>][scores &gt; score_thresh]</span><br><span class="line">    keep = inds.astype(int)</span><br><span class="line">    <span class="keyword">return</span> keep</span><br><span class="line"></span><br><span class="line"><span class="comment"># boxes and scores</span></span><br><span class="line">boxes = np.array([[<span class="number">200</span>, <span class="number">200</span>, <span class="number">400</span>, <span class="number">400</span>], [<span class="number">220</span>, <span class="number">220</span>, <span class="number">420</span>, <span class="number">420</span>],</span><br><span class="line">                  [<span class="number">240</span>, <span class="number">200</span>, <span class="number">440</span>, <span class="number">400</span>], [<span class="number">200</span>, <span class="number">240</span>, <span class="number">400</span>, <span class="number">440</span>],</span><br><span class="line">                  [<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">2</span>]], dtype=np.float32)</span><br><span class="line">boxscores = np.array([<span class="number">0.9</span>, <span class="number">0.8</span>, <span class="number">0.7</span>, <span class="number">0.6</span>, <span class="number">0.5</span>], dtype=np.float32)</span><br><span class="line">index = soft_nms(boxes, boxscores, method=<span class="number">2</span>)</span><br><span class="line">print(index) <span class="comment"># 按照 scores 的排序指明了对应的 box 的下标</span></span><br><span class="line">print(boxes[index])</span><br><span class="line">print(boxscores) <span class="comment"># 注意, scores 不需要用 index 获取, scores 已经是更新过的排序 scores</span></span><br></pre></td></tr></table></figure>
<h3 id="介绍一下其他的-NMS-算法"><a href="#介绍一下其他的-NMS-算法" class="headerlink" title="介绍一下其他的 NMS 算法"></a><a href="../计算机视觉-NMS-Implementation/#介绍一下其他的 NMS 算法">介绍一下其他的 NMS 算法</a></h3><ul>
<li><a href="../计算机视觉-NMS-Implementation/#简述 NMS 的原理">简述 NMS 的原理</a></li>
<li><a href="../计算机视觉-NMS-Implementation/#NMS 算法源码实现">NMS 算法源码实现</a></li>
<li><a href="../计算机视觉-NMS-Implementation/#简述 Soft-NMS 的原理及算法实现">简述 Soft-NMS 的原理</a></li>
<li><a href="../计算机视觉-NMS-Implementation/#Soft-NMS 算法源码实现">Soft-NMS 算法源码实现</a></li>
<li><a href="../计算机视觉-NMS-Implementation/#介绍一下其他的 NMS 算法">介绍一下其他的 NMS 算法</a></li>
</ul>
<p><span id="R-CNN"></span></p>
<h2 id="R-CNN"><a href="#R-CNN" class="headerlink" title="R-CNN"></a><a href="../计算机视觉-R-CNN-CVPR2014">R-CNN</a></h2><ul>
<li>Selective Search</li>
<li>AlexNet</li>
<li>SVM</li>
<li>Bounding Box Regression</li>
</ul>
<script type="math/tex; mode=display">t_x = (G_x - P_x) / P_w, t_y = (G_y - P_y) / P_h</script><script type="math/tex; mode=display">t_w = log(G_w / P_w), t_h = log(G_h / P_h)</script><p><span id="Fast R-CNN"></span></p>
<h2 id="Fast-R-CNN"><a href="#Fast-R-CNN" class="headerlink" title="Fast R-CNN"></a><a href="../计算机视觉-FastR-CNN-ICCV2015">Fast R-CNN</a></h2><p><strong>R-CNN 缺点</strong>:</p>
<ul>
<li>训练过程是分阶段的(Training is a multi-stage pipeline)</li>
<li>Training is expensive in space and time</li>
<li>目标检测速度太慢(Object detection is slow)</li>
</ul>
<p><strong>SPPNet 缺点</strong>:</p>
<ul>
<li>训练过程是分阶段的(Training is a multi-stage pipeline)</li>
<li>无法 Fine-Tuning 金字塔池化层之前的卷积层</li>
</ul>
<p><strong>Fast R-CNN 贡献</strong>:</p>
<ul>
<li>更高的检测准确率(mAP)</li>
<li>整个训练过程更加统一(利用多目标损失函数)</li>
<li>训练时可以对所有网络层参数进行更新(相比于SPPNet)</li>
<li>无需在硬盘上额外存储 feature.(相比于 R-CNN, 因为共享卷积计算结果, 使得feature的体积大大降低)</li>
</ul>
<p><strong>要点</strong>:</p>
<ul>
<li>Multi-task loss: 下式中, $L_{cls}(p,u) = - log p_u$, 即对于真实类别 $u$ 的 log 损失.<script type="math/tex; mode=display">L(p, u, t_u, v) = L_{cls}(p,u) + \lambda [u \geq 1] L_{loc}(t^u, v) \tag 1</script><script type="math/tex; mode=display">L_{loc}(t^u, v) = \sum_{i\in {x,y,w,h}} smooth_{L_1}(t_i^u - v_i) \tag 2</script><script type="math/tex; mode=display">smooth_{L_1}(x) = \begin{cases} 0.5x^2 && |x|<1 \\ |x| - 0.5 && otherwise \end{cases} \tag 3</script></li>
<li>Mini-batch Sampling</li>
<li>RoI Pooling Layer</li>
<li><a href="../深度学习-奇异值分解">Truncated SVD 截断式奇异矩阵分解</a></li>
</ul>
<p><span id="Faster R-CNN"></span></p>
<h2 id="Faster-R-CNN"><a href="#Faster-R-CNN" class="headerlink" title="Faster R-CNN"></a><a href="../计算机视觉-FasterR-CNN-NIPS2015">Faster R-CNN</a></h2><h3 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h3><ul>
<li>RPN (Region Proposals Networks)<br><div style="width: 550px; margin: auto"><img src="https://wx1.sinaimg.cn/large/d7b90c85ly1fxsf9g1udsj21q00s3152.jpg" alt="图2"></div></li>
<li>损失函数<script type="math/tex; mode=display">L(\{p_i\}, \{t_i\}) = \frac{1}{N_{cls}} \sum_i L_{cls}(p_i, p_i^* ) + \lambda \frac{1}{N_{reg}} \sum_i p_i^* L_{reg}(t_i, t_i^* )</script></li>
<li>RPN 与 Fast R-CNN 共享卷积参数<ul>
<li>Alternating training(交叉训练)</li>
<li>Approximate joint training(近似联合训练)</li>
<li>Non-approximate joint training(非近似联合训练)</li>
</ul>
</li>
</ul>
<p><strong>问题:</strong></p>
<h3 id="RoI-Pooling-如何进行反向传播"><a href="#RoI-Pooling-如何进行反向传播" class="headerlink" title="RoI Pooling 如何进行反向传播"></a>RoI Pooling 如何进行反向传播</h3><p>在特征图谱上的每个 RoI, 都会根据设定的网格大小进行最大池化操作, 在反向传播时, 每个 RoI 的计算时独立的, 因此, 只需要对每个 RoI 执行普通的最大池化的反向传播规则即可, 最终的损失函数会综合所有 RoI 的损失值.</p>
<h2 id="Mask-R-CNN"><a href="#Mask-R-CNN" class="headerlink" title="Mask R-CNN"></a><a href="../计算机视觉-MaskR-CNN-ICCV2017">Mask R-CNN</a></h2><ul>
<li>基于 Faster R-CNN 的基本结构, 替换 backbone 为 ResNet-50/101-C4 和 ResNet-50/101-FPN, ResNeXt-101-FPN.</li>
<li>除了边框回归和目标分类两个分支外, 新添加了一个全卷积的 Mask Prediction 网络, 该分支在每一个 RoI 上的输出维度为 $K\times m^2$, 代表 $K$ 个类别的二值掩膜.</li>
<li>在计算 mask 的损失时, 使用的是 sigmoid 的二分类损失, 而不是多分类的 softmax 损失, 这减少了类别之前的竞争, 使得可以生成更好的分割结果.</li>
<li>RoIAlign 消除了 RoI Pooling 中的两次量化操作, 使得最终提取到的特征可以 RoI 尽可能的对齐. 从而大幅提升在实例分割任务上的性能表现.</li>
</ul>
<p><div style="width: 550px; margin: auto"><img src="https://wx2.sinaimg.cn/large/d7b90c85ly1fx1toyw0xkj20kc0a5wkw.jpg" alt="图1"></div></p>
<h2 id="FPN"><a href="#FPN" class="headerlink" title="FPN"></a><a href="../计算机视觉-FPN-CVPR2017">FPN</a></h2><h2 id="FCN"><a href="#FCN" class="headerlink" title="FCN"></a><a href="../">FCN</a></h2><h2 id="RFCN"><a href="#RFCN" class="headerlink" title="RFCN"></a><a href="../">RFCN</a></h2><h2 id="Deformable-CNN"><a href="#Deformable-CNN" class="headerlink" title="Deformable CNN"></a><a href="../">Deformable CNN</a></h2><h2 id="Cascade-R-CNN"><a href="#Cascade-R-CNN" class="headerlink" title="Cascade R-CNN"></a><a href="../">Cascade R-CNN</a></h2><h2 id="SSD"><a href="#SSD" class="headerlink" title="SSD"></a>SSD</h2><p>【链接】目标检测|SSD原理与实现<br><a href="https://zhuanlan.zhihu.com/p/33544892" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/33544892</a></p>
<p><strong>问题:</strong></p>
<ul>
<li>为什么SSD不直接使用浅层的特征图谱, 而非要额外增加卷积层, 这样不是增加模型的复杂度了吗?</li>
<li>SSD 使用了哪些数据增广方法?</li>
</ul>
<h2 id="YOLOv1"><a href="#YOLOv1" class="headerlink" title="YOLOv1"></a>YOLOv1</h2><p><a href="http://caffecn.cn/?/question/1842" target="_blank" rel="noopener">http://caffecn.cn/?/question/1842</a></p>
<h2 id="YOLOv2"><a href="#YOLOv2" class="headerlink" title="YOLOv2"></a>YOLOv2</h2><p>YOLOv2(也叫做 YOLO9000)</p>
<h2 id="YOLOv3"><a href="#YOLOv3" class="headerlink" title="YOLOv3"></a>YOLOv3</h2><h2 id="FocalLoss"><a href="#FocalLoss" class="headerlink" title="FocalLoss"></a><a href="../计算机视觉-FocalLoss-ICCV2017">FocalLoss</a></h2><p>FocalLoss</p>
<h2 id="TridentNet"><a href="#TridentNet" class="headerlink" title="TridentNet"></a><a href="../">TridentNet</a></h2><h2 id="DenseBox"><a href="#DenseBox" class="headerlink" title="DenseBox"></a><a href="../">DenseBox</a></h2><h2 id="CornerNet"><a href="#CornerNet" class="headerlink" title="CornerNet"></a><a href="../">CornerNet</a></h2><p>CornerNet-Lite 描述<br>基于关键点的对象检测[53,56,26]是一类通过检测和分组其关键点来生成对象边界框的方法。 CornerNet [26]是其中最先进的技术，可以检测并分组边界框的左上角和右下角; 它使用堆叠 HourGlass 网络[39]来预测角落的热图，然后使用 associate embeddings [38]对它们进行分组。 CornerNet 允许简化设计，无需使用 anchor box[46]，并且在 One-Stage 探测器中实现了COCO [32]的 SOTA 精度。</p>
<p>CenterNet 描述:<br>为了检测 corner，CornerNet 会产生两个热图：左上角的热图和右下角的热图。热图表示不同类别的关键点的位置，并为每个关键点分配置信度分数。此外，它还会预测每个 corner 的 embedding 和一组 offsets。embedding 用于识别两个 corner 是否来自同一对象。offsets 将热图上的 corners 重新映射到输入图像上。为了生成 object bounding box，分别根据它们的分数从热图中选择前 $k$ 个左上角和右下角。然后，计算一对 corners 的 embedding 距离以确定成对的 corner 是否属于同一对象。如果距离小于阈值，则生成对象边界框。为边界框分配置信度分数，该分数等于 corner pairs 的平均分数。</p>
<h2 id="CornerNet-Lite"><a href="#CornerNet-Lite" class="headerlink" title="CornerNet-Lite"></a><a href="../">CornerNet-Lite</a></h2><h2 id="FSAF"><a href="#FSAF" class="headerlink" title="FSAF"></a><a href="../">FSAF</a></h2><h2 id="FoveaBox"><a href="#FoveaBox" class="headerlink" title="FoveaBox"></a><a href="../">FoveaBox</a></h2><h2 id="FCOS"><a href="#FCOS" class="headerlink" title="FCOS"></a><a href="../">FCOS</a></h2><h2 id="ExtremeNet"><a href="#ExtremeNet" class="headerlink" title="ExtremeNet"></a><a href="../">ExtremeNet</a></h2><h2 id="CenterNet"><a href="#CenterNet" class="headerlink" title="CenterNet"></a><a href="../">CenterNet</a></h2><h2 id="CenterNet-Objects-as-Points"><a href="#CenterNet-Objects-as-Points" class="headerlink" title="CenterNet(Objects as Points)"></a><a href="../">CenterNet(Objects as Points)</a></h2><h2 id="CornerNet-Lite-1"><a href="#CornerNet-Lite-1" class="headerlink" title="CornerNet-Lite"></a><a href="../">CornerNet-Lite</a></h2><h2 id="TridentNet-1"><a href="#TridentNet-1" class="headerlink" title="TridentNet"></a><a href="../">TridentNet</a></h2><h2 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h2><p>RefineDet, SNIP, SNIPPER, Fitness NMS, RFBNet, M2Det, TridentNet, HTC, NAS-FPN(为开源)</p>
<p>Guided Anchoring<br>Libra R-CNN<br>Hybrid Task Cascade</p>
<h1 id="图像处理篇"><a href="#图像处理篇" class="headerlink" title="图像处理篇"></a>图像处理篇</h1><p>4.1 图像特征提取的算法有哪些，各自优缺点、适用范围<br><a href="https://blog.csdn.net/xiongchao99/article/details/78776629" target="_blank" rel="noopener">https://blog.csdn.net/xiongchao99/article/details/78776629</a></p>
<p><span id="图像放缩"></span></p>
<h2 id="图像放缩"><a href="#图像放缩" class="headerlink" title="图像放缩"></a>图像放缩</h2><p><strong>双线性插值</strong><br>双线性插值本质上就是在两个方向上做线性插值.</p>
<p><div style="width: 550px; margin: auto"><img src="https://wx3.sinaimg.cn/large/d7b90c85ly1g1hbfdtyvcj21dg0m6ta3.jpg" alt="双线性插值"></div></p>
<p>假如我们想得到未知函数 $f$ 在点 $P = (x, y)$ 的值, <strong>在图像中, 这个 $f$ 代表的就是某个像素点的像素值.</strong> 当我们已知点 $P$ 周围四个点的值以后, 我们可以首先在 $x$ 方向上进行线性插值, 得到:</p>
<script type="math/tex; mode=display">f(R_1) \approx \frac{x_2 - x}{x_2 - x_1} f(Q_{11}) + \frac{x - x1}{x_2 - x_1}f(Q_{21})</script><script type="math/tex; mode=display">f(R_2) \approx \frac{x_2 - x}{x_2 - x_1} f(Q_{12}) + \frac{x - x_1}{x_2 - x_1} f(Q_{22})</script><p>然后在 $y$ 方向上进行线性插值, 得到:</p>
<script type="math/tex; mode=display">f(P) \approx \frac{y_2 - y}{y_2 - y_1} f(R_1) + \frac{y - y_1}{y_2 - y_1}f(R_2)</script><p><span id="边缘检测算法"></span></p>
<h2 id="边缘检测算法"><a href="#边缘检测算法" class="headerlink" title="边缘检测算法"></a>边缘检测算法</h2><p><a href="https://www.jianshu.com/p/2334bee37de5" target="_blank" rel="noopener">https://www.jianshu.com/p/2334bee37de5</a></p>
<p><a href="https://blog.csdn.net/KYJL888/article/details/78253053" target="_blank" rel="noopener">https://blog.csdn.net/KYJL888/article/details/78253053</a></p>
<p>Roberts算子<br>Sobel算子<br>Prewit算子<br>Canny算子</p>
<p><span id="霍夫变换"></span></p>
<h2 id="霍夫变换"><a href="#霍夫变换" class="headerlink" title="霍夫变换"></a>霍夫变换</h2><p><a href="https://www.cnblogs.com/AndyJee/p/3805594.html" target="_blank" rel="noopener">https://www.cnblogs.com/AndyJee/p/3805594.html</a></p>
<p><a href="https://blog.csdn.net/m0_37264397/article/details/72729423" target="_blank" rel="noopener">https://blog.csdn.net/m0_37264397/article/details/72729423</a></p>
<p><span id="滤波器"></span></p>
<h2 id="图像保边滤波器"><a href="#图像保边滤波器" class="headerlink" title="图像保边滤波器"></a>图像保边滤波器</h2><p><a href="https://blog.csdn.net/Trent1985/article/details/80509232" target="_blank" rel="noopener">https://blog.csdn.net/Trent1985/article/details/80509232</a></p>
<p><a href="https://blog.csdn.net/eejieyang/article/details/52333112" target="_blank" rel="noopener">https://blog.csdn.net/eejieyang/article/details/52333112</a></p>
<p><a href="https://blog.csdn.net/LG1259156776/article/details/51816875" target="_blank" rel="noopener">https://blog.csdn.net/LG1259156776/article/details/51816875</a></p>
<p><a href="https://blog.csdn.net/u012968002/article/details/44463229" target="_blank" rel="noopener">https://blog.csdn.net/u012968002/article/details/44463229</a></p>
<h2 id="图像平移"><a href="#图像平移" class="headerlink" title="图像平移"></a>图像平移</h2><p><a href="https://blog.csdn.net/qq_25867649/article/details/52131252" target="_blank" rel="noopener">https://blog.csdn.net/qq_25867649/article/details/52131252</a></p>
<p><a href="https://blog.csdn.net/linqianbi/article/details/78593203" target="_blank" rel="noopener">https://blog.csdn.net/linqianbi/article/details/78593203</a></p>
<h2 id="图像开操作、闭操作"><a href="#图像开操作、闭操作" class="headerlink" title="图像开操作、闭操作"></a>图像开操作、闭操作</h2><p><a href="https://blog.csdn.net/learning_tortosie/article/details/80030201" target="_blank" rel="noopener">https://blog.csdn.net/learning_tortosie/article/details/80030201</a></p>
<p><a href="https://blog.csdn.net/water_93/article/details/50859193" target="_blank" rel="noopener">https://blog.csdn.net/water_93/article/details/50859193</a></p>
<p><a href="https://www.cnblogs.com/daxiongblog/p/6289551.html" target="_blank" rel="noopener">https://www.cnblogs.com/daxiongblog/p/6289551.html</a></p>
<h2 id="图像旋转"><a href="#图像旋转" class="headerlink" title="图像旋转"></a>图像旋转</h2><p><a href="https://www.cnblogs.com/hustlx/p/5245226.html" target="_blank" rel="noopener">https://www.cnblogs.com/hustlx/p/5245226.html</a></p>
<p><a href="https://blog.csdn.net/ccblogger/article/details/72918354" target="_blank" rel="noopener">https://blog.csdn.net/ccblogger/article/details/72918354</a></p>
<h2 id="图像重建质量评价指标"><a href="#图像重建质量评价指标" class="headerlink" title="图像重建质量评价指标"></a>图像重建质量评价指标</h2><p><a href="https://blog.csdn.net/smallstones/article/details/42198049" target="_blank" rel="noopener">https://blog.csdn.net/smallstones/article/details/42198049</a></p>
<h2 id="光流法"><a href="#光流法" class="headerlink" title="光流法"></a>光流法</h2><p><a href="https://blog.csdn.net/longlovefilm/article/details/79824723" target="_blank" rel="noopener">https://blog.csdn.net/longlovefilm/article/details/79824723</a></p>
<p><a href="https://www.xuebuyuan.com/3203656.html" target="_blank" rel="noopener">https://www.xuebuyuan.com/3203656.html</a></p>
<h2 id="图像去噪的方法"><a href="#图像去噪的方法" class="headerlink" title="图像去噪的方法"></a>图像去噪的方法</h2><p><a href="https://blog.csdn.net/eric_e/article/details/79504444" target="_blank" rel="noopener">https://blog.csdn.net/eric_e/article/details/79504444</a></p>
<h2 id="度量图像patch相似度的方法"><a href="#度量图像patch相似度的方法" class="headerlink" title="度量图像patch相似度的方法"></a>度量图像patch相似度的方法</h2><p><a href="https://blog.csdn.net/lg1259156776/article/details/47037583/" target="_blank" rel="noopener">https://blog.csdn.net/lg1259156776/article/details/47037583/</a></p>
<p><a href="https://blog.csdn.net/zchang81/article/details/73275155/" target="_blank" rel="noopener">https://blog.csdn.net/zchang81/article/details/73275155/</a></p>
<p><a href="https://blog.csdn.net/yangyangyang20092010/article/details/8472257" target="_blank" rel="noopener">https://blog.csdn.net/yangyangyang20092010/article/details/8472257</a></p>
<h2 id="传统图像处理CDC做过吗？"><a href="#传统图像处理CDC做过吗？" class="headerlink" title="传统图像处理CDC做过吗？"></a>传统图像处理CDC做过吗？</h2><h2 id="傅里叶变换"><a href="#傅里叶变换" class="headerlink" title="傅里叶变换"></a>傅里叶变换</h2><h2 id="图像融合算法有哪些？"><a href="#图像融合算法有哪些？" class="headerlink" title="图像融合算法有哪些？"></a>图像融合算法有哪些？</h2><h2 id="图像增强算法有哪些"><a href="#图像增强算法有哪些" class="headerlink" title="图像增强算法有哪些"></a>图像增强算法有哪些</h2><h2 id="图像滤波方法"><a href="#图像滤波方法" class="headerlink" title="图像滤波方法"></a>图像滤波方法</h2><h2 id="直方图均衡化"><a href="#直方图均衡化" class="headerlink" title="直方图均衡化"></a>直方图均衡化</h2><p><a href="https://www.cnblogs.com/hustlx/p/5245461.html" target="_blank" rel="noopener">https://www.cnblogs.com/hustlx/p/5245461.html</a></p>
<p><a href="https://www.cnblogs.com/tianyalu/p/5687782.html" target="_blank" rel="noopener">https://www.cnblogs.com/tianyalu/p/5687782.html</a></p>
<h1 id="算法实现篇"><a href="#算法实现篇" class="headerlink" title="算法实现篇"></a>算法实现篇</h1><h2 id="KNN-1"><a href="#KNN-1" class="headerlink" title="KNN"></a>KNN</h2><h2 id="K-Means"><a href="#K-Means" class="headerlink" title="K-Means"></a>K-Means</h2><h2 id="IoU"><a href="#IoU" class="headerlink" title="IoU"></a>IoU</h2><h2 id="NMS-1"><a href="#NMS-1" class="headerlink" title="NMS"></a>NMS</h2><h2 id="矩阵乘法"><a href="#矩阵乘法" class="headerlink" title="矩阵乘法"></a>矩阵乘法</h2><h2 id="高斯滤波"><a href="#高斯滤波" class="headerlink" title="高斯滤波"></a>高斯滤波</h2><h1 id="数学基础篇"><a href="#数学基础篇" class="headerlink" title="数学基础篇"></a>数学基础篇</h1><p><span id="概率分布"></span></p>
<h2 id="概率分布"><a href="#概率分布" class="headerlink" title="概率分布"></a>概率分布</h2><p><a href="../机器学习-数学基础/#Beta 分布">Beta 分布</a></p>
<p>5.1 概率分布<br>5.2 期望、方差、协方差、相关系数<br>5.3 假设检验<br><a href="https://support.minitab.com/zh-cn/minitab/18/help-and-how-to/statistics/basic-statistics/supporting-topics/basics/what-is-a-hypothesis-test/" target="_blank" rel="noopener">https://support.minitab.com/zh-cn/minitab/18/help-and-how-to/statistics/basic-statistics/supporting-topics/basics/what-is-a-hypothesis-test/</a></p>
<p><a href="https://blog.csdn.net/pipisorry/article/details/51182843" target="_blank" rel="noopener">https://blog.csdn.net/pipisorry/article/details/51182843</a></p>
<p><a href="https://blog.csdn.net/YtdxYHZ/article/details/51780310" target="_blank" rel="noopener">https://blog.csdn.net/YtdxYHZ/article/details/51780310</a></p>
<p>5.4 54张牌，分3组，大王小王同在一组的概率<br>分成3份 总的分法 M=(C54，18)(C36，18)(C18，18)</p>
<p>大小王在同一份N=(C3，1)(C52，16)(C36，18)x(C18，18) P=N /M=17/53 。</p>
<p>5.5 最大似然估计、贝叶斯估计<br><a href="https://blog.csdn.net/bitcarmanlee/article/details/52201858" target="_blank" rel="noopener">https://blog.csdn.net/bitcarmanlee/article/details/52201858</a></p>
<p><a href="https://www.cnblogs.com/zjh225901/p/7495505.html" target="_blank" rel="noopener">https://www.cnblogs.com/zjh225901/p/7495505.html</a></p>
<p><a href="https://blog.csdn.net/feilong_csdn/article/details/61633180" target="_blank" rel="noopener">https://blog.csdn.net/feilong_csdn/article/details/61633180</a></p>
<p>5.6<br><a href="https://www.nowcoder.com/questionTerminal/836b01b7809248b7b6e9c30495d4680e?from=14pdf" target="_blank" rel="noopener">https://www.nowcoder.com/questionTerminal/836b01b7809248b7b6e9c30495d4680e?from=14pdf</a></p>
<p>假设一段公路上，1小时内有汽车经过的概率为96%，那么，30分钟内有汽车经过的概率为?</p>
<p>48%<br>52%<br>80%<br>96%</p>
<p>一小时有车的概率 = 1 - 一小时没车的概率 = 1 - 两个半小时都没车的概率 = 1 - （1 - 半小时有车的概率）^2<br>1-(1-x)^2=0.96<br>x = 0.8</p>
<p>5.7 三门问题<br>三个宝箱里有一个宝箱里有宝物，两个是空的，你选了一个，主持人打开剩下2个中的一个发现没有宝物，问你换不换</p>
<p>假设A无，B无，C有，<br>选A，则主持人只会开B，1/3概率；<br>选B，则主持人只会开A，1/3概率；<br>选C，则主持人会开A\B，1/3概率；</p>
<p>可见，不换只有1/3的概率中，换的话，有2/3的概率中；</p>
<p>5.8 概率题：抛一个骰子，直到集齐六面，问抛骰子的期望次数。<br>5.9 概率题：抛色子连续n次正面向上的期望次数。<br>5.10 一个人向北走了一公里，向东走了一公里，又向南走了一公里，最后回到了最开始的起点，为什么？<br>南极点，刚好一个等边三角形；</p>
<p>或者是一个一圈距离刚好是1公里的那个地方。向北走之后，达到那个地方，饶了一圈回到这个地方，再向南走回去。</p>
<p><a href="https://blog.csdn.net/Turinglife/article/details/7358061" target="_blank" rel="noopener">https://blog.csdn.net/Turinglife/article/details/7358061</a></p>
<p>从逻辑上来讲，题目从好像缺少了一次向西的过程，才可以回到原地。有没有可能向东1公里还在原地，答案是肯定的，如果有一个纬度，绕其一圈恰好是1公里即可实现，所以这样的点有无穷多个，只要找到那个纬度即可。</p>
<p>5.11 一个四位数abcd，满足abcd <em> 4 = dcba，求这个数<br>a9没有进位，且为四位数，a只能为1<br>d9个位数为1，d只能是9<br>b9后为个位数（9加任何数进位），这个数只能是1或0，排除1，b=0<br>c9+8的尾数为0，则c</em>9个位数为2，c=8</p>
<p>a4没有进位，说明a=1或2，但是d4的个位是a，不可能a=1，所以a=2;</p>
<p>d=a4=8;而且没有进位，说明b4+它的可能进位不超过10；</p>
<p>如果b=0：则c*4的个位需要是7，不存在，不符；</p>
<p>如果b=1：则c*4的个位需要是8，存c=2不符合，c=7符合，所以为2178；</p>
<p>如果b=2:则c*4的个位需要是9，不符；</p>
<p>5.12 概率题：一个家庭有两个孩子，已知其中一个是女孩，求另一个也是女孩的概率<br>(1/21/2)/(1-1/21/2)<br>=(1/4)/(3/4)<br>=1/3</p>
<p>5.13 16个球队中随机选2个，在大量选取后，越强的队越容易被选中<br>5.14 有一个3L、一个5L的桶，请量出4L的水<br>5L桶装满水，倒入3L桶；此时5L中有2L水，3L桶中有3L水；</p>
<p>3L桶全部倒走，将5L桶的2L水道入3L桶中，此时5L桶中没有水，3L桶中有2L水；</p>
<p>将5L桶倒满水，然后向3L桶中倒水，此时3L桶水已满，5L桶中还剩4L水。</p>
<p>5.15 把1~9这9个数填入九格宫里,使每一横、竖、斜相等。<br><a href="https://zhidao.baidu.com/question/329122415632328485.html" target="_blank" rel="noopener">https://zhidao.baidu.com/question/329122415632328485.html</a></p>
<p>5.16 一个圆上随机三个点组成锐角三角形的概率<br>一个圆周上,随机点三个点,这三个点在同一个半圆上的概率是多少?<br>三个点在同一个半圆时,形成的三角形为直角或钝角三形（自己想为什么）.<br>不在同一个半圆时,为锐角三角形.<br>三点在同一半圆的概率是3/4,所以你这题的答案为1/4.</p>
<p>设在圆上任取的3点是A、B、C。圆心为 O<br>先假定A、B的位置，设弦AB的圆心角为∠α，且∠α属于[0，π].那么满足锐角三角形的C点就要在AO延长线与BO延长线间，所以C点的取值范围只有圆心为α的弧，即概率为：α/（2π）<br>对任意A、B的位置，C点的概率为对α/（2π）从[0，π]积分，结果是 π/4</p>
<p>关于为什么C点就要在AO延长线与BO延长线间，因为C点如果不在这之间，则ABC三点就会处于同一个半圆中。而处于同一个半圆中的三个点构成直角或者钝角三角形。</p>
<h2 id="线性代数"><a href="#线性代数" class="headerlink" title="线性代数"></a>线性代数</h2><h1 id="常见问题篇"><a href="#常见问题篇" class="headerlink" title="常见问题篇"></a>常见问题篇</h1><p><a href="../面试-计算机视觉常见问题详细解答">面试-计算机视觉常见问题详细解答</a></p>
<ul>
<li>目前的 SOTA 目标检测模型</li>
<li>SSD, FPN, RefineDet, PFPNet, STDN, M2Det 等特征金字塔的区别</li>
<li>常用的训练 Trick</li>
<li>有哪些数据增广方法? 怎么实现的?</li>
<li>FCN 是如何降低计算量的?</li>
</ul>
<p><span id="目前的 SOTA 目标检测模型"></span></p>
<h2 id="目前的-SOTA-目标检测模型"><a href="#目前的-SOTA-目标检测模型" class="headerlink" title="目前的 SOTA 目标检测模型"></a>目前的 SOTA 目标检测模型</h2><p>比较经典的, 比如 R-CNN 系列, YOLO, 以及 SSD 等属于比较具有代表性的一些模型. 在此基础上, 从 17 年开始, 又有很多新的模型出现, 按照不同的关注角度来分, 大致有这么几类.<br>首先是对卷积网络的特征金字塔的构建和生成进行优化和改进的模型, 比如 FPN 和 M2Det 等.<br>其次是从感受野的角度进行优化的模型, 比如 Deformable ConvNet, RFBNet.<br>还有从 bounding box 回归角度进行优化的 RefineDet.<br>然后还有从损失函数及样本不均衡角度进行优化, 使用 Focal Loss 的 RetinaNet等.</p>
<ul>
<li>在 feature map 的多尺度金字塔特征上进行优化: SSD, FPN, PFPNet, M2Det</li>
<li>在 bbox 回归上进行优化: RefineDet</li>
<li>然后也可以在感受野上进行优化: DCN, RFBNet</li>
<li>以另一种角度来选取 bbox: CornerNet</li>
<li>在 anchor 的生成上进行优化: CornerNet, MetaAnchor</li>
<li>对 NMS 和 IoU 上进行优化: Soft-NMS, Sofer-NMS, Fitness NMS, Relation Network, IoUNet, Cascade R-CNN</li>
<li>在 backbone 网络上优化: DetNet</li>
<li>在损失函数和样本不均衡上进行优化: Focal Loss, Gradient Harmonized(梯度均衡)</li>
<li>针对移动端设备: Pelee</li>
<li>多尺度问题: SNIP, SNIPER</li>
<li>小目标检测: STDNet, Augmentation for small od.</li>
<li>超大目标检测: HKRM</li>
</ul>
<p>FPN,<br>RefineDet, RFBNet<br>STDN</p>
<p><span id="SSD, FPN, RefineDet, PFPNet, STDN, M2Det 等特征金字塔的区别"></span></p>
<h2 id="SSD-FPN-RefineDet-PFPNet-STDN-M2Det-等特征金字塔的区别"><a href="#SSD-FPN-RefineDet-PFPNet-STDN-M2Det-等特征金字塔的区别" class="headerlink" title="SSD, FPN, RefineDet, PFPNet, STDN, M2Det 等特征金字塔的区别"></a>SSD, FPN, RefineDet, PFPNet, STDN, M2Det 等特征金字塔的区别</h2><p>SSD 是通过使用 backbone(VGG16) 的最后两个卷积段的特征图谱和 4 个额外卷积层特征图谱来构建特征金字塔的.<br>FPN 是通过融合深层和浅层的特征图谱来构建特征金字塔. 主要做法是将最后一层特征图谱进行不断的上采样得到 top-down 结构的特征图谱, 然后与原始的 down-top 结构的特征图谱相结合, 从而得到新的表征能力更强的特征金字塔结构.<br>M2Det 主要是从现在特征金字塔的一些缺点出发进行优化, 它认为, 现有金字塔结构中每一个尺度的特征仅仅来自于 backbone 中单一层级(level)的特征. 这样一来, 小尺度的特征图谱往往缺少浅层低级的语义信息, 而大尺度的特征图谱又缺少深层的高级语义信息. 因此, 作者就提出了融合多个层级特征的 Multi-Level FPN (MLFPN). 从而可以让小尺寸的特征图谱上包含有更多的低级语义信息, 让大尺寸的特征图谱包含更多的高级语义信息.</p>
<p><span id="常用的训练 Trick"></span></p>
<h2 id="常用的训练-Trick"><a href="#常用的训练-Trick" class="headerlink" title="常用的训练 Trick"></a>常用的训练 Trick</h2><p><span id="有哪些数据增广方法? 怎么实现的?"></span></p>
<h2 id="有哪些数据增广方法-怎么实现的"><a href="#有哪些数据增广方法-怎么实现的" class="headerlink" title="有哪些数据增广方法? 怎么实现的?"></a>有哪些数据增广方法? 怎么实现的?</h2><ul>
<li>颜色变换(Convert Color): BGR 与 HSV 格式随机切换. HSV 模型的三维表示是从 RGB 立方体以旧换新儿来的, 设想从 RGB 沿立方体对角线的白色顶点向黑色顶点观察, 就可以看到立方体的六边形外形. 六边形边界表示色彩, 水平轴表示纯度, 明度沿垂直测量.</li>
<li>随机对比度和亮度: 像素最大最小值的差值影响对比度, 像素的整体大小影响亮度, 通过公式 $g(i, j) = a\times f(i,j) + b$ 控制, $a$ 影响的是对比度, $b$ 影响的图像的亮度.</li>
<li>随机饱和度(Random Saturation): 先将图片转换成 HSV 格式, 然后对 S 通道乘以一个随机值</li>
<li>随机色度(Random Hue): 先将图片转换成 HSV 格式, 然后对 H 通过进行修改</li>
<li>随机交换通道, 增加噪声</li>
</ul>
<h2 id="FCN-是如何降低计算量的"><a href="#FCN-是如何降低计算量的" class="headerlink" title="FCN 是如何降低计算量的?"></a>FCN 是如何降低计算量的?</h2><p>面对 $384\times 384$ 的图像, 让含全连接层的初始卷积神经网络以 32 像素的步长独立对图像中的 $224\times 224$ 块进行多次评价, 其效果和使用全卷积网络进行一次评价时相同的. 后者通过权值共享起到了加速计算的作用.</p>
<p><span id="简单说一下 PyTorch 和 TensorFlow 的区别"></span></p>
<h2 id="PyTorch-和-TensorFlow-的区别"><a href="#PyTorch-和-TensorFlow-的区别" class="headerlink" title="PyTorch 和 TensorFlow 的区别"></a>PyTorch 和 TensorFlow 的区别</h2><p>两个框架虽然都是在张量上运行, 并且将模型都看做是一个有向非循环图(DAG), 但是二者对于图的定义不同. TensorFlow 是基于静态计算图, 因此是先定义再运行, 一次定义多次运行, 而 PyTorch 是基于动态计算图的, 是在运行过程中被定义的, 在运行的时候进行构建, 可以多次构建多次运行.<br>动态图的还有一个好处就是比较容易调试, 在 PyTorch 中, 代码报错的地方, 往往就是代码错写的地方, 而静态图需要先根据代码生成 Graph 对象, 然后在 session.run() 时报错, 但是这种报错几乎很难直接找到代码中对应的出错段落.</p>
<p>链接】Variable和Tensor合并后，PyTorch的代码要怎么改<br><a href="https://blog.csdn.net/dQCFKyQDXYm3F8rB0/article/details/80105285" target="_blank" rel="noopener">https://blog.csdn.net/dQCFKyQDXYm3F8rB0/article/details/80105285</a></p>
<p><span id="你觉得目标检测领域还有哪些可以继续改进或者优化的地方"></span></p>
<h2 id="目标检测领域还有哪些可以继续改进或者优化的地方"><a href="#目标检测领域还有哪些可以继续改进或者优化的地方" class="headerlink" title="目标检测领域还有哪些可以继续改进或者优化的地方"></a>目标检测领域还有哪些可以继续改进或者优化的地方</h2><ol>
<li><p>首先是精确度和速度的考量, 相对于精度较高的 Faster RCNN, RFCN 相关系列模型来说, 个人觉得速度更快的 YOLO 系列和 SSD 系列的模型在实际场景应用中会更加实用, 近年来的主要代表有 RefineDet, RFBNet 等都是基于 SSD 模型的研究.</p>
</li>
<li><p>其次是目标的选框步骤, 从最开始的 Region Based , Anchor Based 到现在的基于角点, 甚至基于 segmentation, 包括 semantic segmentation 和 instance segmentation. 今年比较有代表性的就是 CornerNet. 就目前来说, 目标的选框方法很多还是基于 RPN 的 anchor 思想, 所以, 未来的研究中, 新的更好的目标选框方法依旧是研究的一个重要方向.</p>
</li>
<li><p>多尺度问题(尺度变换问题), 目标常见的三种思路, 采用专门设计的尺度变换模块, STDN: Scale-Transferrable Object Detection.</p>
</li>
</ol>
<h2 id="one-stage目标检测算法中-浅层特征图检测小目标，为什么不同时也检测大目标？"><a href="#one-stage目标检测算法中-浅层特征图检测小目标，为什么不同时也检测大目标？" class="headerlink" title="one stage目标检测算法中,浅层特征图检测小目标，为什么不同时也检测大目标？"></a>one stage目标检测算法中,浅层特征图检测小目标，为什么不同时也检测大目标？</h2><p>浅层感受野较小, 并且语义信息比较低级<br>深层感受野较大, 包含更多高级语义信息</p>
<p>【链接】onestage目标检测算法中,浅层特征图检测小目<br><a href="https://www.zhihu.com/question/305729744/answer/555781620" target="_blank" rel="noopener">https://www.zhihu.com/question/305729744/answer/555781620</a></p>
<p><span id="GPU 两个重要指标之间的关系"></span></p>
<h2 id="GPU-两个重要指标之间的关系"><a href="#GPU-两个重要指标之间的关系" class="headerlink" title="GPU 两个重要指标之间的关系"></a>GPU 两个重要指标之间的关系</h2><p>科普帖,深度学习中GPU和显存分析: <a href="https://zhuanlan.zhihu.com/p/31558973" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/31558973</a></p>
<p><div style="width: 500px; margin: auto"><img src="http://zerozone-blog.oss-cn-beijing.aliyuncs.com/SummaryOfComputerVision/gpu_nvidia-smi.jpg?x-oss-process=style/blog_img" alt="SummaryOfComputerVision%2Fgpu_nvidia-smi.jpg"></div></p>
<p>上图是<code>nvidia-smi</code>命令的输出, 其中最重要的两个指标:</p>
<ul>
<li>显存占用</li>
<li>GPU 利用率</li>
</ul>
<p>显存占用和GPU利用率是两个不一样的东西，显卡是由GPU计算单元和显存等组成的，显存和GPU的关系有点类似于内存和CPU的关系。</p>
<p>显存可以看成是空间，类似于内存</p>
<ul>
<li>显存用于存放模型，数据</li>
<li>显存越大，所能运行的网络也就越大<br>GPU计算单元类似于CPU中的核，用来进行数值计算。衡量计算量的单位是flop: the number of floating-point multiplication-adds，浮点数先乘后加算一个flop。计算能力越强大，速度越快。衡量计算能力的单位是flops: 每秒能执行的flop数量</li>
</ul>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="number">1</span>*<span class="number">2</span> + <span class="number">3</span>  <span class="comment"># 2 flop</span></span><br><span class="line"><span class="number">1</span>*<span class="number">2</span> + <span class="number">3</span>*<span class="number">4</span> + <span class="number">4</span>*<span class="number">5</span> <span class="comment"># 5 flop</span></span><br></pre></td></tr></table></figure>
<p><span id="GPU 及其显存占用"></span></p>
<h2 id="神经网络显存占用"><a href="#神经网络显存占用" class="headerlink" title="神经网络显存占用"></a>神经网络显存占用</h2><p>神经网络模型占用显存的部分包括:</p>
<ul>
<li>模型的输入</li>
<li>模型中间网络层的输出</li>
<li>模型参数</li>
<li>模型参数的梯度</li>
<li>优化器动量</li>
</ul>
<p>首先, 要确定运算过程中使用的数据类型, 常用的数据类型有: int8, int16, float16, float32 等. <strong>通常, 在训练时, 我们为了更高的精度需要使用 float32 的数据类型, 而在预测时, 我们为了压缩模型的大小会选用 float16 的数据类型(预测时几乎不会带来精度损失)</strong>.<br>距离来说, 一个 $(32, 3, 256, 256)$ 的 tensor, 如果使用的是 float32 的数据类型, 那么它的显存占用约为 <strong>24M</strong>, 而如果使用的是 float16 的数据类型, 那么它的显存占用约为 <strong>12M</strong>.</p>
<p>下面来逐一分析:</p>
<ol>
<li><strong>模型的输入:</strong> 一般就是图片的分辨率大小, 另外需要注意的时, 一般不需要计算模型输入(图片)的梯度.</li>
<li><strong>模型中间网络层的输出:</strong> 这部分显存主要是指每个网络层输出的 feature map, 它的形状和模型的具体结构有关, 越大越厚的 feature map 占用的显存越多.</li>
<li><strong>模型参数:</strong> 只有有参数的层, 才会占用显存, 这些网络层一般包括卷积层, 全连接层, BN 层等等. 其它的不包括参数的层如激活层, 池化层, Dropout 层等均不占用显存. 在 PyTorch 中, 当执行完<code>model=MyModel().cuda()</code>之后就会占用相应的显存, 占用的显存大小基本与下面计算的差不多(会稍大一些, 因为还存在一些其它的开销):<ul>
<li>Linear(M-&gt;N): $M\times N$</li>
<li>Conv2d(Cin, Cout, K): $C_{in} \times C_{out} \times K\times K$</li>
<li>BatchNorm(N): $2N$</li>
<li>Embedding(N, W): $N\times W$</li>
</ul>
</li>
<li><strong>模型参数的梯度:</strong> 在训练的时候, 由于需要进行反向传播的原因, 我们还需要保存每个参数对应的梯度, 这部分的显存占用和参数占用的显存大小一致. 通常来说, 神经网络的每一层输入输出都需要保存下来, 用来进行反向传播. 但是在某些特殊情况下, 我们可以不保存输入. 比如 ReLU, 在 PyTorch 中, 使用<code>nn.ReLU(inplace=True)</code>能将激活函数的输出直接覆盖保存于模型的输入之中, 节省不少内存(此时的反向传播:$y = relu(x) -&gt; dx = dy.copy(); dx[y&lt;=0]=0$).</li>
<li><strong>优化器的动量:</strong> 不同的优化器需要的信息量不同, 对于普通的 SGD 来说, 仅仅需要参数的梯度就足够了, 因此 <strong>总显存(参数+梯度+动量)</strong> 占用为参数显存的 <strong>两倍</strong>, 但是对于 Momentum-SGD, 不仅需要梯度, 还需要动量, 因此总显存占用为参数显存的 <strong>三倍</strong>, 对于 Adam 优化器, 需要更多的动量信息, 总显存占用为参数显存的 <strong>四倍</strong>.</li>
</ol>
<p>在深度学习神经网络的显存占用中, 我们可以得到: <strong><script type="math/tex">显存占用 = 模型显存占用 + batchsize \times 每个样本的显存占用</script></strong>. 可以看出, 显存并不是简单的和 batch_size 成正比, 尤其是在模型自身比较大的情况下.</p>
<p><span id="节省显存的方法"></span></p>
<h2 id="节省显存的方法"><a href="#节省显存的方法" class="headerlink" title="节省显存的方法"></a>节省显存的方法</h2><ul>
<li>降低 batch_size</li>
<li>进行下采样, 降低 feature map 的大小</li>
<li>减少全连接层</li>
<li>将激活层设置成<code>inplace=True</code></li>
<li>使用字节数更少的数据类型(float8, float16等)</li>
</ul>
<p>显存计算, PyTorch 显存跟踪: <a href="https://www.cnblogs.com/kk17/p/10262688.html" target="_blank" rel="noopener">https://www.cnblogs.com/kk17/p/10262688.html</a><br><a href="https://oldpan.me/archives/how-to-calculate-gpu-memory" target="_blank" rel="noopener">https://oldpan.me/archives/how-to-calculate-gpu-memory</a></p>
<p><span id="各个网络层的参数量"></span></p>
<h2 id="各个网络层的参数量"><a href="#各个网络层的参数量" class="headerlink" title="各个网络层的参数量"></a>各个网络层的参数量</h2><p>同时计算 weight 和 bias</p>
<ul>
<li>Linear (M-&gt;N): $(1+M)\times N$</li>
<li>Conv2d (Cin, Cout, Kw, Kh): $C_{out}\times (C_{in} \times K_w\times K_h + 1)$</li>
<li>BatchNorm (N): $2N$</li>
<li>Embedding (N, W): $N\times W$</li>
</ul>
<p><span id="如何计算 FLOPs"></span></p>
<h2 id="如何计算-FLOPs-和-MAC"><a href="#如何计算-FLOPs-和-MAC" class="headerlink" title="如何计算 FLOPs 和 MAC"></a>如何计算 FLOPs 和 MAC</h2><p>FLOPs: Floating point operations, 通常是指运算中乘法和加法的总次数. Paper 里比较流行的单位是 GFLOPs, 即 $10^9$ FLOPs<br>FLOPS: Floating Point Operations Per Second, 代表算力<br>MAC: 只统计乘法, 因此 FLOPs 通常是 MAC 的两倍, 这是因为在编码的时候, 芯片内部会用 MAC 指令进行乘加计算, 对应一个乘法和一个加法, 所以 FLOPs 通常是 MAC 的两倍.</p>
<ol>
<li><strong>矩阵乘法:</strong> $M\times N$ 和 $N\times P$ 的两矩阵相乘, 最终输出的矩阵形状为 $M\times P$, 计算 $M\times P$ 上一个元素需要 $N$ 次乘法, 以及 $N-1$ 次加法, 因此, 矩阵乘法所需的总的 FLOPs 为:<script type="math/tex; mode=display">(N + N - 1) \times M \times P</script></li>
<li><strong>卷积层:</strong> ($C_{in}, C_{out}, K_w, K_h, W_{out}, H_{out}$)(输入输出通道数, 卷积核尺寸, 输出特征图谱尺寸): 首先计算得到 output feature map 上一个像素的值需要的 FLOPs 为 $C_{in}\cdot K_w \cdot K_h$ 次乘法, 以及 $C_{in}\cdot K_w \cdot K_h - 1$ 次加法, 如果算上 bias 加法, 则为 $C_{in}\cdot K_w \cdot K_h$ 次加法, 然后根据输出的 tensor 的 shape, 可以知道总共需要计算的像素点数为 $C_{out}\cdot W_{out} \cdot H_{out}$. 于是可以得到一个卷积层总共的 FLOPs 为:<script type="math/tex; mode=display">(2\times C_{in}\cdot K_w \cdot K_h - 1) \times (C_{out}\cdot W_{out} \cdot H_{out}) \tag{不计 bias}</script><script type="math/tex; mode=display">(2 \times C_{in}\cdot K_w \cdot K_h) \times (C_{out}\cdot W_{out} \cdot H_{out}) \tag{计入 bias}</script></li>
<li><strong>全连接层:</strong> (M, N) (输入神经元数量, 输出神经元数量). 输出一个神经元需要 $M$ 次乘法, $M-1$ 次加法, 如果算上 bias, 就是 $M$ 次加法, 扩展到输出 N 个神经元, 所需要 FLOPs 为:<script type="math/tex; mode=display">(2\times M - 1)\times \tag{不计 bias}N</script><script type="math/tex; mode=display">(2\times M)\times N \tag{计入 bias}</script></li>
</ol>
<p><span id="除了 FLOPs, 还有哪些影响模型速度的因素"></span></p>
<h2 id="除了-FLOPs-还有哪些影响模型速度的因素"><a href="#除了-FLOPs-还有哪些影响模型速度的因素" class="headerlink" title="除了 FLOPs, 还有哪些影响模型速度的因素"></a>除了 FLOPs, 还有哪些影响模型速度的因素</h2><p>参考 ShuffleNetV2 论文</p>
<p><a href="https://www.jiqizhixin.com/articles/2017-09-11-2" target="_blank" rel="noopener">https://www.jiqizhixin.com/articles/2017-09-11-2</a> (内存带宽与计算能力，谁才是决定深度学习执行性能的关键)</p>
<p><strong>结论:</strong> 模型的执行速度除了和总的计算量有关外, 还与运算强度(每单位数据执行的运算操作)有关, 比如 1x1 卷积虽然参数量是 3x3 卷积的 1/9. 但是由于运算强度降低, 导致计算性能下降, 因此其执行速度并不能降低到 1/9. 在进行算法的速度优化的时候, 可以参考 Roofline 模型曲线, 进而决定到底是应该增大带宽还是应该降低计算量.</p>
<p><strong>分析:</strong></p>
<p><div style="width: 500px; margin: auto"><img src="http://zerozone-blog.oss-cn-beijing.aliyuncs.com/SummaryOfComputerVision/gpu_bottle.jpg?x-oss-process=style/blog_img" alt="SummaryOfComputerVision%2Fgpu_bottle.jpg"></div></p>
<p>内存带宽对于硬件系统的性能影响如上图所示。如果把内存比做瓶子，运算单元比作杯子，那么数据就是瓶子里的各色颗粒，而内存接口就是瓶口，通过瓶口数据才能进入杯子被消费（处理）掉。而内存带宽就是瓶口的宽度了。瓶口宽度越窄，则数据需要越多时间才能进入杯子（处理单元）。正所谓「巧妇难为无米之炊」，如果带宽有限，那么即使处理单元无限快，在大多数时候也是处理单元在空等数据，造成了计算力的浪费.<br>算法对于内存带宽的需求通常使用「运算强度 (operational intensity，或称 arithmetic intensity)」这个量来表示，单位是 OPs/byte。这个量的意思是，在算法中平均每读入单位数据，能支持多少次运算操作。运算强度越大，则表示单位数据能支持更多次运算，也就是说算法对于内存带宽的要求越低。所以，运算强度大是好事！<br>我们来举一个例子。对于步长（stride）为 1 的 3x3 卷积运算，假设输入数据平面大小为 64x64。简单起见，假设输入和输出 feature 都为 1。这时候，总共需要进行 62x62 次卷积运算，每次卷积需要做 3x3=9 次乘加运算，所以总共的计算次数为 34596，而数据量为（假设数据和卷积核都用单精度浮点数 2byte）：64x64x2（输入数据）+ 3x3x2（卷积核数据）= 8210 byte，所以运算强度为 34596/8210=4.21。如果我们换成 1x1 卷积，那么总的计算次数变成了 64x64=4096，而所需的数据量为 64x64x2 + 1x1x2=8194。显然，切换为 1x1 卷积可以把计算量降低接近 9 倍，但是运算强度也降低为 0.5，即对于内存带宽的需求也上升了接近 9 倍。因此，如果内存带宽无法满足 1x1 卷积计算，那么切换成 1x1 卷积计算虽然降低了接近 9 倍计算量，但是无法把计算速度提升 9 倍。</p>
<p><div style="width: 500px; margin: auto"><img src="http://zerozone-blog.oss-cn-beijing.aliyuncs.com/SummaryOfComputerVision/gpu_RooflineModel.jpg?x-oss-process=style/blog_img" alt="SummaryOfComputerVision%2Fgpu_RooflineModel.jpg"></div></p>
<p>典型的 Roofline 曲线模型如上图所示，坐标轴分别是计算性能（纵轴）和算法的运算强度（横轴）。Roofline 曲线分成了两部分：左边的上升区，以及右边的饱和区。当算法的运算强度较小时，曲线处于上升区，即计算性能实际被内存带宽所限制，有很多计算处理单元是闲置的。随着算法运算强度上升，即在相同数量的数据下算法可以完成更多运算，于是闲置的运算单元越来越少，这时候计算性能就会上升。然后，随着运算强度越来越高，闲置的计算单元越来越少，最后所有计算单元都被用上了，Roofline 曲线就进入了饱和区，此时运算强度再变大也没有更多的计算单元可用了，于是计算性能不再上升，或者说计算性能遇到了由计算能力（而非内存带宽）决定的「屋顶」（roof）。拿之前 3x3 和 1x1 卷积的例子来说，3x3 卷积可能在 roofline 曲线右边的饱和区，而 1x1 卷积由于运算强度下降，有可能到了 roofline 左边的上升区，这样 1x1 卷积在计算时的计算性能就会下降无法到达峰值性能。虽然 1x1 卷积的计算量下降了接近 9 倍，但是由于计算性能下降，因此实际的计算时间并不是 3x3 卷积的九分之一。</p>
<p>显然，一个计算系统的内存带宽如果很宽，则算法不需要运算强度很大也能轻易碰到计算能力上限决定的「屋顶」。在下图中，计算能力不变，而随着内存带宽的上升，达到计算力屋顶所需的运算强度也越低。</p>
<p><div style="width: 500px; margin: auto"><img src="http://zerozone-blog.oss-cn-beijing.aliyuncs.com/SummaryOfComputerVision/gpu_RooflineModel2.png?x-oss-process=style/blog_img" alt="SummaryOfComputerVision%2Fgpu_RooflineModel2.png"></div></p>
<p>Roofline 模型在算法-硬件协同设计中非常有用，可以确定算法和硬件优化的方向：到底应该增加内存带宽／减小内存带宽需求，还是提升计算能力／降低计算量？如果算法在 roofline 曲线的上升区，那么我们应该增加内存带宽／减小内存带宽需求，提升计算能力／降低计算量对于这类情况并没有帮助。反之亦然。</p>
<p><span id="BN 放在不同位置的区别"></span></p>
<h2 id="BN-放在不同位置的区别"><a href="#BN-放在不同位置的区别" class="headerlink" title="BN 放在不同位置的区别"></a>BN 放在不同位置的区别</h2><p>结论: 由于目前我们对于神经网络内部网络层之间的影响机制还不是特别清楚, 所以在实际中通常就是前面放着试一下, 后面放着试一下, 然后取一个在具体场景下效果最好的. 目前在 <strong>实际上</strong>, Conv-ReLU-BN 的组合方式效果较好.<br>个人拙见: BN 放在激活层之前还是之后取决于你想要进行归一化的对象, 它更像是一个超参数, 需要通过实验结合实际场景来决定. 做了一些简单的实验, 发现小模型使用 BN-ReLU, 大模型使用 ReLU-BN 效果较好.</p>
<ol>
<li><p>Conv-BN-ReLU: 这是比较常见的使用方式, 这种实现方法有一个直接的好处就是可以在网络做前向 inference 的时候, 将 BN 融合到 Conv 中进行加速. 还有另一种好处是个人理解, 就是 BN 在 ReLU 的激活之前, 可以防止某一层的激活值全部被抑制(及某一层的值均小于0), 从而防止从这一层传播的梯度全是 0, 进而可以防止梯度消失现象. (BN 的减均值处理会使得相当一部分响应值变为正, 进而解决了零梯度问题)</p>
</li>
<li><p>Conv-ReLU-BN: 在具体的实验中, 通常 BN 放在最后面效果最好. 个人见解: BN 实际上就是一种归一化, 而归一化通常是对于输入层使用的, 因此, 把 BN 放在最后, 实际上就是对下一个卷积段的输入进行归一化, 从这个角度看, 将 BN 放在激活层之后, 是比较自然的一种做法. 另外, BN 的原文使用的是 sigmoid 和 tanh 激活函数, 但是对于 ReLU 激活来说, 其曲线图像有较大区别, 而 BN 层会起到一定的平滑隐藏层输入分布的作用, 因此, 对于不同的激活函数, BN 的最佳位置或许有些许不同.</p>
</li>
</ol>
<p><span id="BN 在 Inference 阶段的加速"></span></p>
<h2 id="BN-在-Inference-阶段的加速"><a href="#BN-在-Inference-阶段的加速" class="headerlink" title="BN 在 Inference 阶段的加速"></a>BN 在 Inference 阶段的加速</h2><p>在 Inference 阶段, 我们已经确定了 BN 层所需的 mean, std, $\gamma$, $\beta$ 等参数, 不用再单独的计算这些参数的值, 又因为 BN 层的运算实际上就相当于两次 Scale (缩放平移) 操作, 因此当 BN 层和 Conv 层相邻时, 我们可以将 BN 层融合到 Conv 层中, 这对于 Conv 层来说只是改变了一些计算规则, 并没有增加卷积层的计算量, 因此可以起到一定的加速作用.</p>
<p>具体在融合时分为两个情况:</p>
<ol>
<li><p>Conv-BN:<br>卷积层操作: $Y = \vec w X + \vec b$<br>BN层操作: $Y’ = \gamma \frac{Y - \hat \mu}{\sqrt{\sigma^2 + \epsilon}} + \beta$<br>将上面两个公式融合后可变为: $Y’ = \gamma \frac{Y - \hat \mu}{\sqrt{\sigma^2 + \epsilon}} + \beta = \gamma \frac{\vec w X + \vec b - \hat \mu}{\sqrt{\sigma^2 + \epsilon}} + \beta = (\frac{\gamma}{\sqrt{\sigma^2 + \epsilon}} \vec w)\cdot X + \frac{\gamma}{\sqrt{\sigma^2 + \epsilon}} \cdot \vec b - \frac{\gamma}{\sqrt{\sigma^2 + \epsilon}}\hat \mu + \beta = k\vec w \cdot X + \vec b’$<br>可见, 融合后的 BN 就相当于是给卷积层多乘了一个常量, 同时多加了一个常量.</p>
</li>
<li><p>BN-Conv: BN-Conv 无法进行融合, 始终都需要再单独执行 BN 的 Scale 操作, 然后再执行 Conv 的卷积操作</p>
</li>
<li><p>Conv 和 BN 中间有激活层: 无法融合, 需要单独执行每一个网络层</p>
</li>
</ol>
<h2 id="Anchor-的作用是什么-为什么需要-Anchor"><a href="#Anchor-的作用是什么-为什么需要-Anchor" class="headerlink" title="Anchor 的作用是什么? 为什么需要 Anchor?"></a>Anchor 的作用是什么? 为什么需要 Anchor?</h2><p>结论: 为了将 bbox 的 scale 和 aspect ratio 划分到若干个固定的子空间中, 降低问题的复杂度, 同时也降低模型的学习难度. 另一方面, anchor 可以解决多个物体 overlap 过大导致检测结果容易丢失的问题(YOLO 单个 cell 只负责单个物体, Overlap 过大的多个物体可能会落在同一个 cell 中).</p>
<p>Faster RCNN 引入 Anchor 的 motivation:</p>
<blockquote>
<p>In contrast to prevalent methods [8], [9], [1], [2] that use pyramids of images (Figure 1, a) or pyramids of filters (Figure 1, b), we introduce novel “anchor” boxes that serve as references at <strong>multiple scales and aspect ratios</strong>. Our scheme can be thought of as a pyramid of regression references (Figure 1, c), which avoids enumerating images or filters of multiple scales or aspect ratios.</p>
</blockquote>
<p>可见, Anchor 机制要解决的问题是变化范围较大的 bbox 的 scale 和 aspect rotios 问题. 之前的解决方法都是利用 pyramids of images(耗时) 或者 pyramids of filters(传统图像处理). 此外, Anchor 机制还顺便解决了另外一个重要的问题: gt box 之间如果 overlap 较大, 那么它们就会落到一个 cell 上, 从而导致个别 gt box 丢失. 而 anchor 机制不同 scale 和 aspect ratio 的 anchor 会负责各自的 gt box, 即使有多个框映射到同一个 cell, 也不会导致 gt box 丢失.</p>
<h2 id="Anchor-是越多越好吗"><a href="#Anchor-是越多越好吗" class="headerlink" title="Anchor 是越多越好吗?"></a>Anchor 是越多越好吗?</h2><p><strong>当增加超过 6~9 个 anchor 后模型并没有显示出进一步的收益。 性能饱和意味着认为定义的、密度过大的 anchor 并没有呈现出巨大的优势。</strong><br>过于密集的 anchor 不仅会增加 前景-背景 的优化难度，而且还可能导致模糊位置定义问题。 对于每个输出空间的 location 来说，其 anchors 的标签根据与 GT 的 IoU 值定义。 其中，有一些 anchor 被定义为 positive samples，而另一些则被定义为 negative samples。 但是，它们共享这相同的 feature maps。因此分类器不仅需要区分不同位置的样本，还需要在同一位置区分不同的 anchor。</p>
<p><strong>anchor 的数量并不是越多越好</strong>, 虽然直观上来说, anchor 越多时, 可以覆盖越好的 gt box, 但是, 当 anchor 的数量过多时, 一方面由于每一个点上产生的 anchor 实际上共享了一块相似的特征, 但是这些 anchor 有一部分作为正样本, 而另一部分作为负样本, 因此, 对于神经网络来说, 他要通过不断学习来区分这些样本, 不仅如此, 他还要将这些样本与其他点产生的 anchor 区分开, 虽然 anchor 数量的增多, 学习的难度也就慢慢增多, 最终甚至会出现掉点的现象, 个人认为不会掉的特别多, 因为毕竟更多的 anchor 可以覆盖更多的局部最优解. 但是 anchor 会导致计算量的大幅度上升, 因此不建议设置过多 anchor.</p>
<p>FoveaBox 的优势(就 anchor 来说): (1) 神经网络的输出维度大大降低(1/A), 学习起来相对简单直接; (2) 不会出现 anchor 之间互相矛盾的现象 (3) 没有了 anchor 后, 检测网络变的更加简单直接, 扩展性更好</p>
<p>详细见 FoveaBox 分析</p>
<h2 id="Anchor-based-方法和-Anchor-free-方法各有什么优缺点"><a href="#Anchor-based-方法和-Anchor-free-方法各有什么优缺点" class="headerlink" title="Anchor based 方法和 Anchor free 方法各有什么优缺点?"></a>Anchor based 方法和 Anchor free 方法各有什么优缺点?</h2><ul>
<li>Anchor-based 方法处理的尺度范围小(基于 anchor 的设定), 但是更加精准(学习难度小); Anchor-free 方法覆盖的尺度范围大(没有认为设定的 anchor), 但是检测小尺度的能力较低.</li>
<li>Anchor-based 需要根据不同的任务设置更多的超参(anchor scale, aspect ratio)</li>
<li>Anchor-based 方法产生的预选框要在训练阶段和 gt box 进行 IoU 的计算才能确定正负样本, 这会占用一定的内存和运行时间, 降低训练速度. 此外, 对于 SSD 类的算法来说, 为了使其能够更为有效的检测小目标, 通常会在更大尺度的特征图上生成候选框, 这就导致候选框的数量大幅增加.</li>
<li>针对不同的任务, 所有的超参都需要重新调节, 这样一个模型的迁移能力就体现不出来了.</li>
<li>anchor-free 的方法能够在精度上媲美 anchor-based 的方法，最大的功劳我觉得应该归于 FPN，其次归于 Focal Loss。（内心OS：RetinaNet 赛高）。在每个位置只预测一个框的情况下，FPN 的结构对尺度起到了很好的弥补，FocalLoss 则是对中心区域的预测有很大帮助</li>
</ul>
<h2 id="CNN-具有平移不变性吗"><a href="#CNN-具有平移不变性吗" class="headerlink" title="CNN 具有平移不变性吗?"></a>CNN 具有平移不变性吗?</h2><p>首先, 有两个概念需要区分:</p>
<ul>
<li>平移不变性(translation invariant): 对于同样的 input, 其 output 保持不变.</li>
<li>平移等变性(translation equivalence): 如果 innput 平移, 那么其 output 也会发生相应的平移, <strong>但是 output 的取值应该保持不变</strong>.<br>对于分类(classification)任务来说, 我们希望网络具有平移不变性, 因为对于一个物体的平移来说, 不应该改变这个物体的类别. 但是对于检测(detection), 分割(segmentation)任务来说, 我们希望网络具有平移等价性, 即当物体的位置发生变化时, 我们输出的框的位置也应该发生相应的变化, 但是它的取值, 即框的大小, 框的类别应该保持不变.</li>
</ul>
<p>常见网络层对于平移不变性和平移等价性的影响:</p>
<ul>
<li>卷积层: 从卷积的运算定义来看, 卷积应该具有一定的平移等价性, 但是这种等价性需要在物体平移量为 stride 的整数倍时才 <strong>严格成立</strong>(不是整数倍时, 也具有一定程度的平移等价性). 而对于平移不变性来说, 只有当卷积核的值分布比较均匀(值相差不大), 而输入的 feature map 上的值也有很多值分布均匀(值相差不大)的区域时来具有比较弱的平移不变性, 因为这个时候 feature map 上的微小移动对于输出的改变较少.</li>
<li>池化层: 目前大部分的观点都认为, 卷积网络的平移不变性主要是通过池化层实现的, 其中最大池化相对于均值池化来说带有更强的平移不变性, 全局池化层则具有更强的平移不变性. 由于池化操作往往会忽略核内元素的位置, 因此通常认为池化层是不具有平移等价性. 另外, 个人觉得正是因为池化层具有一定程度的平移不变性, 且几乎不具有平移等价性, 因此在处理一些需要平移等价性的任务(比如检测, 分割)的时候, 会经常使用 stride 为 2 的卷积层来代替池化层, 而在分类任务中, 往往会使用池化和全局池化来消除平移的影响. 在 18 年的一篇论文(Why do deep convolutional networks generalize so poorly to small image)中也提到了 stride 为 2 的降采样操作会使得 CNN 网络丢失平移不变性.</li>
<li>全连接层: 从全连接层的计算规则来看, FC <strong>即不具有</strong> 平移不变性 <strong>也不具有</strong> 平移等价性. 因为当参与计算的向量值发生偏移时, 很明显 FC 的输出结果会发生较大的变化, 尤其适当 FC 上的神经元权重相差较大时. (等价性也要求结果保持相对不变). 但是, 我们不能就此断定添加了 FC 层的网络就丧失了平移不变性, 18 年的那篇文章里面给出的实验结果发现 VGG 的平移不变性均好于 ResNet 和 InceptionResNetV2, 文中作者的分析是因为 VGG 具有更大的 max pooling 层而另外两个网络相对较少, 同时后面两个网络更深. 但是还有一点要注意的是, <strong>VGG 有全连接层</strong> 而其他两个没有, 这说明全连接层并不是破坏 CNN 平移不变性的主导因素.</li>
</ul>
<p>我个人认为评价一个网络层是不是具有平移不变性或者平移等价性, 一方面要看它的结构特点, 另一方面也要着重看一下这个网络层学习到的参数, 不同的参数值具有的平移不变性和等价性的强度有较大区别, <strong>而参数的值又来自于数据</strong>, 所以很多时候, 想办法拿到更好的数据也是非常关键的一步. 有文章(也是18那篇)也分析了目前的大部分数据集中的数据, 都具有一定的偏向性, 这种偏向性也就导致训练出来的参数具有一定的偏向性, 不能说这种偏向性不好, 但是它对于网络的泛化能力也确实有一定的影响.</p>
<h1 id="为什么说-ReLU-中的神经元会大量死亡-死亡的神经元可以复活吗-有什么解决办法"><a href="#为什么说-ReLU-中的神经元会大量死亡-死亡的神经元可以复活吗-有什么解决办法" class="headerlink" title="为什么说 ReLU 中的神经元会大量死亡? 死亡的神经元可以复活吗? 有什么解决办法?"></a>为什么说 ReLU 中的神经元会大量死亡? 死亡的神经元可以复活吗? 有什么解决办法?</h1><p>为什么实际使用中不使用 LeakyReLU?(死亡的神经元也可以起到一定的正则作用, 实际使用效果较好)</p>
<p>在Mobile v1里面使用ReLU6，ReLU6就是普通的ReLU但是限制最大输出值为6（对输出值做clip）</p>
<p>看mobilenetv2的论文注意到激活函数是relu6，查了一下，有人说是方便后面参数的定点化Why the 6 in relu6?，　也有说relu6可以让模型学到稀疏性？</p>
<h1 id="未整理的问题"><a href="#未整理的问题" class="headerlink" title="未整理的问题"></a>未整理的问题</h1><p>Why Anchor? <a href="https://mp.weixin.qq.com/s/R0mqIUzyj-8m5JqJ-kMC5Q" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/R0mqIUzyj-8m5JqJ-kMC5Q</a><br>盘点: 性能最强的目标检测算法 <a href="https://mp.weixin.qq.com/s/N7QdQVzm6UuPvPN9niHI6w" target="_blank" rel="noopener">https://mp.weixin.qq.com/s/N7QdQVzm6UuPvPN9niHI6w</a></p>
<p>此外，变体ShuffleNet v2<em>具有最好的精度，仍然比其他方法更快。这引发了一个实际的问题:<em>*如何增加接受域的大小?这对于高分辨率图像[39]中的目标检测至关重要。</em></em> 我们以后会研究这个话题。</p>
<p>ResNet 之后还有什么模型?</p>
<p>Batch 的 size 怎么选, 显存中一般会存储写什么: 显存占用 <a href="https://blog.csdn.net/lien0906/article/details/7886311" target="_blank" rel="noopener">https://blog.csdn.net/lien0906/article/details/7886311</a></p>
<p>【链接】网络inference阶段conv层和BN层的融合<br><a href="https://zhuanlan.zhihu.com/p/48005099" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/48005099</a></p>
<p>模型压缩方法: SVD(由于近似计算, 会降低精度), Network Pruning, Crompression.</p>
<p>手写 iou, nms, soft-nms</p>
<p>二值交叉熵, softmax 公式</p>
<p>手写计算两向量的欧式距离</p>
<p>BN</p>
<p>链表排序</p>
<p>卷积参数量的计算</p>
<p>过拟合遇到过吗？怎么处理的</p>
<p>训练时出现 Nan 可能的原因是什么?  怎么办?<br><a href="https://blog.csdn.net/Michael__Corleone/article/details/78531795" target="_blank" rel="noopener">https://blog.csdn.net/Michael__Corleone/article/details/78531795</a></p>
<p><a href="https://zhuanlan.zhihu.com/p/25110930" target="_blank" rel="noopener">https://zhuanlan.zhihu.com/p/25110930</a></p>
<p><a href="https://www.zhihu.com/question/49346370" target="_blank" rel="noopener">https://www.zhihu.com/question/49346370</a></p>
<p>PCA了解不，其优化目标是什么, Pca白化是什么？</p>
<p>手写BN的实现。注意BN的mean和std是在哪个维度求梯度的，mean和std是滑动平均的值。基于numpy实现</p>
<p>说下牛顿法</p>
<p>反卷积具体怎么实现的</p>
<p>为什么dropout能减少过拟合</p>
<p>NMS的原理，假设两个人靠的非常近，则会识别成一个bbx，会有什么问题，怎么解决</p>
<p>Pytorch当中permute和view的功能</p>
<h1 id="逻辑回归-1"><a href="#逻辑回归-1" class="headerlink" title="逻辑回归"></a>逻辑回归</h1><p>Logistic(Sigmoid) 函数: $g(z) = \frac{1}{1+e^{-z}}$<br>Logistic 表达式: $h_\theta (x) = g(\theta^T x) = \frac{1}{1 + e^{-\theta^Tx}}$<br>线性回归模型: $\theta^T x = \sum^n_{i=1}\theta_i x_i$<br>SGD</p>
<p>Logistic 的梯度更新表达式和最小二乘法(LMS)的公式相同, 虽然看上去完全相同, 但实际上 SGD 和 LMS 是两个完全不同的算法, 因为 SGD 中的 $h_\theta (x)$ 表示的是关于 $\theta^T x$ 的一个非线性函数.</p>
<p>机器学习500问 第二章<br>百面机器学习 第三章</p>
<h1 id="线性回归和逻辑回归的原理和区别"><a href="#线性回归和逻辑回归的原理和区别" class="headerlink" title="线性回归和逻辑回归的原理和区别"></a>线性回归和逻辑回归的原理和区别</h1><h1 id="在Faster-RCNN中-如果两个物体重合度很高-会怎么样"><a href="#在Faster-RCNN中-如果两个物体重合度很高-会怎么样" class="headerlink" title="在Faster RCNN中, 如果两个物体重合度很高, 会怎么样"></a>在Faster RCNN中, 如果两个物体重合度很高, 会怎么样</h1><p>由于 Faster RCNN 在提取感兴趣区域的时候, 它的类别默认是只有二类, 即是否包含物体, 所以如果两个物体重合度很高的话, 最终可能就只能检测出一个物体.(right?)</p>
<h1 id="卷积神经网络复杂度分析"><a href="#卷积神经网络复杂度分析" class="headerlink" title="卷积神经网络复杂度分析"></a>卷积神经网络复杂度分析</h1><p><a href="../深度学习-卷积神经网络复杂度分析">卷积神经网络复杂度分析</a></p>
<h1 id="卷积计算-卷积层特参数个数及征图谱尺寸计算"><a href="#卷积计算-卷积层特参数个数及征图谱尺寸计算" class="headerlink" title="卷积计算,卷积层特参数个数及征图谱尺寸计算"></a>卷积计算,卷积层特参数个数及征图谱尺寸计算</h1><p>卷积层输入图谱大小为 $D_in \times D_{in} \times depth_{in}$ , 卷积核尺寸为 $F \times F \times depth_{in}$, 步长为 $stride$ ,结合padding,输出的图谱size是多少</p>
<script type="math/tex; mode=display">D_{out} = \frac{D_{in} - F + 2*Padding}{stride} + 1</script><p>输出的特征图谱的深度为卷积核的个数: $depth_{out} = Num_{filters}$</p>
<p>本层的偏置参数数量: $Num_{bias} = Num_{filters}$, 注意只与卷积核的个数有关, 与输入的特征图谱的深度无关</p>
<p>该层的参数个数 = 卷积核参数个数 + 偏置项参数个数:</p>
<script type="math/tex; mode=display">Num_{params} = F \times F \times depth_{in} \times depth_{out} + Num_{bias}</script><h1 id="L2正则化和L2规范化-归一化-的不同"><a href="#L2正则化和L2规范化-归一化-的不同" class="headerlink" title="L2正则化和L2规范化(归一化)的不同"></a>L2正则化和L2规范化(归一化)的不同</h1><p>正则化是指正则项, 计算完以后是一个矢量. 归一化是将向量中每个元素进行归一化, 计算完以后还是同size的向量, L2归一化实际上就是对每一个元素除以L2正则项.</p>
<h1 id="从-rcnn-到-faster"><a href="#从-rcnn-到-faster" class="headerlink" title="从 rcnn 到 faster"></a>从 rcnn 到 faster</h1><p><a href="https://blog.csdn.net/xiaoye5606/article/details/71191429" target="_blank" rel="noopener">https://blog.csdn.net/xiaoye5606/article/details/71191429</a></p>
<h1 id="为什么fast-rcnn的roi-pooling比spp的-spatial-pooling效果好"><a href="#为什么fast-rcnn的roi-pooling比spp的-spatial-pooling效果好" class="headerlink" title="为什么fast rcnn的roi pooling比spp的 spatial pooling效果好???"></a>为什么fast rcnn的roi pooling比spp的 spatial pooling效果好???</h1><h1 id="神经网络参数初始化"><a href="#神经网络参数初始化" class="headerlink" title="神经网络参数初始化"></a>神经网络参数初始化</h1><h1 id="分类问题为什么用交叉熵"><a href="#分类问题为什么用交叉熵" class="headerlink" title="分类问题为什么用交叉熵"></a>分类问题为什么用交叉熵</h1><p><strong>典型错误答案1:</strong> 如果用交叉熵，能保证神经网络训练时是一个凸优化问题</p>
<p>错误原因: 凸函数的复合并不一定是凸函数</p>
<p><strong>典型错误答案2:</strong> 如果当前值与目标值相差很远，则梯度下降法迭代时收敛的更快一些</p>
<p>错误原因: 欧式距离(平方损失)也能起到这个作用, 为什么不用?</p>
<p><strong>正确答案:</strong></p>
<p>Cross-Entropy vs. Squared Error Training: a Theoretical and Experimental Comparison.</p>
<h1 id="Relu和Dropout都具有正则化作用-它们在正则化方面的区别是什么"><a href="#Relu和Dropout都具有正则化作用-它们在正则化方面的区别是什么" class="headerlink" title="Relu和Dropout都具有正则化作用, 它们在正则化方面的区别是什么?"></a>Relu和Dropout都具有正则化作用, 它们在正则化方面的区别是什么?</h1><p>Relu是强制正则化(所有神经元的输出值, 只要小于0, 就置为0)</p>
<p>Dropout是随机正则化(随机让一些神经元的不起作用)</p>
<h1 id="介绍一下-hard-negative-mining-难样例挖掘"><a href="#介绍一下-hard-negative-mining-难样例挖掘" class="headerlink" title="介绍一下 hard negative mining(难样例挖掘)"></a>介绍一下 hard negative mining(难样例挖掘)</h1><h1 id="dropout内部是怎么实现的"><a href="#dropout内部是怎么实现的" class="headerlink" title="dropout内部是怎么实现的"></a>dropout内部是怎么实现的</h1><p>在 <strong>训练阶段</strong> 给每个神经元的参数都会乘以 $\frac{1}{\alpha_{dropout}}$, 这样一来, 在训练阶段可以随时更改dropout的参数值, 而对于测试阶段来说, 无需对神经元进行任何额外处理, 所有的神经元都相当于适配了训练过程中dropout对参数带来的影响.</p>
<h1 id="简述一下BN"><a href="#简述一下BN" class="headerlink" title="简述一下BN"></a>简述一下BN</h1><p>首先标准化就是将数据归一到一个希望的区间内, 一般都是归一化到激活函数敏感区域内, 而BN和传统标准标准化的区别主要有两点:</p>
<ul>
<li>BN是在每一个batch上做标准化的, 并且不仅仅只对输入层数据做标准化, 对网络内部的隐藏层输入也会进行标准话</li>
<li>第二就是BN并不是在标准的减均值初标准差之后, 还会进行一个线性变换,<strong>其本质就是改变数据分布的方差和均值</strong>. 对应的两个参数是通过学习学出来的. 其主要思想是考虑到数据可能本身就具有一定的不对称性, 并且激活函数也不一定就在面对标准数据时才有最好的表现, 因此</li>
</ul>
<p>关于BN的详细解析可以看:</p>
<p><div style="width: 550px; margin: auto"><img src="Batch-Normalization深入解析" alt=""></div></p>
<h1 id="各种初始化方式，及公式各个参数对训练的影响"><a href="#各种初始化方式，及公式各个参数对训练的影响" class="headerlink" title="各种初始化方式，及公式各个参数对训练的影响"></a>各种初始化方式，及公式各个参数对训练的影响</h1><h1 id="目标检测，数据不平衡问题怎么解决"><a href="#目标检测，数据不平衡问题怎么解决" class="headerlink" title="目标检测，数据不平衡问题怎么解决"></a>目标检测，数据不平衡问题怎么解决</h1><p>对于目标物的不平衡问题, 通过采样方法来缓解.</p>
<p>对于前后景样本数的不平衡问题, 尝试使用FocalLoss来解决</p>
<script type="math/tex; mode=display">L = -(1-p_t)^\gamma log(p_t)</script><h1 id="你的zerotensor和TF比性能上有优势吗"><a href="#你的zerotensor和TF比性能上有优势吗" class="headerlink" title="你的zerotensor和TF比性能上有优势吗"></a>你的zerotensor和TF比性能上有优势吗</h1><h1 id="常用的数据增强技术"><a href="#常用的数据增强技术" class="headerlink" title="常用的数据增强技术"></a>常用的数据增强技术</h1><p>水平或垂直翻转图像、裁剪、色彩变换、扩展和旋转</p>
<h1 id="有哪些可以避免过拟合的办法"><a href="#有哪些可以避免过拟合的办法" class="headerlink" title="有哪些可以避免过拟合的办法"></a>有哪些可以避免过拟合的办法</h1><p>数据增强, 正则化, 模型融合(其中dropout是模型融合方法中最高效和常用的技巧)</p>
<p>为了防止过拟合，增加训练样本是一个好的解决方案。此外，还可使用数据增强、L1 正则化、L2 正则化、Dropout、DropConnect 和早停（Early stopping）法等</p>
<h1 id="正则化L1和L2的区别"><a href="#正则化L1和L2的区别" class="headerlink" title="正则化L1和L2的区别"></a>正则化L1和L2的区别</h1><h2 id="rcnn。。"><a href="#rcnn。。" class="headerlink" title="rcnn。。"></a>rcnn。。</h2><h1 id="推导svm"><a href="#推导svm" class="headerlink" title="推导svm"></a>推导svm</h1><h1 id="卷积层的参数个数计算公式是："><a href="#卷积层的参数个数计算公式是：" class="headerlink" title="卷积层的参数个数计算公式是："></a>卷积层的参数个数计算公式是：</h1><p>输入的filers×kernerl size ×输出的filters。如：</p>
<p>（3×3×256）×512   括号前面是每一个卷积核的大小，后面的是总共有512个卷积核</p>
<h1 id="梯度消失和梯度爆炸的概念，引用这两个现象的原因及其解决办法"><a href="#梯度消失和梯度爆炸的概念，引用这两个现象的原因及其解决办法" class="headerlink" title="梯度消失和梯度爆炸的概念，引用这两个现象的原因及其解决办法"></a>梯度消失和梯度爆炸的概念，引用这两个现象的原因及其解决办法</h1><p>详见<a href="">梯度消失和梯度爆炸问题深入解析</a></p>
<p><span id="activation"> </span></p>
<h1 id="关于各种激活函数的解析与讨论"><a href="#关于各种激活函数的解析与讨论" class="headerlink" title="关于各种激活函数的解析与讨论"></a>关于各种激活函数的解析与讨论</h1><h1 id="简述ResNet"><a href="#简述ResNet" class="headerlink" title="简述ResNet"></a>简述ResNet</h1><h1 id="嵌入式开发很底层-一般还是倾向于做一些上层的东西"><a href="#嵌入式开发很底层-一般还是倾向于做一些上层的东西" class="headerlink" title="嵌入式开发很底层   一般还是倾向于做一些上层的东西"></a>嵌入式开发很底层   一般还是倾向于做一些上层的东西</h1><h1 id="推导SVM"><a href="#推导SVM" class="headerlink" title="推导SVM"></a>推导SVM</h1><h1 id="比较Boosting和Bagging的异同"><a href="#比较Boosting和Bagging的异同" class="headerlink" title="比较Boosting和Bagging的异同"></a>比较Boosting和Bagging的异同</h1><p>二者都是集成学习方法, 都是将多个弱学习器组合成强学习器的方法, 它们的区别在于:</p>
<p>Boosting: 每一轮根据上一轮的分类结果动态调整每个样本在分类器中的权重, 训练得到k个弱分类器, 他们都有各自的权重, 通过加权组合的方式得到最终的分类结果</p>
<p>Bagging: 从原始数据集中每一轮又放回地抽取训练集(抽取的训练集小于原始数据集), 训练得到k个弱学习器, 然后将这k个软学习器的分类结果结合, 得到最终的分类结果.</p>
<h1 id="无监督学习中存在过拟合吗"><a href="#无监督学习中存在过拟合吗" class="headerlink" title="无监督学习中存在过拟合吗?"></a>无监督学习中存在过拟合吗?</h1><p>存在.<br>//TODO 补充  什么情况下会产生无监督的过拟合</p>
<h1 id="什么是K折交叉验证"><a href="#什么是K折交叉验证" class="headerlink" title="什么是K折交叉验证?"></a>什么是K折交叉验证?</h1><p>将原始数据集划分为k个子集, 将其中一个子集作为验证集, 其余k-1个子集作为训练集, 如此训练和验证一轮成为一次交叉验证. 交叉验证重复k此, 每个子集都会做一次验证, 最终得到k个模型, 然后可以对这k个模型的结果加权平均, 以作为评估整体模型的依据</p>
<h1 id="关于k折交叉验证-需要注意什么"><a href="#关于k折交叉验证-需要注意什么" class="headerlink" title="关于k折交叉验证, 需要注意什么?"></a>关于k折交叉验证, 需要注意什么?</h1><p>k越大, 不一定效果越好, 而且越大的k会加大训练时间;</p>
<p>在选择k时, 需要考虑最小化数据集之间的方差, 比如对于2分类任务, 如果采用2折交叉验证, 即对原始数据集二分,若此时训练集中都是A类别, 验证集中都是B类别, 则交叉验证效果会非常差</p>
<h1 id="对于一个二分类问题-我们定义超过阈值t的判定为正例-否则判定为负例-现在若将t增大-则准确率和召回率会如何变化"><a href="#对于一个二分类问题-我们定义超过阈值t的判定为正例-否则判定为负例-现在若将t增大-则准确率和召回率会如何变化" class="headerlink" title="对于一个二分类问题, 我们定义超过阈值t的判定为正例, 否则判定为负例. 现在若将t增大, 则准确率和召回率会如何变化?"></a>对于一个二分类问题, 我们定义超过阈值t的判定为正例, 否则判定为负例. 现在若将t增大, 则准确率和召回率会如何变化?</h1><p>准确率 = TP / (TP + FP), 召回率 = TP / (TP, FN)</p>
<p>若增大阈值t, 则更多不确定的样本将会被分为负例, 剩余确定样本的所占比例会增大, 那么准确率就会提升(或不变); 同时, 由于那些不确定的样本中还可能包含有正例, 引起, 阈值调大后, 这些正例就会被认为是负例, 所以召回率减小(或不变)</p>
<h1 id="增加网络层数-是否总能减小训练集错误率"><a href="#增加网络层数-是否总能减小训练集错误率" class="headerlink" title="增加网络层数, 是否总能减小训练集错误率?"></a>增加网络层数, 是否总能减小训练集错误率?</h1><p>不能, 有时候网络层数过深, 还会因为梯度消失导致模型退化, 使得模型性能降低</p>
<h1 id="在目标检测问题上-如何做数据增广"><a href="#在目标检测问题上-如何做数据增广" class="headerlink" title="在目标检测问题上, 如何做数据增广?"></a>在目标检测问题上, 如何做数据增广?</h1><h1 id="softmax怎么跟交叉熵损失函数结合"><a href="#softmax怎么跟交叉熵损失函数结合" class="headerlink" title="softmax怎么跟交叉熵损失函数结合?"></a>softmax怎么跟交叉熵损失函数结合?</h1><h1 id="用梯度下降训练神经网络的参数-为什么参数有时候会被训练为nan值"><a href="#用梯度下降训练神经网络的参数-为什么参数有时候会被训练为nan值" class="headerlink" title="用梯度下降训练神经网络的参数, 为什么参数有时候会被训练为nan值?"></a>用梯度下降训练神经网络的参数, 为什么参数有时候会被训练为nan值?</h1><p>输入数据本身存在nan值, 或者考虑是否梯度爆炸了(可以试着降低学习率, 或者利用截断法先知梯度的值)</p>
<h1 id="有没有自己试过更改模型的框架"><a href="#有没有自己试过更改模型的框架" class="headerlink" title="有没有自己试过更改模型的框架."></a>有没有自己试过更改模型的框架.</h1><p>有时候读paper会遇到一些好的点子或者方法, 自己会去加到现有的网络中去验证一下是不是能够提升模型的性能, 一般情况下, 比较经典且认可度较高的一些算法, 由于在网上都能找到相应的源码, 加上去的时候性能往往会有一点提升, 但是有时候有的方法比较偏, 我加完了以后有时候是没作用, 有时候是性能降低了, 我不知道到底是我实现的和paper有出入, 还是这个东西不适合当前框架</p>
<h1 id="说一下你所有的提高精度的方法-并且说明它们带来了多少的精度提升"><a href="#说一下你所有的提高精度的方法-并且说明它们带来了多少的精度提升" class="headerlink" title="说一下你所有的提高精度的方法, 并且说明它们带来了多少的精度提升!"></a>说一下你所有的提高精度的方法, 并且说明它们带来了多少的精度提升!</h1><p>OHEM ~3%</p>
<h1 id="SSD已经使用了难样例挖掘的技巧-Focal-Loss-相比之下为什么能够提高"><a href="#SSD已经使用了难样例挖掘的技巧-Focal-Loss-相比之下为什么能够提高" class="headerlink" title="SSD已经使用了难样例挖掘的技巧, Focal Loss 相比之下为什么能够提高"></a>SSD已经使用了难样例挖掘的技巧, Focal Loss 相比之下为什么能够提高</h1><h1 id="池化的优点-优化的缺点"><a href="#池化的优点-优化的缺点" class="headerlink" title="池化的优点, 优化的缺点"></a>池化的优点, 优化的缺点</h1><p>优点:</p>
<ul>
<li>显著减少参数数量, 降低过拟合</li>
<li>池化单元具有平移不变性</li>
</ul>
<p>缺点:<br>pooling能够增大感受野, 让后续的卷积看到更多的信息, 但是它在降维的过程中丢失了一些信息, 这对segmentation要求的精确location有一定的影响, 所以pooling层跟segmentation有一定的冲突, 但是感受野的增大有可以特征检测实例的准确率, 还可以降低计算量, 增强泛化能力. 所以这个是实例分割问题需要解决的一个关键点之一.</p>
<h1 id="待定"><a href="#待定" class="headerlink" title="待定"></a>待定</h1><p><a href="https://blog.csdn.net/comway_Li/article/details/82532573" target="_blank" rel="noopener">https://blog.csdn.net/comway_Li/article/details/82532573</a></p>
<h1 id="完善bisai待看"><a href="#完善bisai待看" class="headerlink" title="完善bisai待看"></a>完善bisai待看</h1><p><a href="https://www.kaggle.com/c/google-ai-open-images-object-detection-track/discussion/64986" target="_blank" rel="noopener">https://www.kaggle.com/c/google-ai-open-images-object-detection-track/discussion/64986</a></p>
<p><a href="https://arxiv.org/abs/1809.00778" target="_blank" rel="noopener">https://arxiv.org/abs/1809.00778</a></p>
<p><a href="https://www.kaggle.com/c/google-ai-open-images-object-detection-track/discussion" target="_blank" rel="noopener">https://www.kaggle.com/c/google-ai-open-images-object-detection-track/discussion</a></p>
<h1 id="谈谈你参加的比赛"><a href="#谈谈你参加的比赛" class="headerlink" title="谈谈你参加的比赛"></a>谈谈你参加的比赛</h1><p>对于一个比赛任务, 我会首先进行预处理,  之后, 会根据数据集的数据分布来对参数进行调整, 比如, 先只训练顶层, 然后逐步放开, 最后再训练所有层的参数.  在训练的时候,我一般都会采用bagging的思想, 将训练集随机28分, 分成3份, 然后训练, 最后进行模型融合,  融合的时候我一般都是对训练结果进行融合.</p>
<p>如果是目标检测累任务, 那么就:…</p>
<p>如果是实力分割类任务, 那么就:</p>
<h1 id="对于一个新任务-你一般都会使用那些数据预处理方法"><a href="#对于一个新任务-你一般都会使用那些数据预处理方法" class="headerlink" title="(对于一个新任务,) 你一般都会使用那些数据预处理方法"></a>(对于一个新任务,) 你一般都会使用那些数据预处理方法</h1><ol>
<li>训练数据可视化</li>
</ol>
<p>首先, 不论是什么样的数据集, 我都会先随机挑选 20 到 100张 的训练数据, 然后根据标签, 将图片数据可视化出来, 比如说如果是目标检测的任务, 我就会用opencv 的<code>cv2.rectangle()</code> 函数和 <code>cv2.putText()</code> 函数将标签里面的bbox标签和类别标签画到图片上去, 并且建立一个字典结构, 将不同的class-id对应到不同的颜色,  如果是实力分割任务, 我就会将mask标签反应到图片上去, 一般就是先将单通道的mask扩展成多通道的, 同时根据不同的class-id赋予不同的颜色, 最后利用numpy的where方法和原始图片进行叠加.  一般对于这种几十张的smaple图片, 我都是直接保存, 这样以后想再看的时候也不用重新跑脚本了.</p>
<p>之后, 我就会先简单浏览一下这些数据, 对整个数据集有一个初步的把握, 大概知道哪些物体被标注了, 有时候也能发现很多标注存在问题, 不过这也没有办法,  毕竟标注是一个很费时费力的工作, 错误在所难免.</p>
<ol>
<li>计算数据分布信息</li>
</ol>
<p>然后我就会写个脚本对整个数据集和标签进行遍历, 统计一些信息, 通常我会检测这么几个信息:</p>
<p>图像的平均尺寸, 整个数据集的像素平均值, 每张图片平均包含的目标个数, 每个类别的目标个数以及目标的平均大小,</p>
<p>同时, 因为平均值有时候往往反应不出来太多信息, 所以我还会用matplotlib把每种信息的直方图画出来, 然后看一下数据的整体分布是什么样子的, 比如图片size的分布, 目标大小的分布等等, 我主要就是根据这些分布信息来决定我最开始的参数设置.  主要调的参数就是imagesize,anchors相关的参数, 其他的还有就非极大抑制和置信度的阈值, 有时候还会试一下BN的作用(默认是关闭的)</p>
<p>然后一般情况下我都会对数据集做增广</p>
<p>常用的就是裁剪, 反转, 虚化, 颜色变换等等, 增广我不会做太多, 一般就用一些常用的增广方法</p>
<h1 id="比赛中用到的模型融合方法"><a href="#比赛中用到的模型融合方法" class="headerlink" title="比赛中用到的模型融合方法:"></a>比赛中用到的模型融合方法:</h1><p>对于目标检测任务:</p>
<p>我用的融合策略就是先以一个结果文件为基准, 然后用另一个结果文件里面的某张图片的框去跟前一个结果文件对应图片的所有框作比较, 因为之间会对框的面积做排序, 所以只与面积相似的框作比较, 看看框的位置是不是也相似, 如果相似, 就认为检测的是同一个物体, 然后就看他们的类别是否相同, 这里我一般会使用三个结果文件(来自于三个不同模型)进行投票选择.</p>
<p>对于有的框不在另一个文件的,  我就会根据框的置信度来设置一个阈值, 大于阈值的我就直接把框加进去, 如果有票数相同的, 就按置信度来区分.</p>
<h1 id="你的方法与其他人方法的区别是什么-为什么比别人的方法差"><a href="#你的方法与其他人方法的区别是什么-为什么比别人的方法差" class="headerlink" title="你的方法与其他人方法的区别是什么? 为什么比别人的方法差?"></a>你的方法与其他人方法的区别是什么? 为什么比别人的方法差?</h1><h1 id="对于faster-rcnn-你都调了哪些参数"><a href="#对于faster-rcnn-你都调了哪些参数" class="headerlink" title="对于faster rcnn 你都调了哪些参数?"></a>对于faster rcnn 你都调了哪些参数?</h1><p>首先调的是anchor相关参数, 比如anchor size 和 anchor ratio</p>
<p>然后是学习率, 前景后景的样本比例, 非极大抑制的阈值, 候选区域块的生成个数, 图片的缩放尺度等等</p>
<h1 id="BN具体是什么实现的"><a href="#BN具体是什么实现的" class="headerlink" title="BN具体是什么实现的"></a>BN具体是什么实现的</h1><h1 id="对于平均移动了解吗"><a href="#对于平均移动了解吗" class="headerlink" title="对于平均移动了解吗"></a>对于平均移动了解吗</h1><h1 id="积分图-快速求矩阵的核"><a href="#积分图-快速求矩阵的核" class="headerlink" title="积分图, 快速求矩阵的核"></a>积分图, 快速求矩阵的核</h1><h1 id="样本不均衡问题怎么解决"><a href="#样本不均衡问题怎么解决" class="headerlink" title="样本不均衡问题怎么解决"></a>样本不均衡问题怎么解决</h1><h1 id="详细说一下Focal-Loss"><a href="#详细说一下Focal-Loss" class="headerlink" title="详细说一下Focal Loss"></a>详细说一下Focal Loss</h1><h1 id="说一下为什么Faster-比YOLO和SSD更准确"><a href="#说一下为什么Faster-比YOLO和SSD更准确" class="headerlink" title="说一下为什么Faster 比YOLO和SSD更准确"></a>说一下为什么Faster 比YOLO和SSD更准确</h1><h1 id="样本采样的理论化值是"><a href="#样本采样的理论化值是" class="headerlink" title="样本采样的理论化值是"></a>样本采样的理论化值是</h1><h1 id="anchor的参数设值怎么选的？-为什么这么设置"><a href="#anchor的参数设值怎么选的？-为什么这么设置" class="headerlink" title="anchor的参数设值怎么选的？  为什么这么设置"></a>anchor的参数设值怎么选的？  为什么这么设置</h1><h1 id="在调试RPN网络时有没有遇到什么问题？"><a href="#在调试RPN网络时有没有遇到什么问题？" class="headerlink" title="在调试RPN网络时有没有遇到什么问题？"></a>在调试RPN网络时有没有遇到什么问题？</h1><h1 id="简述一下faster-rcnn模型"><a href="#简述一下faster-rcnn模型" class="headerlink" title="简述一下faster rcnn模型"></a>简述一下faster rcnn模型</h1><h1 id="简述一下ResNet模型及它解决的问题"><a href="#简述一下ResNet模型及它解决的问题" class="headerlink" title="简述一下ResNet模型及它解决的问题"></a>简述一下ResNet模型及它解决的问题</h1><h1 id="如何优化CNN-Backbone"><a href="#如何优化CNN-Backbone" class="headerlink" title="如何优化CNN Backbone"></a>如何优化CNN Backbone</h1><p>我们在DataParallel的语境下面讨论这个问题。也就是说，每张显卡都保存一份参数全集，一份数据+数据形成FeatureMap的子集。</p>
<p>我们知道，就像组装深度学习服务器一样，你的预算一定的条件下，如何搭配一台服务器才能让CPU对数据预处理够用、内存加载数据够用、硬盘I/O够用，以及最重要的是，选择一块好的GPU卡。资源不是无限的。这其实是一个线性规划问题。在这里不赘述。</p>
<p>进行CNN Backbone优化同样有这个问题：</p>
<h1 id="你的显存利用率和GPU算力利用率如何达到最高？"><a href="#你的显存利用率和GPU算力利用率如何达到最高？" class="headerlink" title="你的显存利用率和GPU算力利用率如何达到最高？"></a>你的显存利用率和GPU算力利用率如何达到最高？</h1><p>降低Batch-size会减小Feature Map占用缓存，但收敛情况怎么样，可能饮鸩止渴。<br>加宽直接影响参数数量。<br>加深不仅影响参数数量还影响Feature Map大小。<br>分组极大节省参数，甚至还能提高效果。<br>结构复用、压缩节省参数，增加计算量。<br>特征拼接、高阶操作降低并行效率，尤其不是inplace的那种。在动态图框架尤为如此。<br>Bilinear大量使用额外参数。<br>非对称带来额外的代码工作。<br>任何新颖结构的引入带来非连续超参，让模型BP，让超参优化无B可P。<br>如何提高CNN Backbone设计品位？<br>美就是简单<br>美就是复用<br>美就是对称<br>美就是分形<br>Inception-ResNet.v2干不过ResNeXt，我一点都不意外。<br>Mask-RCNN标配ResNeXt101 Backbone，我一点都不意外。</p>
<h1 id="为什么要压缩模型，而不是直接训练一个小模型"><a href="#为什么要压缩模型，而不是直接训练一个小模型" class="headerlink" title="为什么要压缩模型，而不是直接训练一个小模型"></a>为什么要压缩模型，而不是直接训练一个小模型</h1><p><a href="https://www.zhihu.com/question/303922732/answer/541660954" target="_blank" rel="noopener">https://www.zhihu.com/question/303922732/answer/541660954</a></p>
<h1 id="分类问题为什么使用交叉熵损失函数-而不是平方误差"><a href="#分类问题为什么使用交叉熵损失函数-而不是平方误差" class="headerlink" title="分类问题为什么使用交叉熵损失函数, 而不是平方误差"></a>分类问题为什么使用交叉熵损失函数, 而不是平方误差</h1><p>神经网络中如果预测值与实际值的误差越大，那么在反向传播训练的过程中，各种参数调整的幅度就要更大，从而使训练更快收敛；如果预测值与实际值的误差小，各种参数调整的幅度就要小，从而减少震荡。</p>
<p>使用平方误差损失函数，误差增大参数的梯度会增大，但是当误差很大时，参数的梯度就会又减小了。</p>
<p>使用交叉熵损失函数，误差越大参数的梯度也越大，能够快速收敛。</p>
<h1 id="你知道-mixed-precision-training-吗"><a href="#你知道-mixed-precision-training-吗" class="headerlink" title="你知道 mixed precision training 吗?"></a>你知道 mixed precision training 吗?</h1><h1 id="手写-K-Means-伪代码"><a href="#手写-K-Means-伪代码" class="headerlink" title="手写 K-Means 伪代码"></a>手写 K-Means 伪代码</h1><h1 id="Adam-优化器的迭代公式"><a href="#Adam-优化器的迭代公式" class="headerlink" title="Adam 优化器的迭代公式"></a>Adam 优化器的迭代公式</h1><h1 id="找完全二叉树的最后一个节点"><a href="#找完全二叉树的最后一个节点" class="headerlink" title="找完全二叉树的最后一个节点"></a>找完全二叉树的最后一个节点</h1><h1 id="手推两层神经网络的反向传播"><a href="#手推两层神经网络的反向传播" class="headerlink" title="手推两层神经网络的反向传播"></a>手推两层神经网络的反向传播</h1><h1 id="其他的例如softmax与cross-entropy的推导，过拟合与正则化，BiLSTM，Gradient-Explosion，Top-N，特征选择都是常规问题就不仔细说了。"><a href="#其他的例如softmax与cross-entropy的推导，过拟合与正则化，BiLSTM，Gradient-Explosion，Top-N，特征选择都是常规问题就不仔细说了。" class="headerlink" title="其他的例如softmax与cross entropy的推导，过拟合与正则化，BiLSTM，Gradient Explosion，Top N，特征选择都是常规问题就不仔细说了。"></a>其他的例如softmax与cross entropy的推导，过拟合与正则化，BiLSTM，Gradient Explosion，Top N，特征选择都是常规问题就不仔细说了。</h1>
      
    </div>

    

    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/知识点梳理/" rel="tag"><i class="fa fa-tag"></i> 知识点梳理</a>
          
            <a href="/tags/计算机视觉/" rel="tag"><i class="fa fa-tag"></i> 计算机视觉</a>
          
            <a href="/tags/面试/" rel="tag"><i class="fa fa-tag"></i> 面试</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/z_post/计算机视觉-目标检测训练策略/" rel="prev" title="计算机视觉-目标检测训练策略">
                <i class="fa fa-chevron-left"></i> 计算机视觉-目标检测训练策略
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/z_post/面试-算法刷题-LeetCode-record/" rel="next" title="LeetCode 算法题(记录总结)">
                LeetCode 算法题(记录总结) <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          

  
    <div class="comments" id="comments">
    </div>
  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            文章目录
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            站点概览
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <img class="site-author-image" itemprop="image"
                src="/images/avatar_zz.png"
                alt="ZeroZone" />
            
              <p class="site-author-name" itemprop="name">ZeroZone</p>
              <p class="site-description motion-element" itemprop="description">吾乃闪耀的芝士蛋挞!</p>
          </div>

          
            <nav class="site-state motion-element">
              
                <div class="site-state-item site-state-posts">
                
                  <a href="/archives/">
                
                    <span class="site-state-item-count">268</span>
                    <span class="site-state-item-name">日志</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-categories">
                  <a href="/categories/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">13</span>
                    <span class="site-state-item-name">分类</span>
                  </a>
                </div>
              

              
                
                
                <div class="site-state-item site-state-tags">
                  <a href="/tags/index.html">
                    
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                      
                    
                    <span class="site-state-item-count">41</span>
                    <span class="site-state-item-name">标签</span>
                  </a>
                </div>
              
            </nav>
          

          

          
            <div class="links-of-author motion-element">
              
                <span class="links-of-author-item">
                  <a href="https://github.com/hellozhaozheng" target="_blank" title="GitHub"><i class="fa fa-fw fa-github"></i>GitHub</a>
                  
                </span>
              
                <span class="links-of-author-item">
                  <a href="mailto:hellozhaozheng@foxmail.com" target="_blank" title="E-Mail"><i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  
                </span>
              
            </div>
          

          
          

          
          
            <div class="links-of-blogroll motion-element links-of-blogroll-block">
              <div class="links-of-blogroll-title">
                <i class="fa  fa-fw fa-link"></i>
                友情链接
              </div>
              <ul class="links-of-blogroll-list">
                
                  <li class="links-of-blogroll-item">
                    <a href="https://blog.csdn.net/ksws0292756" title="零域CSDN博客" target="_blank">零域CSDN博客</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://xinghanzzy.github.io/" title="BoXiao的博客" target="_blank">BoXiao的博客</a>
                  </li>
                
                  <li class="links-of-blogroll-item">
                    <a href="https://oldpan.me/" title="Oldpan的博客" target="_blank">Oldpan的博客</a>
                  </li>
                
              </ul>
            </div>
          

          
            
          
          

        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#总目录篇"><span class="nav-text">总目录篇</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#机器学习篇"><span class="nav-text">机器学习篇</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#基本概念"><span class="nav-text">基本概念</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#TP-TN-FP-FN-及各种比值代表的含义"><span class="nav-text">TP, TN, FP, FN 及各种比值代表的含义</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#PR-ROC-AUC"><span class="nav-text">PR, ROC, AUC</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#PR-曲线"><span class="nav-text">PR 曲线</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#ROC-曲线"><span class="nav-text">ROC 曲线</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#绘制-ROC-曲线"><span class="nav-text">绘制 ROC 曲线</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#AUC-的含义及计算"><span class="nav-text">AUC 的含义及计算</span></a></li></ol></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#逻辑回归"><span class="nav-text">逻辑回归</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#逻辑回归和线性回归的定义"><span class="nav-text">逻辑回归和线性回归的定义</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#逻辑回归和线性回归的区别和联系"><span class="nav-text">逻辑回归和线性回归的区别和联系</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#对于一个二分类问题-如果数据集中存在一些离异值-在不清洗数据的情况下-选择逻辑回归还是-SVM-为什么"><span class="nav-text">对于一个二分类问题, 如果数据集中存在一些离异值, 在不清洗数据的情况下, 选择逻辑回归还是 SVM? 为什么?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#逻辑回归与-SVM-的区别是什么"><span class="nav-text">逻辑回归与 SVM 的区别是什么</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#逻辑回归和-SVM-哪个是参数模型-哪个是非参数模型"><span class="nav-text">逻辑回归和 SVM 哪个是参数模型, 哪个是非参数模型</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#逻辑回归和-SVM-分别适合在什么情况下使用"><span class="nav-text">逻辑回归和 SVM 分别适合在什么情况下使用</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#KNN"><span class="nav-text">KNN</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#简述-KNN-算法的原理"><span class="nav-text">简述 KNN 算法的原理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#KNN-算法进行分类和回归时的区别"><span class="nav-text">KNN 算法进行分类和回归时的区别</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#KNN-算法的三要素"><span class="nav-text">KNN 算法的三要素</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#KNN-算法是否可微"><span class="nav-text">KNN 算法是否可微</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#编程实现-KNN-算法"><span class="nav-text">编程实现 KNN 算法</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#支持向量机"><span class="nav-text">支持向量机</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#简述-SVM-的基本概念和原理"><span class="nav-text">简述 SVM 的基本概念和原理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#SVM-推导过程"><span class="nav-text">SVM 推导过程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#SVM-如何解决线性不可分问题"><span class="nav-text">SVM 如何解决线性不可分问题</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#为什么SVM的分类结果仅依赖于支持向量"><span class="nav-text">为什么SVM的分类结果仅依赖于支持向量?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#如何选取核函数"><span class="nav-text">如何选取核函数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#为什么说高斯核函数将原始特征空间映射成了无限维空间"><span class="nav-text">为什么说高斯核函数将原始特征空间映射成了无限维空间?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#核函数中不同参数的影响"><span class="nav-text">核函数中不同参数的影响</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#既然深度学习技术性能表现以及全面超越-SVM-SVM-还有存在的必要吗"><span class="nav-text">既然深度学习技术性能表现以及全面超越 SVM, SVM 还有存在的必要吗?</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#决策树"><span class="nav-text">决策树</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#朴素贝叶斯"><span class="nav-text">朴素贝叶斯</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#降维"><span class="nav-text">降维</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#聚类"><span class="nav-text">聚类</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#简述-K-Means-聚类的原理"><span class="nav-text">简述 K-Means 聚类的原理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#K-Means-算法的优点和缺点"><span class="nav-text">K-Means 算法的优点和缺点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#K-Means-实现流程"><span class="nav-text">K-Means 实现流程</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#K-Means-常规实现代码"><span class="nav-text">K-Means 常规实现代码</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#K-Means-实现-anchor-划分"><span class="nav-text">K-Means 实现 anchor 划分</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#XGBoost"><span class="nav-text">XGBoost</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Bagging"><span class="nav-text">Bagging</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#深度学习篇"><span class="nav-text">深度学习篇</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#优化方法"><span class="nav-text">优化方法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#简述各种优化方法的概念及其优缺点"><span class="nav-text">简述各种优化方法的概念及其优缺点</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#各损失函数更新动画"><span class="nav-text">各损失函数更新动画</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#如何选择合适的优化方法"><span class="nav-text">如何选择合适的优化方法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#一阶矩-二阶矩的计算方法及其代表的含义"><span class="nav-text">一阶矩, 二阶矩的计算方法及其代表的含义</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#简述-Adam-中使用的指数加权滑动平均法"><span class="nav-text">简述 Adam 中使用的指数加权滑动平均法</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Adam-算法的原理机制是怎么样的"><span class="nav-text">Adam 算法的原理机制是怎么样的</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Adam-算法与相关的-AdaGrad-和-RMSprop-方法有什么区别"><span class="nav-text">Adam 算法与相关的 AdaGrad 和 RMSprop 方法有什么区别</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Adam-算法如何调参-其常用的参数配置是怎么样的"><span class="nav-text">Adam 算法如何调参, 其常用的参数配置是怎么样的</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Adam-实现优化的过程和权重更新规则"><span class="nav-text">Adam 实现优化的过程和权重更新规则</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Adam-的初始化偏差修正的推导"><span class="nav-text">Adam 的初始化偏差修正的推导</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Adam-的扩展形式-AdaMax"><span class="nav-text">Adam 的扩展形式: AdaMax</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#各种优化方法的源码实现"><span class="nav-text">各种优化方法的源码实现</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#参考文献及其他"><span class="nav-text">参考文献及其他</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#初始化方法"><span class="nav-text">初始化方法</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#各个初始化方法的形式"><span class="nav-text">各个初始化方法的形式,</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Xavier-初始化推导"><span class="nav-text">Xavier 初始化推导</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#训练时是否可以将全部参数初始化为-0"><span class="nav-text">训练时是否可以将全部参数初始化为 0</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#损失函数"><span class="nav-text">损失函数</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#绝对值损失-L1"><span class="nav-text">绝对值损失(L1)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#平方损失-L2"><span class="nav-text">平方损失(L2)</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Softmax-交叉熵"><span class="nav-text">Softmax 交叉熵</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#交叉熵损失"><span class="nav-text">交叉熵损失</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Smooth-L1"><span class="nav-text">Smooth L1</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Focal-Loss"><span class="nav-text">Focal Loss</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#DR-Loss"><span class="nav-text">DR Loss</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#写出多层感知机的平方误差和交叉熵误差损失函数"><span class="nav-text">写出多层感知机的平方误差和交叉熵误差损失函数</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#推导平方误差和交叉熵误差损失函数的各层参数更新的梯度计算公式"><span class="nav-text">推导平方误差和交叉熵误差损失函数的各层参数更新的梯度计算公式</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#激活函数"><span class="nav-text">激活函数</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#写出常用的激活函数的公式及其导数形式"><span class="nav-text">写出常用的激活函数的公式及其导数形式</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#简单画出常用激活函数的图像"><span class="nav-text">简单画出常用激活函数的图像</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#为什么需要激活函数"><span class="nav-text">为什么需要激活函数?</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#标准说法"><span class="nav-text">标准说法</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#更形象的解释"><span class="nav-text">更形象的解释</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#举例说明为什么激活函数可以解决-XOR-问题"><span class="nav-text">举例说明为什么激活函数可以解决 XOR 问题</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#各个激活函数的优缺点和适用场景是什么"><span class="nav-text">各个激活函数的优缺点和适用场景是什么</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Sigmoid-激活函数和-Softmax-激活函数的区别"><span class="nav-text">Sigmoid 激活函数和 Softmax 激活函数的区别</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#什么情况下-ReLU-的神经元会死亡-为什么-可以复活吗"><span class="nav-text">什么情况下 ReLU 的神经元会死亡? 为什么? 可以复活吗?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#如何解决-ReLU-神经元死亡问题"><span class="nav-text">如何解决 ReLU 神经元死亡问题</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#激活函数的使用原则"><span class="nav-text">激活函数的使用原则</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#正则化"><span class="nav-text">正则化</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#简述-L1-正则和-L2-正则的形式"><span class="nav-text">简述 L1 正则和 L2 正则的形式</span></a><ol class="nav-child"><li class="nav-item nav-level-4"><a class="nav-link" href="#L1-正则"><span class="nav-text">L1 正则</span></a></li><li class="nav-item nav-level-4"><a class="nav-link" href="#L2-正则"><span class="nav-text">L2 正则</span></a></li></ol></li><li class="nav-item nav-level-3"><a class="nav-link" href="#L1-正则和-L2-正则的特点是什么-各有什么优势"><span class="nav-text">L1 正则和 L2 正则的特点是什么? 各有什么优势?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#L1-和-L2-的区别有哪些"><span class="nav-text">L1 和 L2 的区别有哪些?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#L1正则化使模型参数稀疏的原理是什么"><span class="nav-text">L1正则化使模型参数稀疏的原理是什么?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#为什么-L1-和-L2-分别对应拉普拉斯先验和高斯先验"><span class="nav-text">为什么 L1 和 L2 分别对应拉普拉斯先验和高斯先验?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#为什么权重矩阵稀疏可以防止过拟合"><span class="nav-text">为什么权重矩阵稀疏可以防止过拟合?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#为何权重参数-w-减小就可以防止过拟合"><span class="nav-text">为何权重参数 $w$ 减小就可以防止过拟合?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#L0-范式和-L1-范式都能实现稀疏-为什么不选择用-L0-而要用-L1"><span class="nav-text">L0 范式和 L1 范式都能实现稀疏, 为什么不选择用 L0 而要用 L1?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#为什么说-L2-范式可以优化计算"><span class="nav-text">为什么说 L2 范式可以优化计算?</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#正则项前面的系数一般怎么设置"><span class="nav-text">正则项前面的系数一般怎么设置?</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#归一化"><span class="nav-text">归一化</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#感受野"><span class="nav-text">感受野</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#全连接层"><span class="nav-text">全连接层</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#全连接层的作用是什么"><span class="nav-text">全连接层的作用是什么</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#将全连接层转换成卷积层由什么好处"><span class="nav-text">将全连接层转换成卷积层由什么好处</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#推导两层全连接网络的反向传播公式"><span class="nav-text">推导两层全连接网络的反向传播公式</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#卷积层"><span class="nav-text">卷积层</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#池化层"><span class="nav-text">池化层</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#池化层的作用是什么"><span class="nav-text">池化层的作用是什么</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#池化层反向传播的梯度时如何求的"><span class="nav-text">池化层反向传播的梯度时如何求的</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#最大池化和平均池化有什么异同-分别适用于什么场景"><span class="nav-text">最大池化和平均池化有什么异同, 分别适用于什么场景</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#全局平均池化层-GAP-的作用"><span class="nav-text">全局平均池化层(GAP)的作用</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#反卷积层"><span class="nav-text">反卷积层</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#空洞卷积"><span class="nav-text">空洞卷积</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#训练问题"><span class="nav-text">训练问题</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#网络结构篇"><span class="nav-text">网络结构篇</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#AlexNet"><span class="nav-text">AlexNet</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#VGGNet"><span class="nav-text">VGGNet</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#InceptionV1"><span class="nav-text">InceptionV1</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#InceptionV3"><span class="nav-text">InceptionV3</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#简述-InceptionV2-相比于-GoogLeNet-有什么区别"><span class="nav-text">简述 InceptionV2 相比于 GoogLeNet 有什么区别</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#简述-InceptionV3-相比于-GoogLeNet-有什么区别"><span class="nav-text">简述 InceptionV3 相比于 GoogLeNet 有什么区别</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#InceptionV4-and-Inception-ResNet"><span class="nav-text">InceptionV4 and Inception ResNet</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#简述-InceptionV4-做了哪些改进"><span class="nav-text">简述 InceptionV4 做了哪些改进</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#简述-Inception-Resnet-v1-做了哪些改进"><span class="nav-text">简述 Inception-Resnet-v1 做了哪些改进</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#简述-Inception-ResNet-v2-做了哪些改进"><span class="nav-text">简述 Inception-ResNet-v2 做了哪些改进</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Xception"><span class="nav-text">Xception</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ResNet"><span class="nav-text">ResNet</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ResNeXt"><span class="nav-text">ResNeXt</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#DenseNet"><span class="nav-text">DenseNet</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#SqueezeNet"><span class="nav-text">SqueezeNet</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#MobileNet"><span class="nav-text">MobileNet</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#MobileNetV2"><span class="nav-text">MobileNetV2</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ShuffleNet"><span class="nav-text">ShuffleNet</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ShuffleNetV2"><span class="nav-text">ShuffleNetV2</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#SENet"><span class="nav-text">SENet</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#目标检测篇"><span class="nav-text">目标检测篇</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#NMS"><span class="nav-text">NMS</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#简述-NMS-的原理"><span class="nav-text">简述 NMS 的原理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#NMS-算法源码实现"><span class="nav-text">NMS 算法源码实现</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#简述-Soft-NMS-的原理"><span class="nav-text">简述 Soft-NMS 的原理</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Soft-NMS-算法源码实现"><span class="nav-text">Soft-NMS 算法源码实现</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#介绍一下其他的-NMS-算法"><span class="nav-text">介绍一下其他的 NMS 算法</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#R-CNN"><span class="nav-text">R-CNN</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Fast-R-CNN"><span class="nav-text">Fast R-CNN</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Faster-R-CNN"><span class="nav-text">Faster R-CNN</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#简介"><span class="nav-text">简介</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#RoI-Pooling-如何进行反向传播"><span class="nav-text">RoI Pooling 如何进行反向传播</span></a></li></ol></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Mask-R-CNN"><span class="nav-text">Mask R-CNN</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#FPN"><span class="nav-text">FPN</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#FCN"><span class="nav-text">FCN</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#RFCN"><span class="nav-text">RFCN</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Deformable-CNN"><span class="nav-text">Deformable CNN</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Cascade-R-CNN"><span class="nav-text">Cascade R-CNN</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#SSD"><span class="nav-text">SSD</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#YOLOv1"><span class="nav-text">YOLOv1</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#YOLOv2"><span class="nav-text">YOLOv2</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#YOLOv3"><span class="nav-text">YOLOv3</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#FocalLoss"><span class="nav-text">FocalLoss</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#TridentNet"><span class="nav-text">TridentNet</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#DenseBox"><span class="nav-text">DenseBox</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#CornerNet"><span class="nav-text">CornerNet</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#CornerNet-Lite"><span class="nav-text">CornerNet-Lite</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#FSAF"><span class="nav-text">FSAF</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#FoveaBox"><span class="nav-text">FoveaBox</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#FCOS"><span class="nav-text">FCOS</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#ExtremeNet"><span class="nav-text">ExtremeNet</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#CenterNet"><span class="nav-text">CenterNet</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#CenterNet-Objects-as-Points"><span class="nav-text">CenterNet(Objects as Points)</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#CornerNet-Lite-1"><span class="nav-text">CornerNet-Lite</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#TridentNet-1"><span class="nav-text">TridentNet</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#其他"><span class="nav-text">其他</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#图像处理篇"><span class="nav-text">图像处理篇</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#图像放缩"><span class="nav-text">图像放缩</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#边缘检测算法"><span class="nav-text">边缘检测算法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#霍夫变换"><span class="nav-text">霍夫变换</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#图像保边滤波器"><span class="nav-text">图像保边滤波器</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#图像平移"><span class="nav-text">图像平移</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#图像开操作、闭操作"><span class="nav-text">图像开操作、闭操作</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#图像旋转"><span class="nav-text">图像旋转</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#图像重建质量评价指标"><span class="nav-text">图像重建质量评价指标</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#光流法"><span class="nav-text">光流法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#图像去噪的方法"><span class="nav-text">图像去噪的方法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#度量图像patch相似度的方法"><span class="nav-text">度量图像patch相似度的方法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#传统图像处理CDC做过吗？"><span class="nav-text">传统图像处理CDC做过吗？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#傅里叶变换"><span class="nav-text">傅里叶变换</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#图像融合算法有哪些？"><span class="nav-text">图像融合算法有哪些？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#图像增强算法有哪些"><span class="nav-text">图像增强算法有哪些</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#图像滤波方法"><span class="nav-text">图像滤波方法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#直方图均衡化"><span class="nav-text">直方图均衡化</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#算法实现篇"><span class="nav-text">算法实现篇</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#KNN-1"><span class="nav-text">KNN</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#K-Means"><span class="nav-text">K-Means</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#IoU"><span class="nav-text">IoU</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#NMS-1"><span class="nav-text">NMS</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#矩阵乘法"><span class="nav-text">矩阵乘法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#高斯滤波"><span class="nav-text">高斯滤波</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#数学基础篇"><span class="nav-text">数学基础篇</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#概率分布"><span class="nav-text">概率分布</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#线性代数"><span class="nav-text">线性代数</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#常见问题篇"><span class="nav-text">常见问题篇</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#目前的-SOTA-目标检测模型"><span class="nav-text">目前的 SOTA 目标检测模型</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#SSD-FPN-RefineDet-PFPNet-STDN-M2Det-等特征金字塔的区别"><span class="nav-text">SSD, FPN, RefineDet, PFPNet, STDN, M2Det 等特征金字塔的区别</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#常用的训练-Trick"><span class="nav-text">常用的训练 Trick</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#有哪些数据增广方法-怎么实现的"><span class="nav-text">有哪些数据增广方法? 怎么实现的?</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#FCN-是如何降低计算量的"><span class="nav-text">FCN 是如何降低计算量的?</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#PyTorch-和-TensorFlow-的区别"><span class="nav-text">PyTorch 和 TensorFlow 的区别</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#目标检测领域还有哪些可以继续改进或者优化的地方"><span class="nav-text">目标检测领域还有哪些可以继续改进或者优化的地方</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#one-stage目标检测算法中-浅层特征图检测小目标，为什么不同时也检测大目标？"><span class="nav-text">one stage目标检测算法中,浅层特征图检测小目标，为什么不同时也检测大目标？</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#GPU-两个重要指标之间的关系"><span class="nav-text">GPU 两个重要指标之间的关系</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#神经网络显存占用"><span class="nav-text">神经网络显存占用</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#节省显存的方法"><span class="nav-text">节省显存的方法</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#各个网络层的参数量"><span class="nav-text">各个网络层的参数量</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#如何计算-FLOPs-和-MAC"><span class="nav-text">如何计算 FLOPs 和 MAC</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#除了-FLOPs-还有哪些影响模型速度的因素"><span class="nav-text">除了 FLOPs, 还有哪些影响模型速度的因素</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#BN-放在不同位置的区别"><span class="nav-text">BN 放在不同位置的区别</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#BN-在-Inference-阶段的加速"><span class="nav-text">BN 在 Inference 阶段的加速</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Anchor-的作用是什么-为什么需要-Anchor"><span class="nav-text">Anchor 的作用是什么? 为什么需要 Anchor?</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Anchor-是越多越好吗"><span class="nav-text">Anchor 是越多越好吗?</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Anchor-based-方法和-Anchor-free-方法各有什么优缺点"><span class="nav-text">Anchor based 方法和 Anchor free 方法各有什么优缺点?</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#CNN-具有平移不变性吗"><span class="nav-text">CNN 具有平移不变性吗?</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#为什么说-ReLU-中的神经元会大量死亡-死亡的神经元可以复活吗-有什么解决办法"><span class="nav-text">为什么说 ReLU 中的神经元会大量死亡? 死亡的神经元可以复活吗? 有什么解决办法?</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#未整理的问题"><span class="nav-text">未整理的问题</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#逻辑回归-1"><span class="nav-text">逻辑回归</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#线性回归和逻辑回归的原理和区别"><span class="nav-text">线性回归和逻辑回归的原理和区别</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#在Faster-RCNN中-如果两个物体重合度很高-会怎么样"><span class="nav-text">在Faster RCNN中, 如果两个物体重合度很高, 会怎么样</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#卷积神经网络复杂度分析"><span class="nav-text">卷积神经网络复杂度分析</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#卷积计算-卷积层特参数个数及征图谱尺寸计算"><span class="nav-text">卷积计算,卷积层特参数个数及征图谱尺寸计算</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#L2正则化和L2规范化-归一化-的不同"><span class="nav-text">L2正则化和L2规范化(归一化)的不同</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#从-rcnn-到-faster"><span class="nav-text">从 rcnn 到 faster</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#为什么fast-rcnn的roi-pooling比spp的-spatial-pooling效果好"><span class="nav-text">为什么fast rcnn的roi pooling比spp的 spatial pooling效果好???</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#神经网络参数初始化"><span class="nav-text">神经网络参数初始化</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#分类问题为什么用交叉熵"><span class="nav-text">分类问题为什么用交叉熵</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Relu和Dropout都具有正则化作用-它们在正则化方面的区别是什么"><span class="nav-text">Relu和Dropout都具有正则化作用, 它们在正则化方面的区别是什么?</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#介绍一下-hard-negative-mining-难样例挖掘"><span class="nav-text">介绍一下 hard negative mining(难样例挖掘)</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#dropout内部是怎么实现的"><span class="nav-text">dropout内部是怎么实现的</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#简述一下BN"><span class="nav-text">简述一下BN</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#各种初始化方式，及公式各个参数对训练的影响"><span class="nav-text">各种初始化方式，及公式各个参数对训练的影响</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#目标检测，数据不平衡问题怎么解决"><span class="nav-text">目标检测，数据不平衡问题怎么解决</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#你的zerotensor和TF比性能上有优势吗"><span class="nav-text">你的zerotensor和TF比性能上有优势吗</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#常用的数据增强技术"><span class="nav-text">常用的数据增强技术</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#有哪些可以避免过拟合的办法"><span class="nav-text">有哪些可以避免过拟合的办法</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#正则化L1和L2的区别"><span class="nav-text">正则化L1和L2的区别</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#rcnn。。"><span class="nav-text">rcnn。。</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#推导svm"><span class="nav-text">推导svm</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#卷积层的参数个数计算公式是："><span class="nav-text">卷积层的参数个数计算公式是：</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#梯度消失和梯度爆炸的概念，引用这两个现象的原因及其解决办法"><span class="nav-text">梯度消失和梯度爆炸的概念，引用这两个现象的原因及其解决办法</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#关于各种激活函数的解析与讨论"><span class="nav-text">关于各种激活函数的解析与讨论</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#简述ResNet"><span class="nav-text">简述ResNet</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#嵌入式开发很底层-一般还是倾向于做一些上层的东西"><span class="nav-text">嵌入式开发很底层   一般还是倾向于做一些上层的东西</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#推导SVM"><span class="nav-text">推导SVM</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#比较Boosting和Bagging的异同"><span class="nav-text">比较Boosting和Bagging的异同</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#无监督学习中存在过拟合吗"><span class="nav-text">无监督学习中存在过拟合吗?</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#什么是K折交叉验证"><span class="nav-text">什么是K折交叉验证?</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#关于k折交叉验证-需要注意什么"><span class="nav-text">关于k折交叉验证, 需要注意什么?</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#对于一个二分类问题-我们定义超过阈值t的判定为正例-否则判定为负例-现在若将t增大-则准确率和召回率会如何变化"><span class="nav-text">对于一个二分类问题, 我们定义超过阈值t的判定为正例, 否则判定为负例. 现在若将t增大, 则准确率和召回率会如何变化?</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#增加网络层数-是否总能减小训练集错误率"><span class="nav-text">增加网络层数, 是否总能减小训练集错误率?</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#在目标检测问题上-如何做数据增广"><span class="nav-text">在目标检测问题上, 如何做数据增广?</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#softmax怎么跟交叉熵损失函数结合"><span class="nav-text">softmax怎么跟交叉熵损失函数结合?</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#用梯度下降训练神经网络的参数-为什么参数有时候会被训练为nan值"><span class="nav-text">用梯度下降训练神经网络的参数, 为什么参数有时候会被训练为nan值?</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#有没有自己试过更改模型的框架"><span class="nav-text">有没有自己试过更改模型的框架.</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#说一下你所有的提高精度的方法-并且说明它们带来了多少的精度提升"><span class="nav-text">说一下你所有的提高精度的方法, 并且说明它们带来了多少的精度提升!</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#SSD已经使用了难样例挖掘的技巧-Focal-Loss-相比之下为什么能够提高"><span class="nav-text">SSD已经使用了难样例挖掘的技巧, Focal Loss 相比之下为什么能够提高</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#池化的优点-优化的缺点"><span class="nav-text">池化的优点, 优化的缺点</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#待定"><span class="nav-text">待定</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#完善bisai待看"><span class="nav-text">完善bisai待看</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#谈谈你参加的比赛"><span class="nav-text">谈谈你参加的比赛</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#对于一个新任务-你一般都会使用那些数据预处理方法"><span class="nav-text">(对于一个新任务,) 你一般都会使用那些数据预处理方法</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#比赛中用到的模型融合方法"><span class="nav-text">比赛中用到的模型融合方法:</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#你的方法与其他人方法的区别是什么-为什么比别人的方法差"><span class="nav-text">你的方法与其他人方法的区别是什么? 为什么比别人的方法差?</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#对于faster-rcnn-你都调了哪些参数"><span class="nav-text">对于faster rcnn 你都调了哪些参数?</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#BN具体是什么实现的"><span class="nav-text">BN具体是什么实现的</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#对于平均移动了解吗"><span class="nav-text">对于平均移动了解吗</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#积分图-快速求矩阵的核"><span class="nav-text">积分图, 快速求矩阵的核</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#样本不均衡问题怎么解决"><span class="nav-text">样本不均衡问题怎么解决</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#详细说一下Focal-Loss"><span class="nav-text">详细说一下Focal Loss</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#说一下为什么Faster-比YOLO和SSD更准确"><span class="nav-text">说一下为什么Faster 比YOLO和SSD更准确</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#样本采样的理论化值是"><span class="nav-text">样本采样的理论化值是</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#anchor的参数设值怎么选的？-为什么这么设置"><span class="nav-text">anchor的参数设值怎么选的？  为什么这么设置</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#在调试RPN网络时有没有遇到什么问题？"><span class="nav-text">在调试RPN网络时有没有遇到什么问题？</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#简述一下faster-rcnn模型"><span class="nav-text">简述一下faster rcnn模型</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#简述一下ResNet模型及它解决的问题"><span class="nav-text">简述一下ResNet模型及它解决的问题</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#如何优化CNN-Backbone"><span class="nav-text">如何优化CNN Backbone</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#你的显存利用率和GPU算力利用率如何达到最高？"><span class="nav-text">你的显存利用率和GPU算力利用率如何达到最高？</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#为什么要压缩模型，而不是直接训练一个小模型"><span class="nav-text">为什么要压缩模型，而不是直接训练一个小模型</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#分类问题为什么使用交叉熵损失函数-而不是平方误差"><span class="nav-text">分类问题为什么使用交叉熵损失函数, 而不是平方误差</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#你知道-mixed-precision-training-吗"><span class="nav-text">你知道 mixed precision training 吗?</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#手写-K-Means-伪代码"><span class="nav-text">手写 K-Means 伪代码</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Adam-优化器的迭代公式"><span class="nav-text">Adam 优化器的迭代公式</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#找完全二叉树的最后一个节点"><span class="nav-text">找完全二叉树的最后一个节点</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#手推两层神经网络的反向传播"><span class="nav-text">手推两层神经网络的反向传播</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#其他的例如softmax与cross-entropy的推导，过拟合与正则化，BiLSTM，Gradient-Explosion，Top-N，特征选择都是常规问题就不仔细说了。"><span class="nav-text">其他的例如softmax与cross entropy的推导，过拟合与正则化，BiLSTM，Gradient Explosion，Top N，特征选择都是常规问题就不仔细说了。</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      
        <div class="back-to-top">
          <i class="fa fa-arrow-up"></i>
          
        </div>
      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2017 &mdash; <span itemprop="copyrightYear">2019</span>
  <span class="with-love" id="animate">
    <i class="fa fa-heart"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">ZeroZone</span>

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-area-chart"></i>
    </span>
    
    <span title="站点总字数">2.7m</span>
  

  
    <span class="post-meta-divider">|</span>
    <span class="post-meta-item-icon">
      <i class="fa fa-coffee"></i>
    </span>
    
    <span title="站点阅读时长">40:38</span>
  
</div>










  <div class="footer-custom">勤练带来力量</div>


        
<div class="busuanzi-count">
  <script async src="https://dn-lbstatics.qbox.me/busuanzi/2.3/busuanzi.pure.mini.js"></script>

  
    <span class="site-uv" title="总访客量">
      <i class="fa fa-user"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_uv"></span>
    </span>
  

  
    <span class="site-pv" title="总访问量">
      <i class="fa fa-eye"></i>
      <span class="busuanzi-value" id="busuanzi_value_site_pv"></span>
    </span>
  
</div>









        
      </div>
    </footer>

    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>












  















  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=6.3.0"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=6.3.0"></script>



  
  


  <script type="text/javascript" src="/js/src/affix.js?v=6.3.0"></script>

  <script type="text/javascript" src="/js/src/schemes/pisces.js?v=6.3.0"></script>



  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=6.3.0"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=6.3.0"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=6.3.0"></script>



  



  





  








  <script src="//cdn1.lncld.net/static/js/3.0.4/av-min.js"></script>
  
  
  <script src="//unpkg.com/valine/dist/Valine.min.js"></script>
  
  <script type="text/javascript">
    var GUEST = ['nick','mail','link'];
    var guest = 'nick,mail';
    guest = guest.split(',').filter(function (item) {
      return GUEST.indexOf(item)>-1;
    });
    new Valine({
        el: '#comments' ,
        verify: false,
        notify: true,
        appId: 'o5ny24Rtrv0pjlRYjBoj9rfz-gzGzoHsz',
        appKey: 'o9SAGYkO04n5xjXkeWXaq1pm',
        placeholder: '无需注册即可评论, 支持在 Gravatar(https://cn.gravatar.com) 上自定义头像, 评论时只需填写对应邮箱即可显示自定义头像, 邮箱不会暴露在评论处, 大可放心, 由于无登陆选项, 因此邮箱会作为我联系你的唯一方式',
        avatar:'',
        guest_info:guest,
        pageSize:'10' || 10,
    });
  </script>



  

  <script type="text/javascript">
    // Popup Window;
    var isfetched = false;
    var isXml = true;
    // Search DB path;
    var search_path = "search.xml";
    if (search_path.length === 0) {
      search_path = "search.xml";
    } else if (/json$/i.test(search_path)) {
      isXml = false;
    }
    var path = "/" + search_path;
    // monitor main search box;

    var onPopupClose = function (e) {
      $('.popup').hide();
      $('#local-search-input').val('');
      $('.search-result-list').remove();
      $('#no-result').remove();
      $(".local-search-pop-overlay").remove();
      $('body').css('overflow', '');
    }

    function proceedsearch() {
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay"></div>')
        .css('overflow', 'hidden');
      $('.search-popup-overlay').click(onPopupClose);
      $('.popup').toggle();
      var $localSearchInput = $('#local-search-input');
      $localSearchInput.attr("autocapitalize", "none");
      $localSearchInput.attr("autocorrect", "off");
      $localSearchInput.focus();
    }

    // search function;
    var searchFunc = function(path, search_id, content_id) {
      'use strict';

      // start loading animation
      $("body")
        .append('<div class="search-popup-overlay local-search-pop-overlay">' +
          '<div id="search-loading-icon">' +
          '<i class="fa fa-spinner fa-pulse fa-5x fa-fw"></i>' +
          '</div>' +
          '</div>')
        .css('overflow', 'hidden');
      $("#search-loading-icon").css('margin', '20% auto 0 auto').css('text-align', 'center');

      

      $.ajax({
        url: path,
        dataType: isXml ? "xml" : "json",
        async: true,
        success: function(res) {
          // get the contents from search data
          isfetched = true;
          $('.popup').detach().appendTo('.header-inner');
          var datas = isXml ? $("entry", res).map(function() {
            return {
              title: $("title", this).text(),
              content: $("content",this).text(),
              url: $("url" , this).text()
            };
          }).get() : res;
          var input = document.getElementById(search_id);
          var resultContent = document.getElementById(content_id);
          var inputEventFunction = function() {
            var searchText = input.value.trim().toLowerCase();
            var keywords = searchText.split(/[\s\-]+/);
            if (keywords.length > 1) {
              keywords.push(searchText);
            }
            var resultItems = [];
            if (searchText.length > 0) {
              // perform local searching
              datas.forEach(function(data) {
                var isMatch = false;
                var hitCount = 0;
                var searchTextCount = 0;
                var title = data.title.trim();
                var titleInLowerCase = title.toLowerCase();
                var content = data.content.trim().replace(/<[^>]+>/g,"");
                
                var contentInLowerCase = content.toLowerCase();
                var articleUrl = decodeURIComponent(data.url);
                var indexOfTitle = [];
                var indexOfContent = [];
                // only match articles with not empty titles
                if(title != '') {
                  keywords.forEach(function(keyword) {
                    function getIndexByWord(word, text, caseSensitive) {
                      var wordLen = word.length;
                      if (wordLen === 0) {
                        return [];
                      }
                      var startPosition = 0, position = [], index = [];
                      if (!caseSensitive) {
                        text = text.toLowerCase();
                        word = word.toLowerCase();
                      }
                      while ((position = text.indexOf(word, startPosition)) > -1) {
                        index.push({position: position, word: word});
                        startPosition = position + wordLen;
                      }
                      return index;
                    }

                    indexOfTitle = indexOfTitle.concat(getIndexByWord(keyword, titleInLowerCase, false));
                    indexOfContent = indexOfContent.concat(getIndexByWord(keyword, contentInLowerCase, false));
                  });
                  if (indexOfTitle.length > 0 || indexOfContent.length > 0) {
                    isMatch = true;
                    hitCount = indexOfTitle.length + indexOfContent.length;
                  }
                }

                // show search results

                if (isMatch) {
                  // sort index by position of keyword

                  [indexOfTitle, indexOfContent].forEach(function (index) {
                    index.sort(function (itemLeft, itemRight) {
                      if (itemRight.position !== itemLeft.position) {
                        return itemRight.position - itemLeft.position;
                      } else {
                        return itemLeft.word.length - itemRight.word.length;
                      }
                    });
                  });

                  // merge hits into slices

                  function mergeIntoSlice(text, start, end, index) {
                    var item = index[index.length - 1];
                    var position = item.position;
                    var word = item.word;
                    var hits = [];
                    var searchTextCountInSlice = 0;
                    while (position + word.length <= end && index.length != 0) {
                      if (word === searchText) {
                        searchTextCountInSlice++;
                      }
                      hits.push({position: position, length: word.length});
                      var wordEnd = position + word.length;

                      // move to next position of hit

                      index.pop();
                      while (index.length != 0) {
                        item = index[index.length - 1];
                        position = item.position;
                        word = item.word;
                        if (wordEnd > position) {
                          index.pop();
                        } else {
                          break;
                        }
                      }
                    }
                    searchTextCount += searchTextCountInSlice;
                    return {
                      hits: hits,
                      start: start,
                      end: end,
                      searchTextCount: searchTextCountInSlice
                    };
                  }

                  var slicesOfTitle = [];
                  if (indexOfTitle.length != 0) {
                    slicesOfTitle.push(mergeIntoSlice(title, 0, title.length, indexOfTitle));
                  }

                  var slicesOfContent = [];
                  while (indexOfContent.length != 0) {
                    var item = indexOfContent[indexOfContent.length - 1];
                    var position = item.position;
                    var word = item.word;
                    // cut out 100 characters
                    var start = position - 20;
                    var end = position + 80;
                    if(start < 0){
                      start = 0;
                    }
                    if (end < position + word.length) {
                      end = position + word.length;
                    }
                    if(end > content.length){
                      end = content.length;
                    }
                    slicesOfContent.push(mergeIntoSlice(content, start, end, indexOfContent));
                  }

                  // sort slices in content by search text's count and hits' count

                  slicesOfContent.sort(function (sliceLeft, sliceRight) {
                    if (sliceLeft.searchTextCount !== sliceRight.searchTextCount) {
                      return sliceRight.searchTextCount - sliceLeft.searchTextCount;
                    } else if (sliceLeft.hits.length !== sliceRight.hits.length) {
                      return sliceRight.hits.length - sliceLeft.hits.length;
                    } else {
                      return sliceLeft.start - sliceRight.start;
                    }
                  });

                  // select top N slices in content

                  var upperBound = parseInt('1');
                  if (upperBound >= 0) {
                    slicesOfContent = slicesOfContent.slice(0, upperBound);
                  }

                  // highlight title and content

                  function highlightKeyword(text, slice) {
                    var result = '';
                    var prevEnd = slice.start;
                    slice.hits.forEach(function (hit) {
                      result += text.substring(prevEnd, hit.position);
                      var end = hit.position + hit.length;
                      result += '<b class="search-keyword">' + text.substring(hit.position, end) + '</b>';
                      prevEnd = end;
                    });
                    result += text.substring(prevEnd, slice.end);
                    return result;
                  }

                  var resultItem = '';

                  if (slicesOfTitle.length != 0) {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + highlightKeyword(title, slicesOfTitle[0]) + "</a>";
                  } else {
                    resultItem += "<li><a href='" + articleUrl + "' class='search-result-title'>" + title + "</a>";
                  }

                  slicesOfContent.forEach(function (slice) {
                    resultItem += "<a href='" + articleUrl + "'>" +
                      "<p class=\"search-result\">" + highlightKeyword(content, slice) +
                      "...</p>" + "</a>";
                  });

                  resultItem += "</li>";
                  resultItems.push({
                    item: resultItem,
                    searchTextCount: searchTextCount,
                    hitCount: hitCount,
                    id: resultItems.length
                  });
                }
              })
            };
            if (keywords.length === 1 && keywords[0] === "") {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-search fa-5x" /></div>'
            } else if (resultItems.length === 0) {
              resultContent.innerHTML = '<div id="no-result"><i class="fa fa-frown-o fa-5x" /></div>'
            } else {
              resultItems.sort(function (resultLeft, resultRight) {
                if (resultLeft.searchTextCount !== resultRight.searchTextCount) {
                  return resultRight.searchTextCount - resultLeft.searchTextCount;
                } else if (resultLeft.hitCount !== resultRight.hitCount) {
                  return resultRight.hitCount - resultLeft.hitCount;
                } else {
                  return resultRight.id - resultLeft.id;
                }
              });
              var searchResultList = '<ul class=\"search-result-list\">';
              resultItems.forEach(function (result) {
                searchResultList += result.item;
              })
              searchResultList += "</ul>";
              resultContent.innerHTML = searchResultList;
            }
          }

          if ('auto' === 'auto') {
            input.addEventListener('input', inputEventFunction);
          } else {
            $('.search-icon').click(inputEventFunction);
            input.addEventListener('keypress', function (event) {
              if (event.keyCode === 13) {
                inputEventFunction();
              }
            });
          }

          // remove loading animation
          $(".local-search-pop-overlay").remove();
          $('body').css('overflow', '');

          proceedsearch();
        }
      });
    }

    // handle and trigger popup window;
    $('.popup-trigger').click(function(e) {
      e.stopPropagation();
      if (isfetched === false) {
        searchFunc(path, 'local-search-input', 'local-search-result');
      } else {
        proceedsearch();
      };
    });

    $('.popup-btn-close').click(onPopupClose);
    $('.popup').click(function(e){
      e.stopPropagation();
    });
    $(document).on('keyup', function (event) {
      var shouldDismissSearchPopup = event.which === 27 &&
        $('.search-popup').is(':visible');
      if (shouldDismissSearchPopup) {
        onPopupClose();
      }
    });
  </script>





  

  

  
<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';        
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>


<script>
(function(){
    var bp = document.createElement('script');
    var curProtocol = window.location.protocol.split(':')[0];
    if (curProtocol === 'https') {
        bp.src = 'https://zz.bdstatic.com/linksubmit/push.js';
    }
    else {
        bp.src = 'http://push.zhanzhang.baidu.com/push.js';
    }
    var s = document.getElementsByTagName("script")[0];
    s.parentNode.insertBefore(bp, s);
})();
</script>





  
  

  
  

  
    
      <script type="text/x-mathjax-config">
    MathJax.Hub.Config({
      tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
      },
      TeX: {equationNumbers: { autoNumber: "AMS" }}
    });
</script>

<script type="text/x-mathjax-config">
    MathJax.Hub.Queue(function() {
      var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
    });
</script>
<script type="text/javascript" src="//cdn.jsdelivr.net/npm/mathjax@2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script>

    
  


  
  

  

  

  

  

  
  <style>
    .copy-btn {
      display: inline-block;
      padding: 6px 12px;
      font-size: 13px;
      font-weight: 700;
      line-height: 20px;
      color: #333;
      white-space: nowrap;
      vertical-align: middle;
      cursor: pointer;
      background-color: #eee;
      background-image: linear-gradient(#fcfcfc, #eee);
      border: 1px solid #d5d5d5;
      border-radius: 3px;
      user-select: none;
      outline: 0;
    }

    .highlight-wrap .copy-btn {
      transition: opacity .3s ease-in-out;
      opacity: 0;
      padding: 2px 6px;
      position: absolute;
      right: 4px;
      top: 8px;
    }

    .highlight-wrap:hover .copy-btn,
    .highlight-wrap .copy-btn:focus {
      opacity: 1
    }

    .highlight-wrap {
      position: relative;
    }
  </style>
  <script>
    $('.highlight').each(function (i, e) {
      var $wrap = $('<div>').addClass('highlight-wrap')
      $(e).after($wrap)
      $wrap.append($('<button>').addClass('copy-btn').append('复制').on('click', function (e) {
        var code = $(this).parent().find('.code').find('.line').map(function (i, e) {
          return $(e).text()
        }).toArray().join('\n')
        var ta = document.createElement('textarea')
        document.body.appendChild(ta)
        ta.style.position = 'absolute'
        ta.style.top = '0px'
        ta.style.left = '0px'
        ta.value = code
        ta.select()
        ta.focus()
        var result = document.execCommand('copy')
        document.body.removeChild(ta)
        
        $(this).blur()
      })).on('mouseleave', function (e) {
        var $b = $(this).find('.copy-btn')
        setTimeout(function () {
          $b.text('复制')
        }, 300)
      }).append(e)
    })
  </script>


</body>
</html>
